{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Lambda\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from copy import deepcopy, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters:\n",
    "num_epochs = 10\n",
    "batch_size = 1000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(\n",
    "    root='.',\n",
    "    download=True,\n",
    "    train=True, \n",
    "    )\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root='.',\n",
    "    download=True,\n",
    "    train=False, \n",
    ")\n",
    "\n",
    "\n",
    "train_dataset.data = (train_dataset.data/255.0)  \n",
    "test_dataset.data = (test_dataset.data/255.0)\n",
    "\n",
    "\n",
    "def calculate_mean_and_std() -> Tuple[float, float]:\n",
    "    mean = train_dataset.data.mean()\n",
    "    std = train_dataset.data.std()\n",
    "    return mean, std\n",
    "\n",
    "mean, std = calculate_mean_and_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        #transforms.Lambda(lambda x: x.view(28,28)),\n",
    "        transforms.Lambda(lambda x: (x-mean)/std),       \n",
    "]) \n",
    "\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root = '.', \n",
    "    download = True, \n",
    "    train = True, \n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root='.',\n",
    "    download=True,\n",
    "    train=False, \n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000])\n",
      "Checking, whether normalization in transforms is working.\n",
      "Sample image in bath size:\t mean(x) = -0.1669987589120865\t std(x)=0.7772389650344849\n",
      "Sample image in bath size:\t mean(x) = 0.11545051634311676\t std(x)=1.0766876935958862\n",
      "Sample image in bath size:\t mean(x) = 0.026273908093571663\t std(x)=1.0131289958953857\n",
      "Sample image in bath size:\t mean(x) = 0.13533784449100494\t std(x)=1.134533166885376\n",
      "Sample image in bath size:\t mean(x) = 0.19215869903564453\t std(x)=1.1865630149841309\n",
      "Sample image in bath size:\t mean(x) = 0.04999269172549248\t std(x)=1.0453811883926392\n",
      "Sample image in bath size:\t mean(x) = -0.04233338311314583\t std(x)=0.9469925761222839\n",
      "Sample image in bath size:\t mean(x) = 0.04065779596567154\t std(x)=1.0308281183242798\n",
      "Sample image in bath size:\t mean(x) = 0.2721627354621887\t std(x)=1.2374012470245361\n",
      "Sample image in bath size:\t mean(x) = 0.21128308773040771\t std(x)=1.1802409887313843\n",
      "Sample image in bath size:\t mean(x) = -0.2229432314634323\t std(x)=0.7131277918815613\n",
      "Sample image in bath size:\t mean(x) = -0.11597340553998947\t std(x)=0.8660098314285278\n",
      "Sample image in bath size:\t mean(x) = 0.03478086367249489\t std(x)=1.0419135093688965\n",
      "Sample image in bath size:\t mean(x) = -0.034524571150541306\t std(x)=0.9384729266166687\n",
      "Sample image in bath size:\t mean(x) = -0.052528709173202515\t std(x)=0.9512642025947571\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "#assert len(x.shape) == 4\n",
    "#assert x.shape == (100, 1, 28,28)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(\"Checking, whether normalization in transforms is working.\")\n",
    "\n",
    "for i in range(100):\n",
    "    if i%7==0:\n",
    "        print(\"Sample image in bath size:\\t mean(x) = {:}\\t std(x)={:}\".format(x[i].mean(), x[i].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "nn.conv2d=\n",
    "\n",
    "        in_channels (int) – Number of channels in the input image\n",
    "\n",
    "        out_channels (int) – Number of channels produced by the convolution\n",
    "\n",
    "        kernel_size (int or tuple) – Size of the convolving kernel\n",
    "\n",
    "        stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "\n",
    "        padding (int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0\n",
    "\n",
    "        padding_mode (string, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'\n",
    "\n",
    "        dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
    "\n",
    "        groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "        bias (bool, optional) – If True, adds a learnable bias to the output. Default: True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_small(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_small, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5, padding=0), #1 * 28 * 28 -> 8 * 24 * 24\n",
    "            nn.BatchNorm2d(8),                         #8 * 24 * 24\n",
    "            nn.ReLU())                                 #8 * 24 * 24\n",
    "        \n",
    "        self.layer2  = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=5, padding=0), # 8 * 24 * 24 -> 16 * 20* 20\n",
    "            nn.BatchNorm2d(16),                         #16 * 20 * 20\n",
    "            nn.ReLU())                                  #16 * 20 * 20\n",
    "        \n",
    "        self.fc = nn.Linear(16 * 20 * 20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = CNN_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5, padding=2), #1 * 28 * 28 -> 8 * 28 * 28\n",
    "            nn.BatchNorm2d(8),                         #8 * 28 * 28\n",
    "            nn.ReLU())                                 #8 * 28 * 28\n",
    "            #nn.MaxPool2d(2))       \n",
    "        \n",
    "        self.layer2  = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=5, padding=2), # 8 * 28 * 28 -> 16 * 28* 28\n",
    "            nn.BatchNorm2d(16),                         #16 * 28 * 28\n",
    "            nn.ReLU())                                  #16 * 28 * 28\n",
    "            #nn.MaxPool2d(2))       \n",
    "        \n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,  0 loss -  tensor(0.1451, grad_fn=<NllLossBackward>)\n",
      "epoch,  1 loss -  tensor(0.0791, grad_fn=<NllLossBackward>)\n",
      "epoch,  2 loss -  tensor(0.0626, grad_fn=<NllLossBackward>)\n",
      "epoch,  3 loss -  tensor(0.0414, grad_fn=<NllLossBackward>)\n",
      "epoch,  4 loss -  tensor(0.0221, grad_fn=<NllLossBackward>)\n",
      "epoch,  5 loss -  tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "epoch,  6 loss -  tensor(0.0301, grad_fn=<NllLossBackward>)\n",
      "epoch,  7 loss -  tensor(0.0220, grad_fn=<NllLossBackward>)\n",
      "epoch,  8 loss -  tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "epoch,  9 loss -  tensor(0.0152, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"epoch, \",epoch,\"loss - \", loss, )\n",
    "    print(\"epoch, \",epoch,\"loss - \", loss, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.64 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "       # images = images.to(device)\n",
    "       # labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Paramteres, weights and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layer1.0.weight \t torch.Size([8, 1, 5, 5])\n",
      "layer1.0.bias \t torch.Size([8])\n",
      "layer1.1.weight \t torch.Size([8])\n",
      "layer1.1.bias \t torch.Size([8])\n",
      "layer1.1.running_mean \t torch.Size([8])\n",
      "layer1.1.running_var \t torch.Size([8])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([16, 8, 5, 5])\n",
      "layer2.0.bias \t torch.Size([16])\n",
      "layer2.1.weight \t torch.Size([16])\n",
      "layer2.1.bias \t torch.Size([16])\n",
      "layer2.1.running_mean \t torch.Size([16])\n",
      "layer2.1.running_var \t torch.Size([16])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([10, 12544])\n",
      "fc.bias \t torch.Size([10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " tensor([[[[-0.0759,  0.0487,  0.1627,  0.0699, -0.0248],\n",
      "          [ 0.1798, -0.0290,  0.1644, -0.1599,  0.0678],\n",
      "          [ 0.1376,  0.0257, -0.1042, -0.1645, -0.0962],\n",
      "          [ 0.0095,  0.1079,  0.0114, -0.0978,  0.0887],\n",
      "          [ 0.0188,  0.0047, -0.0642, -0.1813, -0.1474]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0707, -0.0698,  0.0512, -0.0010, -0.0389],\n",
      "          [ 0.0920, -0.0239, -0.1559,  0.1618,  0.1338],\n",
      "          [-0.0602, -0.0102,  0.1800, -0.0139, -0.1545],\n",
      "          [-0.0899, -0.0427,  0.0067,  0.1084, -0.0641],\n",
      "          [-0.0965,  0.0968,  0.0927,  0.1107, -0.2168]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1630,  0.1460,  0.0272,  0.2347,  0.0579],\n",
      "          [ 0.0011,  0.0566, -0.0455, -0.1168,  0.0183],\n",
      "          [-0.1897, -0.0188, -0.0242, -0.1700, -0.0303],\n",
      "          [-0.0376, -0.1020,  0.0887, -0.1878,  0.0098],\n",
      "          [-0.0184, -0.1375, -0.0410,  0.1302, -0.0553]]],\n",
      "\n",
      "\n",
      "        [[[-0.1307,  0.1214, -0.1083, -0.0127, -0.1789],\n",
      "          [ 0.0293,  0.1362, -0.1467, -0.0620,  0.0009],\n",
      "          [ 0.0531, -0.1054,  0.1830,  0.1026,  0.1351],\n",
      "          [ 0.0486,  0.1137, -0.0330, -0.0373,  0.0804],\n",
      "          [ 0.1821, -0.0562,  0.0362,  0.1368, -0.0690]]],\n",
      "\n",
      "\n",
      "        [[[-0.0835, -0.1344, -0.0168,  0.1614,  0.0408],\n",
      "          [ 0.1282, -0.1991, -0.0976, -0.0665, -0.1785],\n",
      "          [-0.0787,  0.0081,  0.0226, -0.2229, -0.2179],\n",
      "          [ 0.0990, -0.1221, -0.1734,  0.0705,  0.1015],\n",
      "          [ 0.0732, -0.0843,  0.0846,  0.1193, -0.0632]]],\n",
      "\n",
      "\n",
      "        [[[-0.1100, -0.0167,  0.0196, -0.1097,  0.0351],\n",
      "          [ 0.1193,  0.0524,  0.1659, -0.0296, -0.0502],\n",
      "          [ 0.1663, -0.0829,  0.0802,  0.0151,  0.0469],\n",
      "          [-0.1999, -0.0103,  0.0613,  0.0123,  0.0237],\n",
      "          [ 0.0441, -0.1647,  0.0054, -0.0109,  0.0475]]],\n",
      "\n",
      "\n",
      "        [[[-0.0288,  0.0631,  0.1093,  0.0084, -0.0733],\n",
      "          [-0.0737,  0.1275,  0.1649,  0.0956, -0.0461],\n",
      "          [-0.1760,  0.1198, -0.0044,  0.1557, -0.1791],\n",
      "          [-0.0682,  0.1168, -0.1705,  0.1812, -0.1718],\n",
      "          [-0.0560,  0.0067,  0.0488,  0.1514, -0.0769]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1254, -0.0635,  0.1711,  0.1499, -0.1557],\n",
      "          [-0.2067, -0.1830,  0.0160,  0.1091,  0.0620],\n",
      "          [ 0.1131,  0.0588,  0.0617, -0.0193,  0.1723],\n",
      "          [ 0.1079, -0.1935,  0.0840, -0.0916,  0.0980],\n",
      "          [-0.0945, -0.1760, -0.0594, -0.1139, -0.0994]]]])\n",
      "\n",
      "\n",
      "\n",
      " tensor([ 0.0350, -0.1326, -0.0275, -0.0547, -0.0174,  0.0831, -0.1906, -0.0324])\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.0154, 0.9722, 1.0427, 0.9806, 1.0248, 1.0149, 0.9752, 1.0147])\n",
      "\n",
      "\n",
      "\n",
      " tensor([-0.0358, -0.0018,  0.0248,  0.0270, -0.0040, -0.0379, -0.0325, -0.0327])\n",
      "\n",
      "\n",
      "\n",
      " tensor([ 0.0333, -0.1380, -0.0209, -0.0421, -0.0334,  0.0788, -0.1986, -0.0484])\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.3942, 0.1098, 0.3189, 0.2430, 0.5387, 0.0718, 0.2444, 0.2053])\n",
      "\n",
      "\n",
      "\n",
      " tensor(600)\n",
      "\n",
      "\n",
      "\n",
      " tensor([[[[ 2.8157e-02,  8.2014e-03,  7.8288e-02, -4.2620e-02,  4.0879e-02],\n",
      "          [ 7.7304e-02, -5.1142e-02,  4.3405e-02,  1.0549e-02, -2.1844e-02],\n",
      "          [ 6.3332e-02, -1.1992e-02,  4.2740e-02,  2.9234e-02,  7.3715e-02],\n",
      "          [-5.6554e-02,  6.7516e-02, -2.5270e-02, -5.8050e-02,  6.7592e-02],\n",
      "          [-2.6628e-02, -5.5438e-02, -4.9187e-03,  4.2963e-02,  2.3504e-02]],\n",
      "\n",
      "         [[-5.0160e-02, -1.3025e-02, -6.1277e-03, -4.5795e-02, -2.6317e-02],\n",
      "          [-3.8050e-02,  6.0640e-02,  7.0930e-02, -2.1849e-02,  5.0669e-02],\n",
      "          [-6.2058e-02,  7.1755e-03,  9.8200e-03,  3.1524e-03, -1.5085e-02],\n",
      "          [ 3.6114e-02, -1.1141e-02, -8.5104e-03, -5.3333e-02,  2.3418e-02],\n",
      "          [ 3.7292e-03, -2.2066e-02,  5.2220e-02, -4.5772e-02,  4.2249e-02]],\n",
      "\n",
      "         [[ 5.1512e-02, -4.9022e-02,  1.2324e-02, -2.0046e-02, -2.9359e-02],\n",
      "          [-4.0394e-02, -3.8360e-02,  2.0422e-02,  8.6186e-02, -2.0856e-03],\n",
      "          [ 3.6469e-02,  1.1566e-02,  5.3363e-02, -4.4622e-02, -4.8062e-02],\n",
      "          [-1.9764e-02, -6.5406e-02, -7.4917e-02, -7.1244e-02, -3.6117e-02],\n",
      "          [-3.8997e-02, -5.6777e-02, -2.8603e-02, -1.0640e-02, -1.3319e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7990e-03, -7.1973e-02, -6.1917e-02,  2.5558e-02,  6.0410e-02],\n",
      "          [-3.2560e-02, -6.3254e-02,  1.1596e-02,  5.7669e-02,  3.2880e-02],\n",
      "          [-8.2852e-02,  7.0121e-02,  6.8908e-02,  7.4204e-02,  4.4559e-02],\n",
      "          [-2.0345e-03,  7.4479e-02,  3.1658e-02, -2.0664e-02, -3.9720e-02],\n",
      "          [ 1.2255e-02, -4.5727e-02,  4.3675e-02,  7.3181e-02, -1.6814e-02]],\n",
      "\n",
      "         [[ 3.0149e-02, -1.3008e-02, -5.0450e-02, -3.5616e-02, -6.5504e-02],\n",
      "          [-5.3365e-02, -2.7041e-02, -1.6887e-02,  7.0007e-02,  3.9914e-02],\n",
      "          [-1.3676e-02,  5.4325e-02, -5.4216e-02, -2.9892e-02, -5.6297e-02],\n",
      "          [ 4.4978e-02,  5.6063e-02, -1.9665e-03,  2.5287e-02,  4.2258e-02],\n",
      "          [ 3.7579e-02, -2.1552e-02, -4.4752e-02,  4.6243e-02, -1.0037e-02]],\n",
      "\n",
      "         [[-2.5599e-02, -1.8191e-02, -4.6559e-02,  1.4179e-02,  2.5156e-02],\n",
      "          [-4.2374e-02,  6.0298e-02, -5.0995e-02, -3.4823e-02,  2.5931e-02],\n",
      "          [ 3.7818e-02, -4.3687e-03,  5.5494e-02,  2.5058e-02, -4.1937e-02],\n",
      "          [-3.9983e-02,  5.4667e-02, -7.2482e-02, -6.2563e-02,  2.4686e-02],\n",
      "          [-6.9075e-02, -3.7635e-02, -3.5181e-02,  1.4058e-02, -1.1864e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9268e-02, -4.4580e-02, -2.4580e-02, -4.8051e-02, -2.5653e-02],\n",
      "          [ 5.3610e-02, -4.2699e-02, -2.6116e-02, -6.8550e-03, -1.8404e-02],\n",
      "          [ 8.2763e-02,  2.5312e-02,  1.3796e-02,  4.4871e-02, -3.1190e-02],\n",
      "          [ 8.8935e-02,  4.3653e-02, -4.8915e-02, -4.8382e-02, -1.8554e-02],\n",
      "          [-1.1199e-03,  3.7602e-02,  6.0737e-02, -5.4677e-02, -4.9778e-02]],\n",
      "\n",
      "         [[-9.6223e-04, -5.2067e-03,  2.6623e-02, -4.6206e-02, -7.3181e-02],\n",
      "          [ 4.8813e-02, -1.5230e-02, -4.0792e-02, -9.5205e-03,  3.6495e-03],\n",
      "          [ 8.4478e-02,  1.5147e-03, -4.1984e-02,  3.6905e-02,  4.0903e-02],\n",
      "          [-1.8599e-02,  2.1501e-02,  3.7799e-02, -6.8065e-02,  4.9779e-02],\n",
      "          [ 1.4742e-02,  6.8059e-02,  7.8023e-02, -6.4684e-02,  4.4449e-02]],\n",
      "\n",
      "         [[ 3.2292e-02, -1.0366e-02, -3.6277e-02, -4.7518e-03,  6.6824e-02],\n",
      "          [-1.5015e-02,  8.1158e-03,  4.3197e-02, -6.1192e-02, -1.1651e-02],\n",
      "          [-2.9217e-02,  6.4306e-02, -6.9935e-02,  3.9195e-03,  2.2853e-02],\n",
      "          [-9.2956e-02, -4.0081e-03, -4.0264e-02, -6.2642e-02,  5.4483e-02],\n",
      "          [ 1.8154e-02, -4.8142e-02, -3.2649e-02,  1.7048e-02,  2.1471e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7855e-02,  3.4148e-03,  2.6832e-02,  4.5503e-02,  2.8768e-02],\n",
      "          [-5.3170e-02, -6.6360e-02, -2.4573e-02, -3.0057e-02,  5.5552e-02],\n",
      "          [ 2.8599e-02,  1.3617e-03, -9.6804e-03, -6.0242e-02, -7.6557e-02],\n",
      "          [ 6.1293e-02,  3.6714e-02, -5.8694e-02, -4.3329e-02, -5.9199e-03],\n",
      "          [-2.7813e-02, -2.2292e-02, -4.2274e-02,  2.3339e-03,  2.3290e-02]],\n",
      "\n",
      "         [[-3.7903e-03, -1.4241e-02, -1.6218e-02,  8.1308e-03,  6.5973e-02],\n",
      "          [ 1.3660e-02, -5.0920e-02,  4.7658e-02, -1.3057e-02,  4.8444e-02],\n",
      "          [-1.8830e-02,  3.9997e-02,  6.1922e-02,  5.3650e-02, -9.5132e-03],\n",
      "          [-3.5751e-02,  5.4307e-02,  6.0534e-02,  6.6366e-02, -7.6667e-03],\n",
      "          [ 5.4889e-02,  7.6667e-02,  4.2630e-02,  6.4308e-04,  2.5443e-02]],\n",
      "\n",
      "         [[ 7.6901e-03, -3.6325e-02, -8.7814e-02, -9.6009e-03,  3.0286e-02],\n",
      "          [ 6.1863e-02, -4.3143e-02, -5.5340e-02, -4.3650e-02,  4.0929e-02],\n",
      "          [ 4.4593e-02,  2.4341e-02, -3.5656e-02, -5.5644e-02,  4.9784e-02],\n",
      "          [-6.3070e-02,  2.3868e-02, -1.7722e-02,  5.0272e-02, -5.4404e-02],\n",
      "          [ 6.0363e-03, -7.6730e-02,  7.3569e-02,  1.2558e-03,  5.5023e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6026e-02, -6.5199e-02,  5.8088e-03, -6.6826e-02, -3.7073e-02],\n",
      "          [-5.4401e-02, -6.2921e-02, -6.6876e-02, -8.3458e-02, -4.1234e-02],\n",
      "          [ 8.2842e-03,  4.8171e-02, -2.5007e-02, -7.0413e-02, -2.6839e-02],\n",
      "          [ 2.7844e-02, -1.4511e-02,  4.5650e-02, -2.8385e-03,  4.0442e-02],\n",
      "          [ 2.5370e-02,  7.5749e-02,  6.0006e-02, -6.6521e-02,  1.1843e-02]],\n",
      "\n",
      "         [[ 4.1030e-02,  4.5589e-02, -1.9989e-02,  2.4776e-02,  1.6988e-02],\n",
      "          [-3.2782e-02,  3.3233e-02,  2.4321e-03, -7.2170e-02,  4.1179e-02],\n",
      "          [ 5.6937e-02, -3.1958e-02,  5.8531e-02, -4.0649e-02,  2.2055e-02],\n",
      "          [-1.6842e-02,  6.8286e-02,  6.2036e-02,  5.0220e-02, -9.6881e-03],\n",
      "          [ 2.9673e-02,  3.4195e-02,  6.5587e-02,  5.5660e-02,  1.8361e-02]],\n",
      "\n",
      "         [[-7.9999e-02, -3.0783e-02,  2.9156e-02, -1.1489e-02, -1.2511e-02],\n",
      "          [ 5.0995e-02,  2.5605e-02, -2.0252e-02,  3.7187e-02,  1.2533e-02],\n",
      "          [ 3.2689e-02,  2.3410e-02, -5.2215e-02, -5.7854e-02,  6.5672e-02],\n",
      "          [ 3.3469e-02, -7.7653e-02, -1.5094e-02, -1.5400e-03,  2.2034e-02],\n",
      "          [-3.4072e-02, -3.3200e-02, -5.2598e-02,  3.3936e-02,  1.1955e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0310e-01,  3.8923e-02, -1.5436e-02,  2.8072e-02, -7.8027e-02],\n",
      "          [ 4.2931e-03,  1.9850e-02,  7.5872e-02, -5.6883e-02, -1.5817e-02],\n",
      "          [ 6.5808e-02,  3.0816e-02,  6.8731e-02, -6.9219e-02, -7.6011e-03],\n",
      "          [ 8.1873e-02, -2.9868e-02,  5.1437e-02, -1.6682e-02,  2.4482e-03],\n",
      "          [ 6.1927e-02, -2.4871e-02,  1.9593e-02, -4.9381e-03,  2.9983e-02]],\n",
      "\n",
      "         [[ 2.0773e-02, -2.9670e-02,  5.7586e-02, -7.5842e-03, -1.3395e-02],\n",
      "          [-1.7272e-02, -3.1783e-02, -4.8012e-04, -4.3876e-02, -6.5861e-02],\n",
      "          [ 2.2354e-02,  3.0304e-02,  3.7285e-03,  5.5010e-02,  3.1137e-02],\n",
      "          [-5.2572e-02,  1.2379e-02, -5.0385e-02, -3.2201e-02, -3.9039e-02],\n",
      "          [ 4.0806e-02,  5.9167e-02, -2.9624e-02, -3.6963e-02, -7.9459e-02]],\n",
      "\n",
      "         [[ 4.4014e-02, -1.8895e-02, -2.4372e-02,  7.0986e-02,  9.6207e-02],\n",
      "          [ 3.1427e-02,  9.1956e-02, -1.3987e-02, -1.1737e-02, -5.2521e-02],\n",
      "          [ 2.6341e-02,  1.0567e-01,  4.9237e-02, -1.2276e-02,  4.9825e-02],\n",
      "          [-6.7748e-02,  5.7724e-03,  3.4767e-02,  2.2732e-02, -2.5587e-02],\n",
      "          [ 3.4995e-02, -6.5780e-02, -3.9233e-02, -4.2054e-02, -5.1065e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.5703e-02, -6.2980e-02, -1.2018e-02, -4.8042e-02, -3.4025e-03],\n",
      "          [-1.0895e-02, -1.7827e-02, -2.4474e-03,  5.0443e-02,  7.3084e-02],\n",
      "          [-2.6495e-02, -1.9368e-02,  6.7647e-02, -3.2187e-02, -2.6141e-02],\n",
      "          [ 6.4949e-02, -1.7136e-02,  3.5370e-02, -3.1115e-02,  5.4113e-02],\n",
      "          [ 1.0861e-02,  9.1925e-02,  2.2670e-02,  3.9731e-02, -2.4957e-02]],\n",
      "\n",
      "         [[-5.9759e-02,  6.7369e-02, -5.0640e-02,  3.4410e-02,  5.1262e-02],\n",
      "          [-1.2238e-02, -2.9922e-02,  2.4743e-02,  4.2645e-02, -5.2000e-02],\n",
      "          [ 4.0297e-02, -6.4764e-02, -1.0825e-02,  2.2128e-02, -3.3877e-02],\n",
      "          [-2.4570e-02, -3.5335e-03,  5.8407e-02,  2.3507e-02, -6.6848e-02],\n",
      "          [-3.9688e-02,  1.1652e-02, -7.0678e-02, -8.4593e-03,  2.5407e-02]],\n",
      "\n",
      "         [[ 3.6546e-02,  1.9203e-02, -1.2004e-04, -1.1157e-02, -1.7342e-02],\n",
      "          [ 2.4046e-02, -2.6246e-02,  6.0830e-02,  6.9469e-02, -3.7579e-02],\n",
      "          [ 5.3215e-02,  4.6290e-02, -6.9463e-02, -3.6090e-02,  5.4376e-02],\n",
      "          [ 4.7736e-03, -2.6099e-02, -5.4983e-02,  1.6267e-02,  6.9370e-02],\n",
      "          [ 4.9064e-02,  3.9424e-02,  1.0385e-01,  3.3800e-02, -1.3541e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1426e-02, -6.9922e-02, -7.5616e-02, -4.4432e-02, -4.2341e-02],\n",
      "          [-9.4455e-02, -7.3709e-02, -2.0002e-02,  4.2318e-02,  2.8983e-02],\n",
      "          [-6.2681e-02, -5.4686e-02, -3.9593e-03, -2.3027e-02, -2.9546e-02],\n",
      "          [ 3.0060e-02, -2.9153e-02, -3.2624e-02,  5.0970e-02,  1.5612e-02],\n",
      "          [-1.4102e-02, -2.9572e-02,  4.2450e-02,  6.0503e-03,  9.3735e-03]],\n",
      "\n",
      "         [[ 1.4701e-02, -6.4438e-02, -8.0080e-02, -3.4606e-03,  1.1202e-02],\n",
      "          [-1.0157e-02,  3.6553e-02,  3.7154e-02,  1.2901e-02, -2.0680e-02],\n",
      "          [ 2.3662e-02, -3.3412e-04,  5.1587e-02, -3.1624e-02,  3.6747e-02],\n",
      "          [-7.0191e-02,  5.2180e-02,  3.0323e-02, -5.4709e-02, -3.6808e-02],\n",
      "          [ 2.5593e-02,  2.0471e-02, -2.5138e-02,  3.7507e-02, -1.8220e-02]],\n",
      "\n",
      "         [[ 2.1223e-02, -4.2948e-02, -3.3562e-02,  6.0015e-02, -3.2590e-03],\n",
      "          [-4.7411e-02,  3.7312e-02,  4.9879e-02,  5.1222e-02,  9.6759e-05],\n",
      "          [ 4.0258e-02,  6.3967e-02,  1.3950e-02,  1.0189e-02,  1.0864e-02],\n",
      "          [-3.0687e-02, -5.7823e-02,  7.4566e-03,  4.9672e-02, -5.6072e-02],\n",
      "          [ 3.4355e-02,  3.7818e-02,  1.8612e-03, -6.5981e-02, -3.5664e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2306e-02,  5.2562e-02, -3.5772e-02, -6.6363e-03, -6.7768e-02],\n",
      "          [-4.8976e-02,  5.4436e-02, -1.6296e-02,  2.8253e-02,  4.7348e-02],\n",
      "          [ 8.3550e-02,  8.5209e-02,  4.1737e-02,  6.2411e-02,  7.0245e-02],\n",
      "          [ 7.9746e-02,  3.3943e-02,  3.6916e-02, -2.8253e-02, -2.6084e-02],\n",
      "          [ 9.0157e-02,  8.8243e-02,  8.2687e-02,  6.9296e-02,  3.1394e-02]],\n",
      "\n",
      "         [[ 2.8722e-02,  2.8570e-02, -2.1596e-02,  4.7860e-02,  1.3036e-02],\n",
      "          [ 4.3281e-02, -1.6584e-03,  1.0626e-02, -1.3479e-02, -3.2285e-03],\n",
      "          [ 2.4201e-02,  6.3439e-02,  3.3894e-02,  3.5238e-02, -5.3926e-02],\n",
      "          [ 8.5763e-02, -4.2829e-02, -4.6324e-02,  5.9682e-02, -1.1224e-02],\n",
      "          [-1.2976e-02, -2.8490e-02, -6.6293e-02, -6.5053e-02,  1.6142e-02]],\n",
      "\n",
      "         [[-4.6135e-03, -7.0942e-02, -1.2794e-02,  4.9907e-02,  5.0132e-02],\n",
      "          [-1.8918e-02, -3.7371e-02,  5.1693e-02,  2.1812e-02,  1.0224e-02],\n",
      "          [ 2.9483e-02,  6.7400e-03, -1.0177e-03,  3.2998e-02, -7.3864e-02],\n",
      "          [-3.8987e-02, -6.5529e-02, -5.3090e-02, -6.9993e-02,  2.6883e-02],\n",
      "          [-1.3774e-02, -6.9632e-02, -2.9851e-02,  1.7558e-02, -5.1767e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4546e-04, -7.8227e-02, -3.2342e-02, -2.2749e-02, -2.4907e-02],\n",
      "          [-1.4344e-02, -8.1610e-03, -2.0001e-02, -1.3075e-02, -8.5707e-03],\n",
      "          [-4.9390e-02,  8.3861e-03, -5.8356e-02,  1.4418e-02, -3.0019e-02],\n",
      "          [ 3.8973e-02, -3.0893e-02,  7.4843e-03,  4.8852e-02, -1.1337e-02],\n",
      "          [-5.7117e-02, -6.2551e-02, -4.6001e-02, -6.5235e-02,  5.2470e-02]],\n",
      "\n",
      "         [[ 7.3711e-03,  5.3204e-02, -6.0576e-02, -4.9310e-02,  3.0624e-02],\n",
      "          [ 6.5451e-02,  5.1753e-02,  5.5883e-02,  4.7934e-02, -2.6063e-02],\n",
      "          [-1.0736e-02, -1.4561e-02,  4.4853e-02, -7.7416e-03, -4.9733e-02],\n",
      "          [ 4.8361e-02, -4.9888e-02,  3.8362e-02, -1.2945e-02, -8.5908e-03],\n",
      "          [ 2.1678e-02,  4.4341e-02,  7.7785e-03, -1.3318e-02, -7.0549e-02]],\n",
      "\n",
      "         [[ 8.1615e-03, -2.7304e-02, -2.0323e-02, -6.4915e-03, -1.3450e-02],\n",
      "          [ 3.1261e-02, -4.1916e-03, -5.1495e-02,  2.0023e-02,  4.0453e-02],\n",
      "          [ 6.6383e-02,  6.6343e-02,  1.4812e-03, -8.0872e-03, -5.4298e-02],\n",
      "          [-2.1599e-02, -2.5501e-02, -4.9391e-02,  4.4954e-02,  8.9253e-02],\n",
      "          [-3.8394e-03, -5.6663e-02, -2.9223e-02,  3.7992e-03,  2.5896e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6533e-03, -1.7368e-02,  7.1405e-02, -5.8599e-02,  3.1660e-02],\n",
      "          [ 4.9155e-02,  4.3603e-02,  1.8281e-02,  3.2269e-02, -6.9137e-02],\n",
      "          [ 1.0125e-02, -1.0794e-02,  2.0055e-02, -4.9853e-02,  6.1031e-02],\n",
      "          [-5.8183e-02, -6.4522e-02, -6.1886e-02, -6.4589e-02, -2.7510e-02],\n",
      "          [ 3.0275e-02, -3.5819e-02,  5.5745e-03,  3.8176e-02, -5.3684e-03]],\n",
      "\n",
      "         [[ 7.5323e-02,  4.9427e-02,  1.6008e-02, -1.9758e-02,  4.1415e-02],\n",
      "          [-7.6851e-02,  9.1975e-02, -4.5082e-02,  4.7854e-02, -8.3226e-03],\n",
      "          [-2.9328e-02, -3.3928e-02, -3.3475e-02, -6.8303e-02, -8.9052e-02],\n",
      "          [-4.1372e-02, -6.6365e-02,  2.4394e-02, -5.3550e-02, -4.4893e-03],\n",
      "          [ 2.7653e-02, -2.9377e-02, -5.3508e-02,  8.3980e-03, -7.7861e-02]],\n",
      "\n",
      "         [[ 9.2106e-02,  1.2519e-02, -4.4742e-02, -7.8175e-02, -6.8805e-02],\n",
      "          [ 3.6720e-02,  6.6410e-02,  7.0050e-02,  1.0061e-02,  9.5531e-03],\n",
      "          [-1.0124e-02,  6.7421e-03,  1.6676e-03,  4.0084e-02, -1.7719e-02],\n",
      "          [-6.9414e-02,  6.5200e-03,  7.7859e-02,  5.6851e-02, -6.0683e-02],\n",
      "          [-3.3557e-02, -3.9880e-02, -2.4469e-02,  7.9512e-02,  1.1638e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1047e-02,  4.1326e-02, -3.1115e-02, -1.8005e-02, -5.6183e-02],\n",
      "          [-6.6544e-02, -5.0931e-02,  5.8831e-02,  3.5082e-02, -5.4934e-02],\n",
      "          [-5.2044e-02, -6.6200e-02, -7.8081e-02,  4.8571e-02, -2.3913e-02],\n",
      "          [ 2.0561e-02, -6.5195e-02,  4.5288e-02,  7.9118e-03,  6.3372e-02],\n",
      "          [-5.5260e-03,  9.6534e-02,  9.2644e-02,  6.0380e-02,  3.2357e-03]],\n",
      "\n",
      "         [[ 2.9542e-02, -5.0752e-02,  4.4217e-02,  4.4065e-02, -7.6716e-03],\n",
      "          [-2.2575e-02, -1.9300e-02, -4.9870e-02,  7.7514e-03, -6.2043e-02],\n",
      "          [ 2.5182e-02, -2.6724e-02, -1.0473e-02, -6.6240e-02,  2.9456e-02],\n",
      "          [-4.6584e-02, -2.8334e-02, -3.0228e-02,  2.0344e-02,  4.4433e-03],\n",
      "          [ 3.6647e-02, -1.0290e-02,  3.2544e-02, -1.8674e-02,  1.6640e-02]],\n",
      "\n",
      "         [[-5.2662e-02,  3.7944e-02, -2.2871e-02, -4.2190e-02,  3.1280e-02],\n",
      "          [ 4.6265e-02,  3.4575e-02,  4.5516e-02,  3.2705e-02, -6.3784e-02],\n",
      "          [ 7.4107e-02,  2.6279e-02,  4.5307e-02,  7.3255e-02,  6.7465e-02],\n",
      "          [ 7.0150e-02,  5.3218e-02, -3.3609e-02,  3.8518e-02, -1.4291e-02],\n",
      "          [ 8.2230e-03,  3.6739e-02, -6.5059e-02,  6.1938e-02,  6.3641e-02]]]])\n",
      "\n",
      "\n",
      "\n",
      " tensor([ 0.0671,  0.0269, -0.0520, -0.0689, -0.0666,  0.0851, -0.0252,  0.0119,\n",
      "         0.0054,  0.1117, -0.0428,  0.0082,  0.0180, -0.0114,  0.0462, -0.0546])\n",
      "\n",
      "\n",
      "\n",
      " tensor([1.0565, 1.1070, 1.1040, 1.0591, 1.1021, 1.1031, 1.0856, 1.0674, 1.1211,\n",
      "        1.0950, 1.1101, 1.0745, 1.0846, 1.1296, 1.0763, 1.1173])\n",
      "\n",
      "\n",
      "\n",
      " tensor([-0.0128,  0.0053, -0.0272,  0.0096,  0.0013, -0.0327, -0.0126, -0.0210,\n",
      "         0.0343, -0.0133,  0.0045, -0.0103, -0.0024, -0.0069, -0.0002, -0.0061])\n",
      "\n",
      "\n",
      "\n",
      " tensor([-0.0154,  0.0241, -0.0561,  0.5937, -0.0160, -0.1857, -0.2833, -0.1950,\n",
      "        -0.0935,  0.1008, -0.3284,  0.2166,  0.2790, -0.0840,  0.0210, -0.0283])\n",
      "\n",
      "\n",
      "\n",
      " tensor([0.0504, 0.1054, 0.0863, 0.1923, 0.0823, 0.0868, 0.0834, 0.1335, 0.1958,\n",
      "        0.0656, 0.1112, 0.1090, 0.2401, 0.1928, 0.2765, 0.1776])\n",
      "\n",
      "\n",
      "\n",
      " tensor(600)\n",
      "\n",
      "\n",
      "\n",
      " tensor([[ 0.0056,  0.0052, -0.0032,  ..., -0.0080,  0.0010,  0.0020],\n",
      "        [ 0.0030,  0.0100,  0.0063,  ..., -0.0154, -0.0049, -0.0059],\n",
      "        [ 0.0035,  0.0026, -0.0087,  ..., -0.0170, -0.0122,  0.0114],\n",
      "        ...,\n",
      "        [ 0.0068,  0.0111,  0.0038,  ..., -0.0313, -0.0138, -0.0074],\n",
      "        [-0.0096, -0.0075, -0.0021,  ...,  0.0105, -0.0099, -0.0158],\n",
      "        [-0.0017,  0.0041,  0.0058,  ...,  0.0336,  0.0118,  0.0120]])\n",
      "\n",
      "\n",
      "\n",
      " tensor([-0.0023,  0.0117,  0.0031, -0.0014, -0.0018, -0.0007,  0.0018,  0.0028,\n",
      "        -0.0069, -0.0062])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(\"\\n\\n\\n\",  model.state_dict()[param_tensor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_layer1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_layer1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5, padding=2), #1 * 28 * 28 -> 8 * 28 * 28\n",
    "            nn.BatchNorm2d(8),                         #8 * 28 * 28\n",
    "            nn.ReLU())                                 #8 * 28 * 28\n",
    "        \n",
    "        self.layer2  = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=5, padding=2), # 8 * 28 * 28 -> 16 * 28* 28\n",
    "            nn.BatchNorm2d(16),                         #16 * 28 * 28\n",
    "            nn.ReLU())                                  #16 * 28 * 28\n",
    "        \n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_layer2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_layer2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5, padding=2), #1 * 28 * 28 -> 8 * 28 * 28\n",
    "            nn.BatchNorm2d(8),                         #8 * 28 * 28\n",
    "            nn.ReLU())                                 #8 * 28 * 28\n",
    "            #nn.MaxPool2d(2))       \n",
    "        \n",
    "        self.layer2  = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=5, padding=2), # 8 * 28 * 28 -> 16 * 28* 28\n",
    "            nn.BatchNorm2d(16),                         #16 * 28 * 28\n",
    "            nn.ReLU())                                  #16 * 28 * 28\n",
    "        \n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "PATH = './model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_layer2(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=12544, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = CNN_layer1()\n",
    "layer1.load_state_dict(torch.load(PATH))\n",
    "layer1.eval()\n",
    "\n",
    "layer2 = CNN_layer2()\n",
    "layer2.load_state_dict(torch.load(PATH))\n",
    "layer2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1's state_dict:\n",
      "layer1.0.weight \t torch.Size([8, 1, 5, 5])\n",
      "layer1.0.bias \t torch.Size([8])\n",
      "layer1.1.weight \t torch.Size([8])\n",
      "layer1.1.bias \t torch.Size([8])\n",
      "layer1.1.running_mean \t torch.Size([8])\n",
      "layer1.1.running_var \t torch.Size([8])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([16, 8, 5, 5])\n",
      "layer2.0.bias \t torch.Size([16])\n",
      "layer2.1.weight \t torch.Size([16])\n",
      "layer2.1.bias \t torch.Size([16])\n",
      "layer2.1.running_mean \t torch.Size([16])\n",
      "layer2.1.running_var \t torch.Size([16])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([10, 12544])\n",
      "fc.bias \t torch.Size([10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer1's state_dict:\")\n",
    "\n",
    "for param_tensor in layer1.state_dict():\n",
    "    print(param_tensor, \"\\t\", layer1.state_dict()[param_tensor].size())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2's state_dict:\n",
      "layer1.0.weight \t torch.Size([8, 1, 5, 5])\n",
      "layer1.0.bias \t torch.Size([8])\n",
      "layer1.1.weight \t torch.Size([8])\n",
      "layer1.1.bias \t torch.Size([8])\n",
      "layer1.1.running_mean \t torch.Size([8])\n",
      "layer1.1.running_var \t torch.Size([8])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([16, 8, 5, 5])\n",
      "layer2.0.bias \t torch.Size([16])\n",
      "layer2.1.weight \t torch.Size([16])\n",
      "layer2.1.bias \t torch.Size([16])\n",
      "layer2.1.running_mean \t torch.Size([16])\n",
      "layer2.1.running_var \t torch.Size([16])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([10, 12544])\n",
      "fc.bias \t torch.Size([10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer2's state_dict:\")\n",
    "\n",
    "for param_tensor in layer1.state_dict():\n",
    "    print(param_tensor, \"\\t\", layer1.state_dict()[param_tensor].size())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0350, -0.1326, -0.0275, -0.0547, -0.0174,  0.0831, -0.1906, -0.0324])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['layer1.0.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See pictures layer after layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True)\n",
    "x,y = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28]) torch.Size([28, 28]) torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4d2c8bd250>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs1 = layer1(x)\n",
    "outputs1.size()\n",
    "\n",
    "outputs2 = layer2(x)\n",
    "outputs2.size()\n",
    "\n",
    "image = x[0][0]\n",
    "image.size()\n",
    "\n",
    "image1 = outputs1[0][0]\n",
    "image2 = outputs2[0][0]\n",
    "\n",
    "image1.detach().numpy()\n",
    "image2.detach().numpy()\n",
    "\n",
    "print(image.size(), image1.size(), image2.size())\n",
    "\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4d2c8084c0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image2.detach().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
