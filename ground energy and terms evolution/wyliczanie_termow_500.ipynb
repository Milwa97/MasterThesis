{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib_linear import *\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read diagonalized iinput-input, input-output and output-output matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_input_matrix = np.array(pd.read_csv('input_input_matrix.csv'))\n",
    "output_input_matrix = np.array(pd.read_csv('output_input_matrix.csv'))\n",
    "output_output_matrix = np.array(pd.read_csv('output_output_matrix.csv'))\n",
    "\n",
    "V_matrix = np.array(pd.read_csv('V_matrix.csv'))\n",
    "U_matrix = np.array(pd.read_csv('U_matrix.csv'))\n",
    "S31_matrix = np.array(pd.read_csv('S_matrix.csv'))  ##actually, just diag values\n",
    "\n",
    "S11_matrix = V_matrix.T @ input_input_matrix @ V_matrix\n",
    "S33_matrix = output_output_matrix\n",
    "\n",
    "S_improved  = pd.read_csv('500/S_improved.csv')\n",
    "S11_improved = np.array(S_improved['S11'])\n",
    "S31_improved = np.array(S_improved['S31'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = calculate_mean_and_std()\n",
    "train_data, test_data =  download_normalized_data(mean, std)\n",
    "\n",
    "batch_size: int = 1000\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNetwork(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple D-layer linear neural network \n",
    "    hidden_dims = topule(n0, n1, n2, ...nD)\n",
    "    n0 = input layer\n",
    "    n_D = output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, D, layers_dim):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize network's weights according to Gaussian iid and network's biases with 0.0 values\n",
    "        \"\"\"\n",
    "        \n",
    "        self.weights = []\n",
    "        self.D = len(layers_dim)-1\n",
    "        assert self.D == D\n",
    "                \n",
    "        for i in range(self.D):\n",
    "            weight: torch.Tensor = torch.rand((layers_dim[i+1], layers_dim[i])) \n",
    "            stdv = 2/ np.sqrt(layers_dim[i])\n",
    "            weight = (weight-0.5)*stdv\n",
    "            weight.requires_grad = True\n",
    "            self.weights.append(weight)\n",
    "    \n",
    "            \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        for i in range(0,self.D):            \n",
    "            x = torch.nn.functional.linear( input = x, weight=self.weights[i])\n",
    "        return x \n",
    "    \n",
    "    \n",
    "    def parameters(self) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns all trainable parameters \n",
    "        \"\"\"\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "output_dim = 10\n",
    "hidden_dim1 = 500\n",
    "D = 2\n",
    "model: CustomNetwork = CustomNetwork(D = D, layers_dim = (input_dim, hidden_dim1, output_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer using the hyperparams below\n",
    "lr: float = 0.005\n",
    "momentum: float = 0.00\n",
    "optimizer: torch.optim.Optimizer = SGD(params = model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss() \n",
    "epoch: int = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_I_tab=[]\n",
    "term_II_tab = []\n",
    "term_IV_tab = []\n",
    "\n",
    "term_I_star_tab=[]\n",
    "term_II_star_tab = []\n",
    "term_IV_star_tab = []\n",
    "\n",
    "term_I_diamond_tab=[]\n",
    "term_II_diamond_tab = []\n",
    "term_IV_diamond_tab = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss = 0.09245636314153671 test acc 0.4139\n",
      "1 loss = 0.07271570712327957 test acc 0.5857\n",
      "2 loss = 0.06393024325370789 test acc 0.6635\n",
      "3 loss = 0.058814600110054016 test acc 0.7089\n",
      "4 loss = 0.05543902516365051 test acc 0.7362\n",
      "5 loss = 0.05304073914885521 test acc 0.7559\n",
      "6 loss = 0.0512472540140152 test acc 0.7713\n",
      "7 loss = 0.04985293373465538 test acc 0.7822\n",
      "8 loss = 0.04873499274253845 test acc 0.7923\n",
      "9 loss = 0.04781583696603775 test acc 0.7989\n",
      "10 loss = 0.047044262290000916 test acc 0.805\n",
      "11 loss = 0.046385277062654495 test acc 0.8096\n",
      "12 loss = 0.04581420123577118 test acc 0.8124\n",
      "13 loss = 0.04531317576766014 test acc 0.816\n",
      "14 loss = 0.04486894607543945 test acc 0.8187\n",
      "15 loss = 0.04447147995233536 test acc 0.8222\n",
      "16 loss = 0.04411303624510765 test acc 0.825\n",
      "17 loss = 0.04378754645586014 test acc 0.8277\n",
      "18 loss = 0.04349015653133392 test acc 0.8294\n",
      "19 loss = 0.043216973543167114 test acc 0.8309\n",
      "20 loss = 0.04296479374170303 test acc 0.8319\n",
      "21 loss = 0.042730994522571564 test acc 0.8335\n",
      "22 loss = 0.042513374239206314 test acc 0.8357\n",
      "23 loss = 0.04231008514761925 test acc 0.8367\n",
      "24 loss = 0.04211956635117531 test acc 0.8371\n",
      "25 loss = 0.04194047302007675 test acc 0.8382\n",
      "26 loss = 0.04177166894078255 test acc 0.8397\n",
      "27 loss = 0.04161214455962181 test acc 0.8401\n",
      "28 loss = 0.041461050510406494 test acc 0.8413\n",
      "29 loss = 0.04131763428449631 test acc 0.8428\n",
      "30 loss = 0.04118121787905693 test acc 0.8432\n",
      "31 loss = 0.0410512313246727 test acc 0.8439\n",
      "32 loss = 0.04092714563012123 test acc 0.8447\n",
      "33 loss = 0.040808502584695816 test acc 0.8465\n",
      "34 loss = 0.04069489613175392 test acc 0.847\n",
      "35 loss = 0.0405859500169754 test acc 0.8475\n",
      "36 loss = 0.0404813326895237 test acc 0.8482\n",
      "37 loss = 0.040380749851465225 test acc 0.8485\n",
      "38 loss = 0.0402839332818985 test acc 0.8488\n",
      "39 loss = 0.04019062966108322 test acc 0.8491\n",
      "40 loss = 0.04010062292218208 test acc 0.8496\n",
      "41 loss = 0.04001370817422867 test acc 0.8497\n",
      "42 loss = 0.039929695427417755 test acc 0.8503\n",
      "43 loss = 0.039848413318395615 test acc 0.8509\n",
      "44 loss = 0.03976971283555031 test acc 0.8516\n",
      "45 loss = 0.0396934449672699 test acc 0.8518\n",
      "46 loss = 0.03961948677897453 test acc 0.8519\n",
      "47 loss = 0.03954770043492317 test acc 0.8528\n",
      "48 loss = 0.03947797790169716 test acc 0.8536\n",
      "49 loss = 0.03941022604703903 test acc 0.8535\n",
      "50 loss = 0.03934432938694954 test acc 0.8538\n",
      "51 loss = 0.03928021341562271 test acc 0.8538\n",
      "52 loss = 0.03921778127551079 test acc 0.8535\n",
      "53 loss = 0.0391569659113884 test acc 0.8535\n",
      "54 loss = 0.039097681641578674 test acc 0.8539\n",
      "55 loss = 0.03903987258672714 test acc 0.8543\n",
      "56 loss = 0.03898346424102783 test acc 0.8546\n",
      "57 loss = 0.03892839699983597 test acc 0.8546\n",
      "58 loss = 0.03887462243437767 test acc 0.8548\n",
      "59 loss = 0.03882208094000816 test acc 0.8552\n",
      "60 loss = 0.03877072036266327 test acc 0.8555\n",
      "61 loss = 0.03872050344944 test acc 0.856\n",
      "62 loss = 0.03867137432098389 test acc 0.8562\n",
      "63 loss = 0.038623299449682236 test acc 0.8561\n",
      "64 loss = 0.03857623413205147 test acc 0.8563\n",
      "65 loss = 0.0385301448404789 test acc 0.8566\n",
      "66 loss = 0.03848499804735184 test acc 0.8566\n",
      "67 loss = 0.03844074532389641 test acc 0.8566\n",
      "68 loss = 0.03839737921953201 test acc 0.857\n",
      "69 loss = 0.03835484758019447 test acc 0.8573\n",
      "70 loss = 0.038313135504722595 test acc 0.8576\n",
      "71 loss = 0.038272205740213394 test acc 0.8576\n",
      "72 loss = 0.03823203593492508 test acc 0.8579\n",
      "73 loss = 0.03819260746240616 test acc 0.8581\n",
      "74 loss = 0.038153886795043945 test acc 0.8582\n",
      "75 loss = 0.038115862756967545 test acc 0.8588\n",
      "76 loss = 0.03807850182056427 test acc 0.8587\n",
      "77 loss = 0.03804178908467293 test acc 0.8588\n",
      "78 loss = 0.038005709648132324 test acc 0.8591\n",
      "79 loss = 0.03797024115920067 test acc 0.8597\n",
      "80 loss = 0.03793536126613617 test acc 0.8601\n",
      "81 loss = 0.037901055067777634 test acc 0.8602\n",
      "82 loss = 0.037867311388254166 test acc 0.8603\n",
      "83 loss = 0.037834107875823975 test acc 0.8604\n",
      "84 loss = 0.037801437079906464 test acc 0.8605\n",
      "85 loss = 0.03776927664875984 test acc 0.8606\n",
      "86 loss = 0.037737611681222916 test acc 0.8608\n",
      "87 loss = 0.03770644590258598 test acc 0.861\n",
      "88 loss = 0.03767574578523636 test acc 0.8611\n",
      "89 loss = 0.03764550760388374 test acc 0.8609\n",
      "90 loss = 0.03761571645736694 test acc 0.8609\n",
      "91 loss = 0.03758637234568596 test acc 0.8611\n",
      "92 loss = 0.0375574491918087 test acc 0.861\n",
      "93 loss = 0.03752893581986427 test acc 0.8608\n",
      "94 loss = 0.03750084340572357 test acc 0.8611\n",
      "95 loss = 0.03747313469648361 test acc 0.861\n",
      "96 loss = 0.03744582086801529 test acc 0.8608\n",
      "97 loss = 0.03741888329386711 test acc 0.8612\n",
      "98 loss = 0.03739231452345848 test acc 0.861\n",
      "99 loss = 0.0373661071062088 test acc 0.861\n",
      "100 loss = 0.037340253591537476 test acc 0.8612\n",
      "101 loss = 0.03731473907828331 test acc 0.8612\n",
      "102 loss = 0.0372895672917366 test acc 0.8612\n",
      "103 loss = 0.03726472333073616 test acc 0.8614\n",
      "104 loss = 0.037240199744701385 test acc 0.8615\n",
      "105 loss = 0.03721599280834198 test acc 0.8614\n",
      "106 loss = 0.037192098796367645 test acc 0.8613\n",
      "107 loss = 0.03716849908232689 test acc 0.8612\n",
      "108 loss = 0.03714520111680031 test acc 0.8613\n",
      "109 loss = 0.03712218627333641 test acc 0.8613\n",
      "110 loss = 0.03709946200251579 test acc 0.8611\n",
      "111 loss = 0.03707700967788696 test acc 0.8612\n",
      "112 loss = 0.03705483302474022 test acc 0.8614\n",
      "113 loss = 0.037032924592494965 test acc 0.8617\n",
      "114 loss = 0.0370112769305706 test acc 0.8619\n",
      "115 loss = 0.036989882588386536 test acc 0.8618\n",
      "116 loss = 0.03696874529123306 test acc 0.862\n",
      "117 loss = 0.03694785013794899 test acc 0.8622\n",
      "118 loss = 0.03692719712853432 test acc 0.8621\n",
      "119 loss = 0.036906782537698746 test acc 0.8621\n",
      "120 loss = 0.03688659518957138 test acc 0.8621\n",
      "121 loss = 0.03686664253473282 test acc 0.8622\n",
      "122 loss = 0.036846913397312164 test acc 0.8624\n",
      "123 loss = 0.03682740405201912 test acc 0.8626\n",
      "124 loss = 0.03680810704827309 test acc 0.8625\n",
      "125 loss = 0.03678903356194496 test acc 0.8625\n",
      "126 loss = 0.036770161241292953 test acc 0.8623\n",
      "127 loss = 0.03675149381160736 test acc 0.8624\n",
      "128 loss = 0.03673302382230759 test acc 0.8622\n",
      "129 loss = 0.03671475872397423 test acc 0.8621\n",
      "130 loss = 0.03669668361544609 test acc 0.862\n",
      "131 loss = 0.03667880594730377 test acc 0.8622\n",
      "132 loss = 0.03666110709309578 test acc 0.8621\n",
      "133 loss = 0.03664359822869301 test acc 0.8621\n",
      "134 loss = 0.03662627562880516 test acc 0.8618\n",
      "135 loss = 0.03660912439227104 test acc 0.862\n",
      "136 loss = 0.03659215569496155 test acc 0.8619\n",
      "137 loss = 0.03657535836100578 test acc 0.8619\n",
      "138 loss = 0.03655872121453285 test acc 0.862\n",
      "139 loss = 0.03654225915670395 test acc 0.8621\n",
      "140 loss = 0.03652596473693848 test acc 0.8621\n",
      "141 loss = 0.03650982305407524 test acc 0.8619\n",
      "142 loss = 0.036493849009275436 test acc 0.862\n",
      "143 loss = 0.03647803142666817 test acc 0.862\n",
      "144 loss = 0.036462366580963135 test acc 0.8621\n",
      "145 loss = 0.03644685819745064 test acc 0.8622\n",
      "146 loss = 0.03643149510025978 test acc 0.8622\n",
      "147 loss = 0.036416273564100266 test acc 0.8623\n",
      "148 loss = 0.036401212215423584 test acc 0.8623\n",
      "149 loss = 0.03638628125190735 test acc 0.8623\n",
      "150 loss = 0.03637149557471275 test acc 0.8622\n",
      "151 loss = 0.0363568477332592 test acc 0.8623\n",
      "152 loss = 0.03634233772754669 test acc 0.8621\n",
      "153 loss = 0.036327965557575226 test acc 0.8622\n",
      "154 loss = 0.036313727498054504 test acc 0.8623\n",
      "155 loss = 0.03629961237311363 test acc 0.8623\n",
      "156 loss = 0.036285631358623505 test acc 0.8623\n",
      "157 loss = 0.03627178445458412 test acc 0.8622\n",
      "158 loss = 0.03625805675983429 test acc 0.8619\n",
      "159 loss = 0.03624445199966431 test acc 0.8619\n",
      "160 loss = 0.036230966448783875 test acc 0.8621\n",
      "161 loss = 0.03621760383248329 test acc 0.8623\n",
      "162 loss = 0.03620436042547226 test acc 0.8623\n",
      "163 loss = 0.03619123622775078 test acc 0.8623\n",
      "164 loss = 0.03617822751402855 test acc 0.8625\n",
      "165 loss = 0.036165330559015274 test acc 0.8623\n",
      "166 loss = 0.03615254536271095 test acc 0.8622\n",
      "167 loss = 0.036139871925115585 test acc 0.8622\n",
      "168 loss = 0.03612730652093887 test acc 0.8622\n",
      "169 loss = 0.03611484915018082 test acc 0.8622\n",
      "170 loss = 0.036102503538131714 test acc 0.8625\n",
      "171 loss = 0.03609025850892067 test acc 0.8626\n",
      "172 loss = 0.036078114062547684 test acc 0.8626\n",
      "173 loss = 0.03606608137488365 test acc 0.8627\n",
      "174 loss = 0.03605414181947708 test acc 0.8626\n",
      "175 loss = 0.03604230657219887 test acc 0.8626\n",
      "176 loss = 0.036030568182468414 test acc 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 loss = 0.03601892665028572 test acc 0.8626\n",
      "178 loss = 0.03600737825036049 test acc 0.8626\n",
      "179 loss = 0.035995930433273315 test acc 0.8626\n",
      "180 loss = 0.035984572023153305 test acc 0.8627\n",
      "181 loss = 0.035973306745290756 test acc 0.8627\n",
      "182 loss = 0.03596213459968567 test acc 0.8626\n",
      "183 loss = 0.03595105558633804 test acc 0.8627\n",
      "184 loss = 0.03594006225466728 test acc 0.8627\n",
      "185 loss = 0.035929158329963684 test acc 0.8628\n",
      "186 loss = 0.03591833636164665 test acc 0.8627\n",
      "187 loss = 0.03590760752558708 test acc 0.8627\n",
      "188 loss = 0.03589696064591408 test acc 0.8628\n",
      "189 loss = 0.03588639572262764 test acc 0.8628\n",
      "190 loss = 0.035875916481018066 test acc 0.8627\n",
      "191 loss = 0.03586551919579506 test acc 0.8629\n",
      "192 loss = 0.03585520014166832 test acc 0.8629\n",
      "193 loss = 0.035844963043928146 test acc 0.8629\n",
      "194 loss = 0.03583480045199394 test acc 0.8629\n",
      "195 loss = 0.035824719816446304 test acc 0.8629\n",
      "196 loss = 0.035814717411994934 test acc 0.8629\n",
      "197 loss = 0.03580478951334953 test acc 0.8629\n",
      "198 loss = 0.0357949398458004 test acc 0.863\n",
      "199 loss = 0.03578516095876694 test acc 0.8632\n",
      "200 loss = 0.035775456577539444 test acc 0.863\n",
      "201 loss = 0.03576582670211792 test acc 0.8629\n",
      "202 loss = 0.035756275057792664 test acc 0.863\n",
      "203 loss = 0.03574678674340248 test acc 0.8631\n",
      "204 loss = 0.03573736920952797 test acc 0.8631\n",
      "205 loss = 0.03572802245616913 test acc 0.8631\n",
      "206 loss = 0.03571873903274536 test acc 0.8632\n",
      "207 loss = 0.03570953384041786 test acc 0.8631\n",
      "208 loss = 0.035700391978025436 test acc 0.8631\n",
      "209 loss = 0.03569132089614868 test acc 0.8631\n",
      "210 loss = 0.035682313144207 test acc 0.8633\n",
      "211 loss = 0.035673364996910095 test acc 0.8633\n",
      "212 loss = 0.03566448763012886 test acc 0.8633\n",
      "213 loss = 0.0356556661427021 test acc 0.8634\n",
      "214 loss = 0.035646919161081314 test acc 0.8634\n",
      "215 loss = 0.0356382317841053 test acc 0.8636\n",
      "216 loss = 0.035629600286483765 test acc 0.8635\n",
      "217 loss = 0.0356210358440876 test acc 0.8634\n",
      "218 loss = 0.03561253100633621 test acc 0.8633\n",
      "219 loss = 0.0356040857732296 test acc 0.8633\n",
      "220 loss = 0.03559569641947746 test acc 0.8633\n",
      "221 loss = 0.0355873666703701 test acc 0.8633\n",
      "222 loss = 0.035579100251197815 test acc 0.8633\n",
      "223 loss = 0.035570885986089706 test acc 0.8633\n",
      "224 loss = 0.03556273505091667 test acc 0.8634\n",
      "225 loss = 0.03555463254451752 test acc 0.8634\n",
      "226 loss = 0.03554658964276314 test acc 0.8634\n",
      "227 loss = 0.035538602620363235 test acc 0.8635\n",
      "228 loss = 0.03553067147731781 test acc 0.8635\n",
      "229 loss = 0.035522788763046265 test acc 0.8635\n",
      "230 loss = 0.035514961928129196 test acc 0.8636\n",
      "231 loss = 0.035507190972566605 test acc 0.8637\n",
      "232 loss = 0.03549947589635849 test acc 0.8637\n",
      "233 loss = 0.03549180179834366 test acc 0.8637\n",
      "234 loss = 0.0354841873049736 test acc 0.8636\n",
      "235 loss = 0.035476621240377426 test acc 0.8635\n",
      "236 loss = 0.03546910360455513 test acc 0.8635\n",
      "237 loss = 0.03546163812279701 test acc 0.8635\n",
      "238 loss = 0.03545422479510307 test acc 0.8636\n",
      "239 loss = 0.035446859896183014 test acc 0.8637\n",
      "240 loss = 0.035439539700746536 test acc 0.8637\n",
      "241 loss = 0.03543226793408394 test acc 0.8636\n",
      "242 loss = 0.03542504459619522 test acc 0.8636\n",
      "243 loss = 0.03541786968708038 test acc 0.8635\n",
      "244 loss = 0.03541073948144913 test acc 0.8634\n",
      "245 loss = 0.03540365770459175 test acc 0.8633\n",
      "246 loss = 0.03539662063121796 test acc 0.8633\n",
      "247 loss = 0.035389624536037445 test acc 0.8634\n",
      "248 loss = 0.03538268432021141 test acc 0.8635\n",
      "249 loss = 0.03537578135728836 test acc 0.8634\n",
      "250 loss = 0.035368919372558594 test acc 0.8635\n",
      "251 loss = 0.03536210581660271 test acc 0.8634\n",
      "252 loss = 0.0353553369641304 test acc 0.8634\n",
      "253 loss = 0.03534860908985138 test acc 0.8633\n",
      "254 loss = 0.03534192591905594 test acc 0.8632\n",
      "255 loss = 0.03533528000116348 test acc 0.8632\n",
      "256 loss = 0.03532867878675461 test acc 0.8631\n",
      "257 loss = 0.03532211855053902 test acc 0.863\n",
      "258 loss = 0.03531559929251671 test acc 0.863\n",
      "259 loss = 0.035309117287397385 test acc 0.863\n",
      "260 loss = 0.03530268371105194 test acc 0.863\n",
      "261 loss = 0.03529628366231918 test acc 0.8629\n",
      "262 loss = 0.03528992459177971 test acc 0.863\n",
      "263 loss = 0.03528360277414322 test acc 0.8629\n",
      "264 loss = 0.03527732193470001 test acc 0.8627\n",
      "265 loss = 0.03527107834815979 test acc 0.8627\n",
      "266 loss = 0.03526487573981285 test acc 0.8626\n",
      "267 loss = 0.035258710384368896 test acc 0.8625\n",
      "268 loss = 0.03525258228182793 test acc 0.8625\n",
      "269 loss = 0.03524649143218994 test acc 0.8625\n",
      "270 loss = 0.035240430384874344 test acc 0.8628\n",
      "271 loss = 0.03523441031575203 test acc 0.8627\n",
      "272 loss = 0.035228431224823 test acc 0.8626\n",
      "273 loss = 0.035222478210926056 test acc 0.8627\n",
      "274 loss = 0.035216569900512695 test acc 0.8627\n",
      "275 loss = 0.03521069511771202 test acc 0.8627\n",
      "276 loss = 0.03520485386252403 test acc 0.8627\n",
      "277 loss = 0.03519904986023903 test acc 0.8627\n",
      "278 loss = 0.03519327566027641 test acc 0.8625\n",
      "279 loss = 0.03518753498792648 test acc 0.8626\n",
      "280 loss = 0.03518183156847954 test acc 0.8625\n",
      "281 loss = 0.03517615795135498 test acc 0.8625\n",
      "282 loss = 0.035170525312423706 test acc 0.8626\n",
      "283 loss = 0.03516491875052452 test acc 0.8625\n",
      "284 loss = 0.03515934571623802 test acc 0.8625\n",
      "285 loss = 0.03515380993485451 test acc 0.8623\n",
      "286 loss = 0.03514830023050308 test acc 0.8625\n",
      "287 loss = 0.03514282405376434 test acc 0.8625\n",
      "288 loss = 0.03513737767934799 test acc 0.8624\n",
      "289 loss = 0.03513196483254433 test acc 0.8623\n",
      "290 loss = 0.03512658551335335 test acc 0.8623\n",
      "291 loss = 0.03512123227119446 test acc 0.8623\n",
      "292 loss = 0.035115912556648254 test acc 0.8623\n",
      "293 loss = 0.03511062264442444 test acc 0.8623\n",
      "294 loss = 0.03510535880923271 test acc 0.8624\n",
      "295 loss = 0.03510013222694397 test acc 0.8624\n",
      "296 loss = 0.035094935446977615 test acc 0.8622\n",
      "297 loss = 0.035089753568172455 test acc 0.8621\n",
      "298 loss = 0.035084620118141174 test acc 0.8621\n",
      "299 loss = 0.03507949784398079 test acc 0.862\n",
      "300 loss = 0.035074420273303986 test acc 0.862\n",
      "301 loss = 0.035069357603788376 test acc 0.8621\n",
      "302 loss = 0.03506433218717575 test acc 0.8619\n",
      "303 loss = 0.035059332847595215 test acc 0.862\n",
      "304 loss = 0.03505435958504677 test acc 0.8622\n",
      "305 loss = 0.03504941239953041 test acc 0.8624\n",
      "306 loss = 0.03504449501633644 test acc 0.8624\n",
      "307 loss = 0.03503959998488426 test acc 0.8624\n",
      "308 loss = 0.03503473848104477 test acc 0.8623\n",
      "309 loss = 0.03502989560365677 test acc 0.8624\n",
      "310 loss = 0.03502508997917175 test acc 0.8624\n",
      "311 loss = 0.03502030298113823 test acc 0.8625\n",
      "312 loss = 0.035015545785427094 test acc 0.8625\n",
      "313 loss = 0.03501081094145775 test acc 0.8625\n",
      "314 loss = 0.03500610217452049 test acc 0.8625\n",
      "315 loss = 0.035001423209905624 test acc 0.8624\n",
      "316 loss = 0.03499676287174225 test acc 0.8623\n",
      "317 loss = 0.03499212861061096 test acc 0.8622\n",
      "318 loss = 0.03498752415180206 test acc 0.8622\n",
      "319 loss = 0.034982942044734955 test acc 0.8622\n",
      "320 loss = 0.03497838228940964 test acc 0.8623\n",
      "321 loss = 0.03497384861111641 test acc 0.8622\n",
      "322 loss = 0.03496933728456497 test acc 0.8622\n",
      "323 loss = 0.034964852035045624 test acc 0.8623\n",
      "324 loss = 0.034960392862558365 test acc 0.8623\n",
      "325 loss = 0.0349559523165226 test acc 0.8623\n",
      "326 loss = 0.034951530396938324 test acc 0.8623\n",
      "327 loss = 0.034947145730257034 test acc 0.8623\n",
      "328 loss = 0.03494277596473694 test acc 0.8623\n",
      "329 loss = 0.03493842855095863 test acc 0.8623\n",
      "330 loss = 0.034934110939502716 test acc 0.8624\n",
      "331 loss = 0.034929804503917694 test acc 0.8624\n",
      "332 loss = 0.03492552787065506 test acc 0.8623\n",
      "333 loss = 0.034921273589134216 test acc 0.8622\n",
      "334 loss = 0.03491703420877457 test acc 0.8623\n",
      "335 loss = 0.0349128283560276 test acc 0.8623\n",
      "336 loss = 0.034908633679151535 test acc 0.8623\n",
      "337 loss = 0.034904465079307556 test acc 0.8623\n",
      "338 loss = 0.03490031883120537 test acc 0.8623\n",
      "339 loss = 0.034896183758974075 test acc 0.8623\n",
      "340 loss = 0.03489208593964577 test acc 0.8622\n",
      "341 loss = 0.034887999296188354 test acc 0.8623\n",
      "342 loss = 0.03488393872976303 test acc 0.8624\n",
      "343 loss = 0.0348798930644989 test acc 0.8624\n",
      "344 loss = 0.03487586975097656 test acc 0.8624\n",
      "345 loss = 0.034871865063905716 test acc 0.8623\n",
      "346 loss = 0.03486788645386696 test acc 0.8625\n",
      "347 loss = 0.034863926470279694 test acc 0.8625\n",
      "348 loss = 0.03485998138785362 test acc 0.8626\n",
      "349 loss = 0.03485606238245964 test acc 0.8626\n",
      "350 loss = 0.03485215827822685 test acc 0.8627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 loss = 0.03484827280044556 test acc 0.8627\n",
      "352 loss = 0.03484440967440605 test acc 0.8627\n",
      "353 loss = 0.03484056144952774 test acc 0.8627\n",
      "354 loss = 0.03483673557639122 test acc 0.8626\n",
      "355 loss = 0.03483292832970619 test acc 0.8625\n",
      "356 loss = 0.034829143434762955 test acc 0.8625\n",
      "357 loss = 0.03482537344098091 test acc 0.8625\n",
      "358 loss = 0.03482162952423096 test acc 0.8625\n",
      "359 loss = 0.0348178893327713 test acc 0.8625\n",
      "360 loss = 0.03481417894363403 test acc 0.8625\n",
      "361 loss = 0.03481047973036766 test acc 0.8625\n",
      "362 loss = 0.03480680286884308 test acc 0.8627\n",
      "363 loss = 0.03480314090847969 test acc 0.8627\n",
      "364 loss = 0.03479950129985809 test acc 0.8627\n",
      "365 loss = 0.03479587286710739 test acc 0.8627\n",
      "366 loss = 0.03479226678609848 test acc 0.8627\n",
      "367 loss = 0.03478867933154106 test acc 0.8625\n",
      "368 loss = 0.03478510305285454 test acc 0.8625\n",
      "369 loss = 0.034781549125909805 test acc 0.8626\n",
      "370 loss = 0.034778013825416565 test acc 0.8626\n",
      "371 loss = 0.03477448970079422 test acc 0.8626\n",
      "372 loss = 0.03477098420262337 test acc 0.8626\n",
      "373 loss = 0.03476749733090401 test acc 0.8626\n",
      "374 loss = 0.03476402536034584 test acc 0.8626\n",
      "375 loss = 0.034760575741529465 test acc 0.8625\n",
      "376 loss = 0.034757133573293686 test acc 0.8625\n",
      "377 loss = 0.0347537100315094 test acc 0.8625\n",
      "378 loss = 0.034750305116176605 test acc 0.8625\n",
      "379 loss = 0.0347469225525856 test acc 0.8625\n",
      "380 loss = 0.0347435437142849 test acc 0.8625\n",
      "381 loss = 0.03474018722772598 test acc 0.8625\n",
      "382 loss = 0.034736841917037964 test acc 0.8626\n",
      "383 loss = 0.034733518958091736 test acc 0.8626\n",
      "384 loss = 0.034730203449726105 test acc 0.8626\n",
      "385 loss = 0.034726910293102264 test acc 0.8626\n",
      "386 loss = 0.03472362831234932 test acc 0.8625\n",
      "387 loss = 0.034720368683338165 test acc 0.8625\n",
      "388 loss = 0.03471711277961731 test acc 0.8624\n",
      "389 loss = 0.03471388295292854 test acc 0.8624\n",
      "390 loss = 0.034710660576820374 test acc 0.8624\n",
      "391 loss = 0.0347074531018734 test acc 0.8624\n",
      "392 loss = 0.034704264253377914 test acc 0.8625\n",
      "393 loss = 0.034701086580753326 test acc 0.8625\n",
      "394 loss = 0.03469792753458023 test acc 0.8626\n",
      "395 loss = 0.03469477966427803 test acc 0.8626\n",
      "396 loss = 0.03469165042042732 test acc 0.8626\n",
      "397 loss = 0.03468852862715721 test acc 0.8626\n",
      "398 loss = 0.03468542546033859 test acc 0.8625\n",
      "399 loss = 0.03468233719468117 test acc 0.8625\n",
      "400 loss = 0.03467926010489464 test acc 0.8626\n",
      "401 loss = 0.034676194190979004 test acc 0.8626\n",
      "402 loss = 0.03467315062880516 test acc 0.8624\n",
      "403 loss = 0.03467011824250221 test acc 0.8624\n",
      "404 loss = 0.03466709703207016 test acc 0.8624\n",
      "405 loss = 0.0346640907227993 test acc 0.8623\n",
      "406 loss = 0.03466109558939934 test acc 0.8623\n",
      "407 loss = 0.03465811535716057 test acc 0.8624\n",
      "408 loss = 0.03465515002608299 test acc 0.8624\n",
      "409 loss = 0.03465219587087631 test acc 0.8624\n",
      "410 loss = 0.034649256616830826 test acc 0.8625\n",
      "411 loss = 0.034646324813365936 test acc 0.8624\n",
      "412 loss = 0.03464340791106224 test acc 0.8624\n",
      "413 loss = 0.03464050963521004 test acc 0.8625\n",
      "414 loss = 0.03463761880993843 test acc 0.8626\n",
      "415 loss = 0.03463474288582802 test acc 0.8626\n",
      "416 loss = 0.0346318818628788 test acc 0.8626\n",
      "417 loss = 0.034629032015800476 test acc 0.8626\n",
      "418 loss = 0.03462618961930275 test acc 0.8626\n",
      "419 loss = 0.034623365849256516 test acc 0.8626\n",
      "420 loss = 0.03462054952979088 test acc 0.8626\n",
      "421 loss = 0.034617748111486435 test acc 0.8626\n",
      "422 loss = 0.03461495786905289 test acc 0.8627\n",
      "423 loss = 0.034612178802490234 test acc 0.8627\n",
      "424 loss = 0.034609414637088776 test acc 0.8627\n",
      "425 loss = 0.03460666537284851 test acc 0.8627\n",
      "426 loss = 0.03460392355918884 test acc 0.8627\n",
      "427 loss = 0.03460119664669037 test acc 0.8627\n",
      "428 loss = 0.03459848091006279 test acc 0.8627\n",
      "429 loss = 0.03459577634930611 test acc 0.8627\n",
      "430 loss = 0.03459307923913002 test acc 0.8627\n",
      "431 loss = 0.03459039703011513 test acc 0.8627\n",
      "432 loss = 0.03458772227168083 test acc 0.8627\n",
      "433 loss = 0.03458506241440773 test acc 0.8627\n",
      "434 loss = 0.03458241745829582 test acc 0.8627\n",
      "435 loss = 0.03457977995276451 test acc 0.8627\n",
      "436 loss = 0.0345771498978138 test acc 0.8626\n",
      "437 loss = 0.034574538469314575 test acc 0.8626\n",
      "438 loss = 0.03457193449139595 test acc 0.8626\n",
      "439 loss = 0.03456933796405792 test acc 0.8627\n",
      "440 loss = 0.03456676006317139 test acc 0.8626\n",
      "441 loss = 0.03456418588757515 test acc 0.8626\n",
      "442 loss = 0.034561626613140106 test acc 0.8626\n",
      "443 loss = 0.03455907851457596 test acc 0.8626\n",
      "444 loss = 0.03455653786659241 test acc 0.8626\n",
      "445 loss = 0.03455400839447975 test acc 0.8626\n",
      "446 loss = 0.03455149382352829 test acc 0.8625\n",
      "447 loss = 0.034548986703157425 test acc 0.8625\n",
      "448 loss = 0.03454648703336716 test acc 0.8625\n",
      "449 loss = 0.034543998539447784 test acc 0.8625\n",
      "450 loss = 0.034541524946689606 test acc 0.8625\n",
      "451 loss = 0.03453906252980232 test acc 0.8625\n",
      "452 loss = 0.034536607563495636 test acc 0.8626\n",
      "453 loss = 0.034534160047769547 test acc 0.8626\n",
      "454 loss = 0.03453172370791435 test acc 0.8626\n",
      "455 loss = 0.034529298543930054 test acc 0.8626\n",
      "456 loss = 0.03452688455581665 test acc 0.8626\n",
      "457 loss = 0.03452448174357414 test acc 0.8626\n",
      "458 loss = 0.03452208638191223 test acc 0.8626\n",
      "459 loss = 0.03451969847083092 test acc 0.8626\n",
      "460 loss = 0.0345173217356205 test acc 0.8626\n",
      "461 loss = 0.03451495245099068 test acc 0.8626\n",
      "462 loss = 0.03451259806752205 test acc 0.8625\n",
      "463 loss = 0.03451025113463402 test acc 0.8624\n",
      "464 loss = 0.034507911652326584 test acc 0.8624\n",
      "465 loss = 0.034505587071180344 test acc 0.8624\n",
      "466 loss = 0.0345032699406147 test acc 0.8625\n",
      "467 loss = 0.034500956535339355 test acc 0.8626\n",
      "468 loss = 0.034498658031225204 test acc 0.8626\n",
      "469 loss = 0.03449636697769165 test acc 0.8625\n",
      "470 loss = 0.03449409082531929 test acc 0.8625\n",
      "471 loss = 0.03449181094765663 test acc 0.8625\n",
      "472 loss = 0.034489553421735764 test acc 0.8625\n",
      "473 loss = 0.034487295895814896 test acc 0.8625\n",
      "474 loss = 0.03448504954576492 test acc 0.8625\n",
      "475 loss = 0.03448281064629555 test acc 0.8626\n",
      "476 loss = 0.034480586647987366 test acc 0.8626\n",
      "477 loss = 0.03447837010025978 test acc 0.8626\n",
      "478 loss = 0.034476157277822495 test acc 0.8626\n",
      "479 loss = 0.034473951905965805 test acc 0.8626\n",
      "480 loss = 0.03447176516056061 test acc 0.8626\n",
      "481 loss = 0.03446957841515541 test acc 0.8626\n",
      "482 loss = 0.03446740284562111 test acc 0.8627\n",
      "483 loss = 0.034465242177248 test acc 0.8627\n",
      "484 loss = 0.03446308150887489 test acc 0.8627\n",
      "485 loss = 0.03446093574166298 test acc 0.8627\n",
      "486 loss = 0.034458789974451065 test acc 0.8627\n",
      "487 loss = 0.034456659108400345 test acc 0.8627\n",
      "488 loss = 0.034454528242349625 test acc 0.8627\n",
      "489 loss = 0.0344524122774601 test acc 0.8626\n",
      "490 loss = 0.03445030376315117 test acc 0.8626\n",
      "491 loss = 0.034448206424713135 test acc 0.8627\n",
      "492 loss = 0.0344461165368557 test acc 0.8627\n",
      "493 loss = 0.03444403037428856 test acc 0.8627\n",
      "494 loss = 0.034441955387592316 test acc 0.8627\n",
      "495 loss = 0.03443988785147667 test acc 0.8627\n",
      "496 loss = 0.03443782776594162 test acc 0.8627\n",
      "497 loss = 0.03443577513098717 test acc 0.8627\n",
      "498 loss = 0.03443372994661331 test acc 0.8627\n",
      "499 loss = 0.03443169966340065 test acc 0.8627\n",
      "500 loss = 0.03442966938018799 test acc 0.8627\n",
      "501 loss = 0.03442765027284622 test acc 0.8627\n",
      "502 loss = 0.034425634890794754 test acc 0.8627\n",
      "503 loss = 0.03442363440990448 test acc 0.8627\n",
      "504 loss = 0.034421637654304504 test acc 0.8627\n",
      "505 loss = 0.03441964462399483 test acc 0.8628\n",
      "506 loss = 0.034417662769556046 test acc 0.8627\n",
      "507 loss = 0.03441568464040756 test acc 0.8627\n",
      "508 loss = 0.03441372141242027 test acc 0.8627\n",
      "509 loss = 0.03441176190972328 test acc 0.8625\n",
      "510 loss = 0.03440980985760689 test acc 0.8625\n",
      "511 loss = 0.03440786898136139 test acc 0.8625\n",
      "512 loss = 0.03440592437982559 test acc 0.8625\n",
      "513 loss = 0.03440399095416069 test acc 0.8625\n",
      "514 loss = 0.03440207615494728 test acc 0.8625\n",
      "515 loss = 0.03440015763044357 test acc 0.8623\n",
      "516 loss = 0.03439825028181076 test acc 0.8623\n",
      "517 loss = 0.03439634293317795 test acc 0.8623\n",
      "518 loss = 0.03439445048570633 test acc 0.8623\n",
      "519 loss = 0.03439256176352501 test acc 0.8623\n",
      "520 loss = 0.034390684217214584 test acc 0.8624\n",
      "521 loss = 0.03438881039619446 test acc 0.8624\n",
      "522 loss = 0.03438694030046463 test acc 0.8624\n",
      "523 loss = 0.0343850813806057 test acc 0.8624\n",
      "524 loss = 0.03438322991132736 test acc 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 loss = 0.03438138589262962 test acc 0.8624\n",
      "526 loss = 0.03437954559922218 test acc 0.8624\n",
      "527 loss = 0.03437771275639534 test acc 0.8624\n",
      "528 loss = 0.034375883638858795 test acc 0.8624\n",
      "529 loss = 0.034374065697193146 test acc 0.8624\n",
      "530 loss = 0.03437225520610809 test acc 0.8623\n",
      "531 loss = 0.03437044844031334 test acc 0.8622\n",
      "532 loss = 0.03436865285038948 test acc 0.8621\n",
      "533 loss = 0.03436685726046562 test acc 0.8621\n",
      "534 loss = 0.03436506912112236 test acc 0.8622\n",
      "535 loss = 0.034363292157649994 test acc 0.8622\n",
      "536 loss = 0.034361518919467926 test acc 0.8622\n",
      "537 loss = 0.03435974940657616 test acc 0.8622\n",
      "538 loss = 0.03435799106955528 test acc 0.8621\n",
      "539 loss = 0.034356240183115005 test acc 0.8621\n",
      "540 loss = 0.03435449302196503 test acc 0.8621\n",
      "541 loss = 0.03435274958610535 test acc 0.8622\n",
      "542 loss = 0.03435101732611656 test acc 0.8622\n",
      "543 loss = 0.03434928506612778 test acc 0.8622\n",
      "544 loss = 0.03434756398200989 test acc 0.8622\n",
      "545 loss = 0.034345850348472595 test acc 0.8622\n",
      "546 loss = 0.0343441367149353 test acc 0.8622\n",
      "547 loss = 0.03434243053197861 test acc 0.8622\n",
      "548 loss = 0.03434073179960251 test acc 0.8622\n",
      "549 loss = 0.034339044243097305 test acc 0.8622\n",
      "550 loss = 0.0343373566865921 test acc 0.8621\n",
      "551 loss = 0.034335676580667496 test acc 0.8621\n",
      "552 loss = 0.03433400020003319 test acc 0.8621\n",
      "553 loss = 0.034332334995269775 test acc 0.8621\n",
      "554 loss = 0.03433066979050636 test acc 0.8621\n",
      "555 loss = 0.03432901203632355 test acc 0.8621\n",
      "556 loss = 0.03432736545801163 test acc 0.862\n",
      "557 loss = 0.03432571887969971 test acc 0.862\n",
      "558 loss = 0.034324079751968384 test acc 0.862\n",
      "559 loss = 0.03432244807481766 test acc 0.862\n",
      "560 loss = 0.03432082012295723 test acc 0.862\n",
      "561 loss = 0.0343192033469677 test acc 0.862\n",
      "562 loss = 0.034317582845687866 test acc 0.862\n",
      "563 loss = 0.03431597352027893 test acc 0.862\n",
      "564 loss = 0.034314367920160294 test acc 0.862\n",
      "565 loss = 0.03431276977062225 test acc 0.8619\n",
      "566 loss = 0.03431117534637451 test acc 0.8619\n",
      "567 loss = 0.03430958837270737 test acc 0.8618\n",
      "568 loss = 0.03430800139904022 test acc 0.8618\n",
      "569 loss = 0.03430642560124397 test acc 0.8618\n",
      "570 loss = 0.03430485352873802 test acc 0.8618\n",
      "571 loss = 0.03430328890681267 test acc 0.8618\n",
      "572 loss = 0.03430172801017761 test acc 0.8618\n",
      "573 loss = 0.034300174564123154 test acc 0.8617\n",
      "574 loss = 0.034298624843358994 test acc 0.8617\n",
      "575 loss = 0.03429707884788513 test acc 0.8617\n",
      "576 loss = 0.03429554030299187 test acc 0.8617\n",
      "577 loss = 0.0342940054833889 test acc 0.8617\n",
      "578 loss = 0.03429247811436653 test acc 0.8617\n",
      "579 loss = 0.03429095447063446 test acc 0.8617\n",
      "580 loss = 0.03428943455219269 test acc 0.8617\n",
      "581 loss = 0.03428792208433151 test acc 0.8617\n",
      "582 loss = 0.034286417067050934 test acc 0.8617\n",
      "583 loss = 0.034284912049770355 test acc 0.8616\n",
      "584 loss = 0.034283414483070374 test acc 0.8615\n",
      "585 loss = 0.03428192064166069 test acc 0.8615\n",
      "586 loss = 0.034280430525541306 test acc 0.8616\n",
      "587 loss = 0.03427894786000252 test acc 0.8616\n",
      "588 loss = 0.03427746891975403 test acc 0.8615\n",
      "589 loss = 0.034275997430086136 test acc 0.8615\n",
      "590 loss = 0.03427452966570854 test acc 0.8615\n",
      "591 loss = 0.034273065626621246 test acc 0.8615\n",
      "592 loss = 0.034271612763404846 test acc 0.8615\n",
      "593 loss = 0.03427015617489815 test acc 0.8615\n",
      "594 loss = 0.034268710762262344 test acc 0.8615\n",
      "595 loss = 0.03426726534962654 test acc 0.8614\n",
      "596 loss = 0.034265827387571335 test acc 0.8615\n",
      "597 loss = 0.034264396876096725 test acc 0.8615\n",
      "598 loss = 0.03426296263933182 test acc 0.8615\n",
      "599 loss = 0.034261543303728104 test acc 0.8615\n",
      "600 loss = 0.03426012024283409 test acc 0.8615\n",
      "601 loss = 0.034258704632520676 test acc 0.8616\n",
      "602 loss = 0.03425729647278786 test acc 0.8616\n",
      "603 loss = 0.03425588831305504 test acc 0.8616\n",
      "604 loss = 0.034254491329193115 test acc 0.8616\n",
      "605 loss = 0.034253090620040894 test acc 0.8615\n",
      "606 loss = 0.03425170108675957 test acc 0.8614\n",
      "607 loss = 0.03425031527876854 test acc 0.8614\n",
      "608 loss = 0.03424893319606781 test acc 0.8614\n",
      "609 loss = 0.03424755856394768 test acc 0.8614\n",
      "610 loss = 0.034246183931827545 test acc 0.8614\n",
      "611 loss = 0.03424481675028801 test acc 0.8615\n",
      "612 loss = 0.034243449568748474 test acc 0.8614\n",
      "613 loss = 0.034242089837789536 test acc 0.8614\n",
      "614 loss = 0.034240737557411194 test acc 0.8613\n",
      "615 loss = 0.03423938527703285 test acc 0.8613\n",
      "616 loss = 0.03423804044723511 test acc 0.8613\n",
      "617 loss = 0.03423669561743736 test acc 0.8613\n",
      "618 loss = 0.03423536196351051 test acc 0.8613\n",
      "619 loss = 0.034234028309583664 test acc 0.8615\n",
      "620 loss = 0.03423269838094711 test acc 0.8616\n",
      "621 loss = 0.03423137217760086 test acc 0.8616\n",
      "622 loss = 0.034230053424835205 test acc 0.8616\n",
      "623 loss = 0.03422873467206955 test acc 0.8616\n",
      "624 loss = 0.03422742709517479 test acc 0.8616\n",
      "625 loss = 0.03422611579298973 test acc 0.8616\n",
      "626 loss = 0.03422481194138527 test acc 0.8616\n",
      "627 loss = 0.034223511815071106 test acc 0.8616\n",
      "628 loss = 0.03422221541404724 test acc 0.8616\n",
      "629 loss = 0.03422092646360397 test acc 0.8616\n",
      "630 loss = 0.03421963378787041 test acc 0.8616\n",
      "631 loss = 0.034218352288007736 test acc 0.8616\n",
      "632 loss = 0.03421708196401596 test acc 0.8616\n",
      "633 loss = 0.03421580418944359 test acc 0.8616\n",
      "634 loss = 0.03421453386545181 test acc 0.8615\n",
      "635 loss = 0.03421326354146004 test acc 0.8615\n",
      "636 loss = 0.03421200439333916 test acc 0.8615\n",
      "637 loss = 0.03421074524521828 test acc 0.8615\n",
      "638 loss = 0.034209489822387695 test acc 0.8614\n",
      "639 loss = 0.03420823812484741 test acc 0.8614\n",
      "640 loss = 0.034206993877887726 test acc 0.8614\n",
      "641 loss = 0.03420575335621834 test acc 0.8614\n",
      "642 loss = 0.03420450910925865 test acc 0.8614\n",
      "643 loss = 0.03420327603816986 test acc 0.8614\n",
      "644 loss = 0.03420204296708107 test acc 0.8613\n",
      "645 loss = 0.034200817346572876 test acc 0.8613\n",
      "646 loss = 0.03419959172606468 test acc 0.8613\n",
      "647 loss = 0.03419837728142738 test acc 0.8613\n",
      "648 loss = 0.034197159111499786 test acc 0.8613\n",
      "649 loss = 0.034195948392152786 test acc 0.8614\n",
      "650 loss = 0.034194737672805786 test acc 0.8614\n",
      "651 loss = 0.03419353440403938 test acc 0.8614\n",
      "652 loss = 0.03419233486056328 test acc 0.8616\n",
      "653 loss = 0.03419113531708717 test acc 0.8616\n",
      "654 loss = 0.034189943224191666 test acc 0.8616\n",
      "655 loss = 0.034188754856586456 test acc 0.8616\n",
      "656 loss = 0.03418756648898125 test acc 0.8616\n",
      "657 loss = 0.03418638929724693 test acc 0.8616\n",
      "658 loss = 0.03418520838022232 test acc 0.8617\n",
      "659 loss = 0.034184034913778305 test acc 0.8617\n",
      "660 loss = 0.03418286144733429 test acc 0.8617\n",
      "661 loss = 0.03418169543147087 test acc 0.8617\n",
      "662 loss = 0.03418053314089775 test acc 0.8617\n",
      "663 loss = 0.03417937085032463 test acc 0.8616\n",
      "664 loss = 0.03417821601033211 test acc 0.8616\n",
      "665 loss = 0.034177061170339584 test acc 0.8616\n",
      "666 loss = 0.03417591378092766 test acc 0.8617\n",
      "667 loss = 0.03417476639151573 test acc 0.8617\n",
      "668 loss = 0.0341736264526844 test acc 0.8617\n",
      "669 loss = 0.034172482788562775 test acc 0.8618\n",
      "670 loss = 0.03417135030031204 test acc 0.8617\n",
      "671 loss = 0.03417021408677101 test acc 0.8617\n",
      "672 loss = 0.03416908532381058 test acc 0.8617\n",
      "673 loss = 0.03416796401143074 test acc 0.8617\n",
      "674 loss = 0.0341668426990509 test acc 0.8616\n",
      "675 loss = 0.034165721386671066 test acc 0.8616\n",
      "676 loss = 0.034164607524871826 test acc 0.8616\n",
      "677 loss = 0.034163493663072586 test acc 0.8616\n",
      "678 loss = 0.034162383526563644 test acc 0.8616\n",
      "679 loss = 0.0341612808406353 test acc 0.8615\n",
      "680 loss = 0.034160174429416656 test acc 0.8615\n",
      "681 loss = 0.03415907919406891 test acc 0.8616\n",
      "682 loss = 0.03415798395872116 test acc 0.8617\n",
      "683 loss = 0.03415689244866371 test acc 0.8617\n",
      "684 loss = 0.03415580466389656 test acc 0.8617\n",
      "685 loss = 0.03415471315383911 test acc 0.8617\n",
      "686 loss = 0.034153636544942856 test acc 0.8617\n",
      "687 loss = 0.0341525562107563 test acc 0.8617\n",
      "688 loss = 0.034151483327150345 test acc 0.8617\n",
      "689 loss = 0.03415040671825409 test acc 0.8617\n",
      "690 loss = 0.03414933383464813 test acc 0.8618\n",
      "691 loss = 0.03414826840162277 test acc 0.8618\n",
      "692 loss = 0.03414720669388771 test acc 0.8618\n",
      "693 loss = 0.03414614871144295 test acc 0.8617\n",
      "694 loss = 0.03414509445428848 test acc 0.8617\n",
      "695 loss = 0.03414403647184372 test acc 0.8617\n",
      "696 loss = 0.03414298593997955 test acc 0.8617\n",
      "697 loss = 0.034141942858695984 test acc 0.8617\n",
      "698 loss = 0.034140899777412415 test acc 0.8617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 loss = 0.034139856696128845 test acc 0.8617\n",
      "700 loss = 0.03413882106542587 test acc 0.8617\n",
      "701 loss = 0.0341377854347229 test acc 0.8618\n",
      "702 loss = 0.034136753529310226 test acc 0.8618\n",
      "703 loss = 0.03413572534918785 test acc 0.8619\n",
      "704 loss = 0.034134697169065475 test acc 0.8619\n",
      "705 loss = 0.0341336764395237 test acc 0.862\n",
      "706 loss = 0.03413265198469162 test acc 0.862\n",
      "707 loss = 0.03413163870573044 test acc 0.862\n",
      "708 loss = 0.03413062542676926 test acc 0.862\n",
      "709 loss = 0.034129612147808075 test acc 0.862\n",
      "710 loss = 0.03412860631942749 test acc 0.862\n",
      "711 loss = 0.034127600491046906 test acc 0.862\n",
      "712 loss = 0.03412659466266632 test acc 0.862\n",
      "713 loss = 0.03412559628486633 test acc 0.862\n",
      "714 loss = 0.034124601632356644 test acc 0.862\n",
      "715 loss = 0.034123606979846954 test acc 0.862\n",
      "716 loss = 0.034122616052627563 test acc 0.862\n",
      "717 loss = 0.03412162885069847 test acc 0.8619\n",
      "718 loss = 0.03412064164876938 test acc 0.8619\n",
      "719 loss = 0.03411966189742088 test acc 0.8619\n",
      "720 loss = 0.03411867842078209 test acc 0.8619\n",
      "721 loss = 0.03411770612001419 test acc 0.8619\n",
      "722 loss = 0.03411673754453659 test acc 0.8619\n",
      "723 loss = 0.034115761518478394 test acc 0.8619\n",
      "724 loss = 0.03411479666829109 test acc 0.8619\n",
      "725 loss = 0.03411383181810379 test acc 0.8619\n",
      "726 loss = 0.03411286696791649 test acc 0.8619\n",
      "727 loss = 0.034111909568309784 test acc 0.8619\n",
      "728 loss = 0.03411095216870308 test acc 0.8618\n",
      "729 loss = 0.03410999849438667 test acc 0.8618\n",
      "730 loss = 0.034109048545360565 test acc 0.8618\n",
      "731 loss = 0.03410809487104416 test acc 0.8618\n",
      "732 loss = 0.03410714864730835 test acc 0.8618\n",
      "733 loss = 0.03410620614886284 test acc 0.8619\n",
      "734 loss = 0.034105267375707626 test acc 0.8619\n",
      "735 loss = 0.034104328602552414 test acc 0.8619\n",
      "736 loss = 0.0341033898293972 test acc 0.8619\n",
      "737 loss = 0.034102458506822586 test acc 0.8619\n",
      "738 loss = 0.03410152718424797 test acc 0.8619\n",
      "739 loss = 0.034100599586963654 test acc 0.8619\n",
      "740 loss = 0.034099675714969635 test acc 0.8619\n",
      "741 loss = 0.034098751842975616 test acc 0.8619\n",
      "742 loss = 0.034097831696271896 test acc 0.8619\n",
      "743 loss = 0.034096915274858475 test acc 0.8619\n",
      "744 loss = 0.03409599885344505 test acc 0.8619\n",
      "745 loss = 0.03409508615732193 test acc 0.8618\n",
      "746 loss = 0.034094180911779404 test acc 0.8618\n",
      "747 loss = 0.03409327566623688 test acc 0.8618\n",
      "748 loss = 0.03409236669540405 test acc 0.8618\n",
      "749 loss = 0.034091465175151825 test acc 0.8618\n",
      "750 loss = 0.034090567380189896 test acc 0.8619\n",
      "751 loss = 0.034089669585227966 test acc 0.862\n",
      "752 loss = 0.034088779240846634 test acc 0.8619\n",
      "753 loss = 0.034087885171175 test acc 0.8619\n",
      "754 loss = 0.03408699482679367 test acc 0.8619\n",
      "755 loss = 0.03408610820770264 test acc 0.8619\n",
      "756 loss = 0.0340852215886116 test acc 0.8619\n",
      "757 loss = 0.034084342420101166 test acc 0.8618\n",
      "758 loss = 0.03408345952630043 test acc 0.8618\n",
      "759 loss = 0.03408258035778999 test acc 0.8618\n",
      "760 loss = 0.03408170863986015 test acc 0.8618\n",
      "761 loss = 0.034080833196640015 test acc 0.8618\n",
      "762 loss = 0.034079961478710175 test acc 0.8618\n",
      "763 loss = 0.03407909721136093 test acc 0.8617\n",
      "764 loss = 0.03407822921872139 test acc 0.8616\n",
      "765 loss = 0.03407736495137215 test acc 0.8616\n",
      "766 loss = 0.0340765081346035 test acc 0.8615\n",
      "767 loss = 0.034075647592544556 test acc 0.8615\n",
      "768 loss = 0.03407479077577591 test acc 0.8615\n",
      "769 loss = 0.03407393768429756 test acc 0.8615\n",
      "770 loss = 0.03407308831810951 test acc 0.8615\n",
      "771 loss = 0.034072235226631165 test acc 0.8615\n",
      "772 loss = 0.034071389585733414 test acc 0.8615\n",
      "773 loss = 0.03407054767012596 test acc 0.8615\n",
      "774 loss = 0.03406970202922821 test acc 0.8615\n",
      "775 loss = 0.03406886011362076 test acc 0.8615\n",
      "776 loss = 0.0340680256485939 test acc 0.8615\n",
      "777 loss = 0.03406718745827675 test acc 0.8615\n",
      "778 loss = 0.03406635299324989 test acc 0.8615\n",
      "779 loss = 0.034065525978803635 test acc 0.8615\n",
      "780 loss = 0.034064698964357376 test acc 0.8615\n",
      "781 loss = 0.03406387194991112 test acc 0.8616\n",
      "782 loss = 0.03406304493546486 test acc 0.8616\n",
      "783 loss = 0.034062229096889496 test acc 0.8615\n",
      "784 loss = 0.034061405807733536 test acc 0.8615\n",
      "785 loss = 0.03406059369444847 test acc 0.8615\n",
      "786 loss = 0.03405977413058281 test acc 0.8614\n",
      "787 loss = 0.034058962017297745 test acc 0.8614\n",
      "788 loss = 0.03405814990401268 test acc 0.8614\n",
      "789 loss = 0.034057337790727615 test acc 0.8614\n",
      "790 loss = 0.034056536853313446 test acc 0.8614\n",
      "791 loss = 0.03405573219060898 test acc 0.8614\n",
      "792 loss = 0.03405492752790451 test acc 0.8614\n",
      "793 loss = 0.03405413031578064 test acc 0.8612\n",
      "794 loss = 0.03405332937836647 test acc 0.8612\n",
      "795 loss = 0.0340525321662426 test acc 0.8612\n",
      "796 loss = 0.03405173867940903 test acc 0.8611\n",
      "797 loss = 0.034050945192575455 test acc 0.8611\n",
      "798 loss = 0.03405015543103218 test acc 0.8611\n",
      "799 loss = 0.034049373120069504 test acc 0.8611\n",
      "800 loss = 0.03404858708381653 test acc 0.8611\n",
      "801 loss = 0.03404780104756355 test acc 0.8611\n",
      "802 loss = 0.034047022461891174 test acc 0.8611\n",
      "803 loss = 0.0340462401509285 test acc 0.8611\n",
      "804 loss = 0.03404546529054642 test acc 0.8611\n",
      "805 loss = 0.03404469043016434 test acc 0.8611\n",
      "806 loss = 0.03404391556978226 test acc 0.8611\n",
      "807 loss = 0.034043148159980774 test acc 0.8611\n",
      "808 loss = 0.03404237702488899 test acc 0.8611\n",
      "809 loss = 0.03404160961508751 test acc 0.8611\n",
      "810 loss = 0.034040845930576324 test acc 0.861\n",
      "811 loss = 0.03404008224606514 test acc 0.861\n",
      "812 loss = 0.03403932601213455 test acc 0.861\n",
      "813 loss = 0.034038566052913666 test acc 0.861\n",
      "814 loss = 0.03403780981898308 test acc 0.861\n",
      "815 loss = 0.03403705358505249 test acc 0.861\n",
      "816 loss = 0.0340363010764122 test acc 0.861\n",
      "817 loss = 0.03403554856777191 test acc 0.861\n",
      "818 loss = 0.03403479978442192 test acc 0.8611\n",
      "819 loss = 0.03403405100107193 test acc 0.8611\n",
      "820 loss = 0.03403330594301224 test acc 0.861\n",
      "821 loss = 0.03403256833553314 test acc 0.861\n",
      "822 loss = 0.03403182327747345 test acc 0.861\n",
      "823 loss = 0.034031085669994354 test acc 0.861\n",
      "824 loss = 0.03403034806251526 test acc 0.861\n",
      "825 loss = 0.03402961045503616 test acc 0.861\n",
      "826 loss = 0.034028876572847366 test acc 0.861\n",
      "827 loss = 0.03402814641594887 test acc 0.861\n",
      "828 loss = 0.03402741253376007 test acc 0.861\n",
      "829 loss = 0.03402668982744217 test acc 0.861\n",
      "830 loss = 0.03402595967054367 test acc 0.861\n",
      "831 loss = 0.03402523696422577 test acc 0.8611\n",
      "832 loss = 0.03402451425790787 test acc 0.8611\n",
      "833 loss = 0.034023795276880264 test acc 0.8611\n",
      "834 loss = 0.03402307629585266 test acc 0.8611\n",
      "835 loss = 0.03402235731482506 test acc 0.861\n",
      "836 loss = 0.03402164205908775 test acc 0.861\n",
      "837 loss = 0.03402093052864075 test acc 0.861\n",
      "838 loss = 0.03402021899819374 test acc 0.861\n",
      "839 loss = 0.034019507467746735 test acc 0.861\n",
      "840 loss = 0.03401879593729973 test acc 0.861\n",
      "841 loss = 0.03401809558272362 test acc 0.861\n",
      "842 loss = 0.03401739150285721 test acc 0.861\n",
      "843 loss = 0.0340166911482811 test acc 0.861\n",
      "844 loss = 0.03401598334312439 test acc 0.861\n",
      "845 loss = 0.034015290439128876 test acc 0.861\n",
      "846 loss = 0.03401459380984306 test acc 0.861\n",
      "847 loss = 0.03401389345526695 test acc 0.861\n",
      "848 loss = 0.03401320055127144 test acc 0.861\n",
      "849 loss = 0.034012507647275925 test acc 0.861\n",
      "850 loss = 0.03401182219386101 test acc 0.861\n",
      "851 loss = 0.03401113301515579 test acc 0.8611\n",
      "852 loss = 0.03401044383645058 test acc 0.8611\n",
      "853 loss = 0.03400975838303566 test acc 0.8611\n",
      "854 loss = 0.03400907665491104 test acc 0.861\n",
      "855 loss = 0.03400839865207672 test acc 0.861\n",
      "856 loss = 0.034007713198661804 test acc 0.8609\n",
      "857 loss = 0.03400703892111778 test acc 0.8609\n",
      "858 loss = 0.03400636464357376 test acc 0.8609\n",
      "859 loss = 0.03400568664073944 test acc 0.8609\n",
      "860 loss = 0.03400501236319542 test acc 0.8608\n",
      "861 loss = 0.0340043380856514 test acc 0.8608\n",
      "862 loss = 0.03400367125868797 test acc 0.8608\n",
      "863 loss = 0.03400300070643425 test acc 0.8608\n",
      "864 loss = 0.034002337604761124 test acc 0.8608\n",
      "865 loss = 0.0340016707777977 test acc 0.8608\n",
      "866 loss = 0.03400100767612457 test acc 0.8608\n",
      "867 loss = 0.034000348299741745 test acc 0.8608\n",
      "868 loss = 0.03399968519806862 test acc 0.8608\n",
      "869 loss = 0.03399902954697609 test acc 0.8609\n",
      "870 loss = 0.03399837389588356 test acc 0.8609\n",
      "871 loss = 0.03399771824479103 test acc 0.8609\n",
      "872 loss = 0.0339970625936985 test acc 0.8609\n",
      "873 loss = 0.03399641439318657 test acc 0.8609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874 loss = 0.03399576246738434 test acc 0.8609\n",
      "875 loss = 0.033995117992162704 test acc 0.8609\n",
      "876 loss = 0.03399446979165077 test acc 0.8609\n",
      "877 loss = 0.03399382159113884 test acc 0.8609\n",
      "878 loss = 0.033993180841207504 test acc 0.8609\n",
      "879 loss = 0.03399254009127617 test acc 0.8609\n",
      "880 loss = 0.03399189934134483 test acc 0.8609\n",
      "881 loss = 0.0339912585914135 test acc 0.8609\n",
      "882 loss = 0.03399062156677246 test acc 0.8609\n",
      "883 loss = 0.033989984542131424 test acc 0.8609\n",
      "884 loss = 0.033989351242780685 test acc 0.8609\n",
      "885 loss = 0.033988721668720245 test acc 0.8609\n",
      "886 loss = 0.03398808464407921 test acc 0.8609\n",
      "887 loss = 0.03398745879530907 test acc 0.8609\n",
      "888 loss = 0.033986832946538925 test acc 0.8609\n",
      "889 loss = 0.033986203372478485 test acc 0.8609\n",
      "890 loss = 0.033985573798418045 test acc 0.8609\n",
      "891 loss = 0.0339849516749382 test acc 0.8609\n",
      "892 loss = 0.03398432582616806 test acc 0.8609\n",
      "893 loss = 0.033983711153268814 test acc 0.8609\n",
      "894 loss = 0.03398308530449867 test acc 0.8609\n",
      "895 loss = 0.033982470631599426 test acc 0.8609\n",
      "896 loss = 0.03398185595870018 test acc 0.8609\n",
      "897 loss = 0.03398124501109123 test acc 0.8609\n",
      "898 loss = 0.03398062288761139 test acc 0.8609\n",
      "899 loss = 0.03398001566529274 test acc 0.8609\n",
      "900 loss = 0.03397940844297409 test acc 0.8609\n",
      "901 loss = 0.033978793770074844 test acc 0.8609\n",
      "902 loss = 0.033978190273046494 test acc 0.8609\n",
      "903 loss = 0.033977583050727844 test acc 0.8608\n",
      "904 loss = 0.03397697955369949 test acc 0.8607\n",
      "905 loss = 0.03397637605667114 test acc 0.8607\n",
      "906 loss = 0.03397577628493309 test acc 0.8607\n",
      "907 loss = 0.03397517278790474 test acc 0.8607\n",
      "908 loss = 0.033974576741456985 test acc 0.8607\n",
      "909 loss = 0.03397398069500923 test acc 0.8607\n",
      "910 loss = 0.03397338092327118 test acc 0.8607\n",
      "911 loss = 0.03397279232740402 test acc 0.8607\n",
      "912 loss = 0.03397219628095627 test acc 0.8607\n",
      "913 loss = 0.03397160395979881 test acc 0.8607\n",
      "914 loss = 0.033971015363931656 test acc 0.8607\n",
      "915 loss = 0.0339704267680645 test acc 0.8607\n",
      "916 loss = 0.03396983817219734 test acc 0.8607\n",
      "917 loss = 0.03396925702691078 test acc 0.8607\n",
      "918 loss = 0.03396867215633392 test acc 0.8607\n",
      "919 loss = 0.033968083560466766 test acc 0.8608\n",
      "920 loss = 0.033967502415180206 test acc 0.861\n",
      "921 loss = 0.033966921269893646 test acc 0.861\n",
      "922 loss = 0.033966343849897385 test acc 0.861\n",
      "923 loss = 0.03396576642990112 test acc 0.861\n",
      "924 loss = 0.03396519273519516 test acc 0.861\n",
      "925 loss = 0.0339646115899086 test acc 0.861\n",
      "926 loss = 0.03396403789520264 test acc 0.861\n",
      "927 loss = 0.03396347165107727 test acc 0.8609\n",
      "928 loss = 0.03396289795637131 test acc 0.8609\n",
      "929 loss = 0.033962324261665344 test acc 0.8609\n",
      "930 loss = 0.033961761742830276 test acc 0.8609\n",
      "931 loss = 0.03396119549870491 test acc 0.8609\n",
      "932 loss = 0.033960625529289246 test acc 0.861\n",
      "933 loss = 0.03396006301045418 test acc 0.861\n",
      "934 loss = 0.03395950049161911 test acc 0.861\n",
      "935 loss = 0.03395893797278404 test acc 0.861\n",
      "936 loss = 0.033958375453948975 test acc 0.861\n",
      "937 loss = 0.033957820385694504 test acc 0.861\n",
      "938 loss = 0.033957261592149734 test acc 0.861\n",
      "939 loss = 0.033956706523895264 test acc 0.861\n",
      "940 loss = 0.03395615145564079 test acc 0.861\n",
      "941 loss = 0.03395559638738632 test acc 0.861\n",
      "942 loss = 0.03395504504442215 test acc 0.861\n",
      "943 loss = 0.03395449370145798 test acc 0.861\n",
      "944 loss = 0.033953938633203506 test acc 0.861\n",
      "945 loss = 0.03395339474081993 test acc 0.861\n",
      "946 loss = 0.033952850848436356 test acc 0.861\n",
      "947 loss = 0.03395229950547218 test acc 0.8609\n",
      "948 loss = 0.033951759338378906 test acc 0.8609\n",
      "949 loss = 0.03395121172070503 test acc 0.8609\n",
      "950 loss = 0.033950671553611755 test acc 0.8609\n",
      "951 loss = 0.03395012766122818 test acc 0.8609\n",
      "952 loss = 0.0339495874941349 test acc 0.8609\n",
      "953 loss = 0.03394905477762222 test acc 0.8609\n",
      "954 loss = 0.033948514610528946 test acc 0.8609\n",
      "955 loss = 0.03394797816872597 test acc 0.8609\n",
      "956 loss = 0.03394744172692299 test acc 0.8609\n",
      "957 loss = 0.03394690901041031 test acc 0.8609\n",
      "958 loss = 0.03394637629389763 test acc 0.8609\n",
      "959 loss = 0.03394583985209465 test acc 0.8608\n",
      "960 loss = 0.03394531086087227 test acc 0.8608\n",
      "961 loss = 0.033944785594940186 test acc 0.8608\n",
      "962 loss = 0.033944252878427505 test acc 0.8608\n",
      "963 loss = 0.03394372761249542 test acc 0.8608\n",
      "964 loss = 0.03394320234656334 test acc 0.8607\n",
      "965 loss = 0.033942680805921555 test acc 0.8607\n",
      "966 loss = 0.03394215926527977 test acc 0.8607\n",
      "967 loss = 0.03394163399934769 test acc 0.8607\n",
      "968 loss = 0.0339411161839962 test acc 0.8607\n",
      "969 loss = 0.033940598368644714 test acc 0.8607\n",
      "970 loss = 0.03394008055329323 test acc 0.8607\n",
      "971 loss = 0.03393956273794174 test acc 0.8607\n",
      "972 loss = 0.033939048647880554 test acc 0.8607\n",
      "973 loss = 0.033938534557819366 test acc 0.8607\n",
      "974 loss = 0.03393802046775818 test acc 0.8607\n",
      "975 loss = 0.03393751010298729 test acc 0.8606\n",
      "976 loss = 0.0339369922876358 test acc 0.8606\n",
      "977 loss = 0.033936481922864914 test acc 0.8606\n",
      "978 loss = 0.03393597900867462 test acc 0.8606\n",
      "979 loss = 0.03393546864390373 test acc 0.8606\n",
      "980 loss = 0.03393496200442314 test acc 0.8606\n",
      "981 loss = 0.03393445536494255 test acc 0.8606\n",
      "982 loss = 0.03393395245075226 test acc 0.8606\n",
      "983 loss = 0.03393344581127167 test acc 0.8606\n",
      "984 loss = 0.033932946622371674 test acc 0.8606\n",
      "985 loss = 0.03393245115876198 test acc 0.8606\n",
      "986 loss = 0.03393194451928139 test acc 0.8606\n",
      "987 loss = 0.03393145278096199 test acc 0.8606\n",
      "988 loss = 0.0339309498667717 test acc 0.8606\n",
      "989 loss = 0.0339304581284523 test acc 0.8606\n",
      "990 loss = 0.03392995521426201 test acc 0.8606\n",
      "991 loss = 0.03392946347594261 test acc 0.8606\n",
      "992 loss = 0.033928971737623215 test acc 0.8606\n",
      "993 loss = 0.03392847999930382 test acc 0.8607\n",
      "994 loss = 0.03392799198627472 test acc 0.8607\n",
      "995 loss = 0.03392750024795532 test acc 0.8607\n",
      "996 loss = 0.033927008509635925 test acc 0.8607\n",
      "997 loss = 0.033926524221897125 test acc 0.8607\n",
      "998 loss = 0.03392603620886803 test acc 0.8607\n",
      "999 loss = 0.03392555192112923 test acc 0.8607\n",
      "1000 loss = 0.03392506763339043 test acc 0.8607\n",
      "1001 loss = 0.03392458334565163 test acc 0.8607\n",
      "1002 loss = 0.033924102783203125 test acc 0.8606\n",
      "1003 loss = 0.033923618495464325 test acc 0.8606\n",
      "1004 loss = 0.03392313793301582 test acc 0.8606\n",
      "1005 loss = 0.03392266109585762 test acc 0.8606\n",
      "1006 loss = 0.03392218053340912 test acc 0.8606\n",
      "1007 loss = 0.033921703696250916 test acc 0.8606\n",
      "1008 loss = 0.03392122685909271 test acc 0.8606\n",
      "1009 loss = 0.03392075374722481 test acc 0.8606\n",
      "1010 loss = 0.0339202806353569 test acc 0.8606\n",
      "1011 loss = 0.0339198037981987 test acc 0.8606\n",
      "1012 loss = 0.033919334411621094 test acc 0.8606\n",
      "1013 loss = 0.03391886129975319 test acc 0.8606\n",
      "1014 loss = 0.03391839191317558 test acc 0.8606\n",
      "1015 loss = 0.03391791880130768 test acc 0.8606\n",
      "1016 loss = 0.03391745686531067 test acc 0.8607\n",
      "1017 loss = 0.03391698747873306 test acc 0.8607\n",
      "1018 loss = 0.033916521817445755 test acc 0.8607\n",
      "1019 loss = 0.033916059881448746 test acc 0.8607\n",
      "1020 loss = 0.03391559049487114 test acc 0.8607\n",
      "1021 loss = 0.03391513228416443 test acc 0.8607\n",
      "1022 loss = 0.03391466662287712 test acc 0.8607\n",
      "1023 loss = 0.03391420468688011 test acc 0.8607\n",
      "1024 loss = 0.0339137464761734 test acc 0.8607\n",
      "1025 loss = 0.03391328826546669 test acc 0.8607\n",
      "1026 loss = 0.033912837505340576 test acc 0.8607\n",
      "1027 loss = 0.03391237556934357 test acc 0.8607\n",
      "1028 loss = 0.033911921083927155 test acc 0.8606\n",
      "1029 loss = 0.03391147032380104 test acc 0.8606\n",
      "1030 loss = 0.03391101211309433 test acc 0.8606\n",
      "1031 loss = 0.03391055762767792 test acc 0.8606\n",
      "1032 loss = 0.033910106867551804 test acc 0.8606\n",
      "1033 loss = 0.03390965610742569 test acc 0.8606\n",
      "1034 loss = 0.033909205347299576 test acc 0.8606\n",
      "1035 loss = 0.03390875831246376 test acc 0.8606\n",
      "1036 loss = 0.033908311277627945 test acc 0.8606\n",
      "1037 loss = 0.03390786796808243 test acc 0.8606\n",
      "1038 loss = 0.033907417207956314 test acc 0.8606\n",
      "1039 loss = 0.0339069738984108 test acc 0.8606\n",
      "1040 loss = 0.03390653058886528 test acc 0.8606\n",
      "1041 loss = 0.033906083554029465 test acc 0.8606\n",
      "1042 loss = 0.033905643969774246 test acc 0.8606\n",
      "1043 loss = 0.03390520066022873 test acc 0.8606\n",
      "1044 loss = 0.03390476852655411 test acc 0.8606\n",
      "1045 loss = 0.03390432149171829 test acc 0.8606\n",
      "1046 loss = 0.03390388563275337 test acc 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047 loss = 0.03390344977378845 test acc 0.8606\n",
      "1048 loss = 0.033903010189533234 test acc 0.8606\n",
      "1049 loss = 0.033902574330568314 test acc 0.8605\n",
      "1050 loss = 0.03390214219689369 test acc 0.8605\n",
      "1051 loss = 0.03390170633792877 test acc 0.8605\n",
      "1052 loss = 0.03390127420425415 test acc 0.8605\n",
      "1053 loss = 0.03390084207057953 test acc 0.8605\n",
      "1054 loss = 0.03390040993690491 test acc 0.8605\n",
      "1055 loss = 0.033899977803230286 test acc 0.8605\n",
      "1056 loss = 0.03389954939484596 test acc 0.8605\n",
      "1057 loss = 0.03389912098646164 test acc 0.8605\n",
      "1058 loss = 0.033898692578077316 test acc 0.8605\n",
      "1059 loss = 0.03389826789498329 test acc 0.8605\n",
      "1060 loss = 0.03389783948659897 test acc 0.8604\n",
      "1061 loss = 0.03389741852879524 test acc 0.8604\n",
      "1062 loss = 0.03389699012041092 test acc 0.8604\n",
      "1063 loss = 0.03389656916260719 test acc 0.8604\n",
      "1064 loss = 0.03389614820480347 test acc 0.8604\n",
      "1065 loss = 0.03389572724699974 test acc 0.8604\n",
      "1066 loss = 0.033895306289196014 test acc 0.8604\n",
      "1067 loss = 0.03389488533139229 test acc 0.8604\n",
      "1068 loss = 0.03389446809887886 test acc 0.8604\n",
      "1069 loss = 0.03389405086636543 test acc 0.8604\n",
      "1070 loss = 0.03389362990856171 test acc 0.8604\n",
      "1071 loss = 0.03389321640133858 test acc 0.8604\n",
      "1072 loss = 0.03389280289411545 test acc 0.8604\n",
      "1073 loss = 0.03389238938689232 test acc 0.8604\n",
      "1074 loss = 0.03389197215437889 test acc 0.8604\n",
      "1075 loss = 0.03389156609773636 test acc 0.8605\n",
      "1076 loss = 0.03389115259051323 test acc 0.8605\n",
      "1077 loss = 0.0338907428085804 test acc 0.8605\n",
      "1078 loss = 0.03389033302664757 test acc 0.8605\n",
      "1079 loss = 0.03388992324471474 test acc 0.8606\n",
      "1080 loss = 0.033889513462781906 test acc 0.8606\n",
      "1081 loss = 0.03388911113142967 test acc 0.8606\n",
      "1082 loss = 0.03388870134949684 test acc 0.8606\n",
      "1083 loss = 0.03388829529285431 test acc 0.8606\n",
      "1084 loss = 0.03388788923621178 test acc 0.8606\n",
      "1085 loss = 0.033887483179569244 test acc 0.8606\n",
      "1086 loss = 0.03388708084821701 test acc 0.8606\n",
      "1087 loss = 0.033886682242155075 test acc 0.8606\n",
      "1088 loss = 0.03388627618551254 test acc 0.8607\n",
      "1089 loss = 0.03388587757945061 test acc 0.8607\n",
      "1090 loss = 0.03388547897338867 test acc 0.8607\n",
      "1091 loss = 0.03388507664203644 test acc 0.8607\n",
      "1092 loss = 0.0338846780359745 test acc 0.8607\n",
      "1093 loss = 0.03388427942991257 test acc 0.8607\n",
      "1094 loss = 0.03388388827443123 test acc 0.8607\n",
      "1095 loss = 0.03388348966836929 test acc 0.8607\n",
      "1096 loss = 0.033883098512887955 test acc 0.8607\n",
      "1097 loss = 0.03388270363211632 test acc 0.8607\n",
      "1098 loss = 0.03388231247663498 test acc 0.8608\n",
      "1099 loss = 0.03388191759586334 test acc 0.8607\n",
      "1100 loss = 0.033881526440382004 test acc 0.8607\n",
      "1101 loss = 0.033881135284900665 test acc 0.8607\n",
      "1102 loss = 0.03388074412941933 test acc 0.8607\n",
      "1103 loss = 0.03388035297393799 test acc 0.8607\n",
      "1104 loss = 0.03387996926903725 test acc 0.8607\n",
      "1105 loss = 0.03387958183884621 test acc 0.8607\n",
      "1106 loss = 0.03387919440865517 test acc 0.8607\n",
      "1107 loss = 0.03387880697846413 test acc 0.8607\n",
      "1108 loss = 0.03387841954827309 test acc 0.8607\n",
      "1109 loss = 0.033878035843372345 test acc 0.8606\n",
      "1110 loss = 0.033877648413181305 test acc 0.8606\n",
      "1111 loss = 0.03387726843357086 test acc 0.8606\n",
      "1112 loss = 0.03387688472867012 test acc 0.8606\n",
      "1113 loss = 0.033876508474349976 test acc 0.8606\n",
      "1114 loss = 0.033876124769449234 test acc 0.8606\n",
      "1115 loss = 0.03387574478983879 test acc 0.8606\n",
      "1116 loss = 0.03387536481022835 test acc 0.8606\n",
      "1117 loss = 0.0338749885559082 test acc 0.8606\n",
      "1118 loss = 0.03387460857629776 test acc 0.8606\n",
      "1119 loss = 0.033874232321977615 test acc 0.8606\n",
      "1120 loss = 0.03387385979294777 test acc 0.8606\n",
      "1121 loss = 0.033873479813337326 test acc 0.8606\n",
      "1122 loss = 0.03387310355901718 test acc 0.8605\n",
      "1123 loss = 0.033872731029987335 test acc 0.8605\n",
      "1124 loss = 0.03387235850095749 test acc 0.8605\n",
      "1125 loss = 0.03387198597192764 test acc 0.8605\n",
      "1126 loss = 0.033871617168188095 test acc 0.8605\n",
      "1127 loss = 0.03387124463915825 test acc 0.8605\n",
      "1128 loss = 0.0338708758354187 test acc 0.8605\n",
      "1129 loss = 0.03387050703167915 test acc 0.8605\n",
      "1130 loss = 0.033870138227939606 test acc 0.8605\n",
      "1131 loss = 0.03386976942420006 test acc 0.8605\n",
      "1132 loss = 0.03386940434575081 test acc 0.8605\n",
      "1133 loss = 0.03386903926730156 test acc 0.8605\n",
      "1134 loss = 0.03386867046356201 test acc 0.8605\n",
      "1135 loss = 0.03386830911040306 test acc 0.8605\n",
      "1136 loss = 0.03386794030666351 test acc 0.8605\n",
      "1137 loss = 0.03386757895350456 test acc 0.8605\n",
      "1138 loss = 0.03386721387505531 test acc 0.8605\n",
      "1139 loss = 0.03386685252189636 test acc 0.8605\n",
      "1140 loss = 0.03386649116873741 test acc 0.8604\n",
      "1141 loss = 0.03386612981557846 test acc 0.8604\n",
      "1142 loss = 0.03386576846241951 test acc 0.8604\n",
      "1143 loss = 0.03386541083455086 test acc 0.8604\n",
      "1144 loss = 0.03386504948139191 test acc 0.8604\n",
      "1145 loss = 0.03386469557881355 test acc 0.8604\n",
      "1146 loss = 0.0338643379509449 test acc 0.8604\n",
      "1147 loss = 0.03386398032307625 test acc 0.8604\n",
      "1148 loss = 0.033863626420497894 test acc 0.8604\n",
      "1149 loss = 0.03386327251791954 test acc 0.8604\n",
      "1150 loss = 0.033862922340631485 test acc 0.8604\n",
      "1151 loss = 0.03386256471276283 test acc 0.8604\n",
      "1152 loss = 0.03386221453547478 test acc 0.8604\n",
      "1153 loss = 0.03386186063289642 test acc 0.8604\n",
      "1154 loss = 0.03386150673031807 test acc 0.8604\n",
      "1155 loss = 0.033861156553030014 test acc 0.8604\n",
      "1156 loss = 0.03386081010103226 test acc 0.8603\n",
      "1157 loss = 0.0338604599237442 test acc 0.8603\n",
      "1158 loss = 0.033860113471746445 test acc 0.8603\n",
      "1159 loss = 0.03385976701974869 test acc 0.8603\n",
      "1160 loss = 0.033859413117170334 test acc 0.8603\n",
      "1161 loss = 0.033859070390462875 test acc 0.8603\n",
      "1162 loss = 0.03385872393846512 test acc 0.8603\n",
      "1163 loss = 0.03385838121175766 test acc 0.8603\n",
      "1164 loss = 0.033858031034469604 test acc 0.8603\n",
      "1165 loss = 0.033857692033052444 test acc 0.8603\n",
      "1166 loss = 0.03385734558105469 test acc 0.8603\n",
      "1167 loss = 0.03385699912905693 test acc 0.8603\n",
      "1168 loss = 0.03385666012763977 test acc 0.8603\n",
      "1169 loss = 0.03385631740093231 test acc 0.8603\n",
      "1170 loss = 0.03385598212480545 test acc 0.8603\n",
      "1171 loss = 0.03385564312338829 test acc 0.8603\n",
      "1172 loss = 0.03385530412197113 test acc 0.8603\n",
      "1173 loss = 0.03385496139526367 test acc 0.8603\n",
      "1174 loss = 0.03385462611913681 test acc 0.8603\n",
      "1175 loss = 0.03385428711771965 test acc 0.8603\n",
      "1176 loss = 0.03385394811630249 test acc 0.8603\n",
      "1177 loss = 0.03385361656546593 test acc 0.8603\n",
      "1178 loss = 0.033853285014629364 test acc 0.8603\n",
      "1179 loss = 0.033852946013212204 test acc 0.8603\n",
      "1180 loss = 0.03385261073708534 test acc 0.8603\n",
      "1181 loss = 0.03385227546095848 test acc 0.8603\n",
      "1182 loss = 0.033851947635412216 test acc 0.8603\n",
      "1183 loss = 0.03385161608457565 test acc 0.8603\n",
      "1184 loss = 0.03385128453373909 test acc 0.8603\n",
      "1185 loss = 0.03385095298290253 test acc 0.8603\n",
      "1186 loss = 0.033850621432065964 test acc 0.8603\n",
      "1187 loss = 0.0338502936065197 test acc 0.8604\n",
      "1188 loss = 0.033849962055683136 test acc 0.8604\n",
      "1189 loss = 0.03384963423013687 test acc 0.8605\n",
      "1190 loss = 0.03384930640459061 test acc 0.8605\n",
      "1191 loss = 0.03384898230433464 test acc 0.8605\n",
      "1192 loss = 0.033848654478788376 test acc 0.8605\n",
      "1193 loss = 0.03384832665324211 test acc 0.8605\n",
      "1194 loss = 0.033848002552986145 test acc 0.8605\n",
      "1195 loss = 0.03384767472743988 test acc 0.8605\n",
      "1196 loss = 0.033847350627183914 test acc 0.8605\n",
      "1197 loss = 0.033847033977508545 test acc 0.8605\n",
      "1198 loss = 0.03384670615196228 test acc 0.8605\n",
      "1199 loss = 0.03384638577699661 test acc 0.8605\n",
      "1200 loss = 0.03384606912732124 test acc 0.8605\n",
      "1201 loss = 0.03384574130177498 test acc 0.8605\n",
      "1202 loss = 0.03384542465209961 test acc 0.8605\n",
      "1203 loss = 0.03384510800242424 test acc 0.8605\n",
      "1204 loss = 0.03384478762745857 test acc 0.8605\n",
      "1205 loss = 0.0338444709777832 test acc 0.8605\n",
      "1206 loss = 0.033844150602817535 test acc 0.8605\n",
      "1207 loss = 0.033843833953142166 test acc 0.8605\n",
      "1208 loss = 0.0338435135781765 test acc 0.8606\n",
      "1209 loss = 0.03384320065379143 test acc 0.8607\n",
      "1210 loss = 0.03384288772940636 test acc 0.8607\n",
      "1211 loss = 0.033842574805021286 test acc 0.8607\n",
      "1212 loss = 0.03384225443005562 test acc 0.8607\n",
      "1213 loss = 0.03384194150567055 test acc 0.8607\n",
      "1214 loss = 0.03384162858128548 test acc 0.8607\n",
      "1215 loss = 0.033841315656900406 test acc 0.8607\n",
      "1216 loss = 0.033841002732515335 test acc 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217 loss = 0.03384069353342056 test acc 0.8607\n",
      "1218 loss = 0.03384038060903549 test acc 0.8607\n",
      "1219 loss = 0.03384007140994072 test acc 0.8607\n",
      "1220 loss = 0.03383976221084595 test acc 0.8607\n",
      "1221 loss = 0.033839453011751175 test acc 0.8607\n",
      "1222 loss = 0.0338391438126564 test acc 0.8607\n",
      "1223 loss = 0.03383883833885193 test acc 0.8607\n",
      "1224 loss = 0.033838532865047455 test acc 0.8607\n",
      "1225 loss = 0.033838219940662384 test acc 0.8607\n",
      "1226 loss = 0.03383791446685791 test acc 0.8607\n",
      "1227 loss = 0.033837612718343735 test acc 0.8607\n",
      "1228 loss = 0.03383730724453926 test acc 0.8607\n",
      "1229 loss = 0.03383700177073479 test acc 0.8607\n",
      "1230 loss = 0.03383669629693031 test acc 0.8607\n",
      "1231 loss = 0.03383639082312584 test acc 0.8607\n",
      "1232 loss = 0.033836085349321365 test acc 0.8607\n",
      "1233 loss = 0.03383578732609749 test acc 0.8607\n",
      "1234 loss = 0.03383548557758331 test acc 0.8606\n",
      "1235 loss = 0.03383518382906914 test acc 0.8606\n",
      "1236 loss = 0.03383488953113556 test acc 0.8606\n",
      "1237 loss = 0.033834584057331085 test acc 0.8606\n",
      "1238 loss = 0.03383428975939751 test acc 0.8606\n",
      "1239 loss = 0.03383399173617363 test acc 0.8606\n",
      "1240 loss = 0.033833689987659454 test acc 0.8606\n",
      "1241 loss = 0.03383339196443558 test acc 0.8607\n",
      "1242 loss = 0.033833097666502 test acc 0.8607\n",
      "1243 loss = 0.03383279964327812 test acc 0.8607\n",
      "1244 loss = 0.033832501620054245 test acc 0.8607\n",
      "1245 loss = 0.033832207322120667 test acc 0.8606\n",
      "1246 loss = 0.03383191302418709 test acc 0.8606\n",
      "1247 loss = 0.03383161872625351 test acc 0.8606\n",
      "1248 loss = 0.03383132815361023 test acc 0.8606\n",
      "1249 loss = 0.03383103385567665 test acc 0.8606\n",
      "1250 loss = 0.03383073955774307 test acc 0.8606\n",
      "1251 loss = 0.03383044898509979 test acc 0.8606\n",
      "1252 loss = 0.03383015841245651 test acc 0.8606\n",
      "1253 loss = 0.033829864114522934 test acc 0.8606\n",
      "1254 loss = 0.03382957726716995 test acc 0.8606\n",
      "1255 loss = 0.033829282969236374 test acc 0.8606\n",
      "1256 loss = 0.03382899612188339 test acc 0.8606\n",
      "1257 loss = 0.03382870927453041 test acc 0.8606\n",
      "1258 loss = 0.03382841870188713 test acc 0.8606\n",
      "1259 loss = 0.03382813185453415 test acc 0.8606\n",
      "1260 loss = 0.03382784500718117 test acc 0.8606\n",
      "1261 loss = 0.03382755443453789 test acc 0.8606\n",
      "1262 loss = 0.033827271312475204 test acc 0.8606\n",
      "1263 loss = 0.03382698446512222 test acc 0.8606\n",
      "1264 loss = 0.03382670134305954 test acc 0.8605\n",
      "1265 loss = 0.03382641449570656 test acc 0.8605\n",
      "1266 loss = 0.033826131373643875 test acc 0.8605\n",
      "1267 loss = 0.03382584825158119 test acc 0.8605\n",
      "1268 loss = 0.03382556512951851 test acc 0.8605\n",
      "1269 loss = 0.033825282007455826 test acc 0.8605\n",
      "1270 loss = 0.033824995160102844 test acc 0.8605\n",
      "1271 loss = 0.03382471576333046 test acc 0.8605\n",
      "1272 loss = 0.033824432641267776 test acc 0.8605\n",
      "1273 loss = 0.03382415696978569 test acc 0.8606\n",
      "1274 loss = 0.03382387384772301 test acc 0.8606\n",
      "1275 loss = 0.03382359445095062 test acc 0.8606\n",
      "1276 loss = 0.03382331505417824 test acc 0.8606\n",
      "1277 loss = 0.03382303938269615 test acc 0.8606\n",
      "1278 loss = 0.03382275998592377 test acc 0.8605\n",
      "1279 loss = 0.03382248058915138 test acc 0.8605\n",
      "1280 loss = 0.033822204917669296 test acc 0.8605\n",
      "1281 loss = 0.03382192924618721 test acc 0.8605\n",
      "1282 loss = 0.033821653574705124 test acc 0.8605\n",
      "1283 loss = 0.03382137790322304 test acc 0.8605\n",
      "1284 loss = 0.03382109850645065 test acc 0.8605\n",
      "1285 loss = 0.033820826560258865 test acc 0.8605\n",
      "1286 loss = 0.03382055461406708 test acc 0.8605\n",
      "1287 loss = 0.03382028266787529 test acc 0.8605\n",
      "1288 loss = 0.0338200107216835 test acc 0.8605\n",
      "1289 loss = 0.033819735050201416 test acc 0.8605\n",
      "1290 loss = 0.03381945937871933 test acc 0.8605\n",
      "1291 loss = 0.03381919115781784 test acc 0.8605\n",
      "1292 loss = 0.03381891921162605 test acc 0.8605\n",
      "1293 loss = 0.033818650990724564 test acc 0.8605\n",
      "1294 loss = 0.03381838649511337 test acc 0.8605\n",
      "1295 loss = 0.033818114548921585 test acc 0.8605\n",
      "1296 loss = 0.033817846328020096 test acc 0.8605\n",
      "1297 loss = 0.03381757438182831 test acc 0.8605\n",
      "1298 loss = 0.03381730616092682 test acc 0.8605\n",
      "1299 loss = 0.03381704166531563 test acc 0.8605\n",
      "1300 loss = 0.03381677344441414 test acc 0.8605\n",
      "1301 loss = 0.03381650522351265 test acc 0.8605\n",
      "1302 loss = 0.03381623700261116 test acc 0.8605\n",
      "1303 loss = 0.03381597250699997 test acc 0.8605\n",
      "1304 loss = 0.03381570428609848 test acc 0.8605\n",
      "1305 loss = 0.03381544351577759 test acc 0.8605\n",
      "1306 loss = 0.0338151752948761 test acc 0.8605\n",
      "1307 loss = 0.03381490707397461 test acc 0.8605\n",
      "1308 loss = 0.033814650028944016 test acc 0.8605\n",
      "1309 loss = 0.033814385533332825 test acc 0.8605\n",
      "1310 loss = 0.033814121037721634 test acc 0.8604\n",
      "1311 loss = 0.03381385654211044 test acc 0.8604\n",
      "1312 loss = 0.03381359949707985 test acc 0.8604\n",
      "1313 loss = 0.03381333872675896 test acc 0.8605\n",
      "1314 loss = 0.033813074231147766 test acc 0.8605\n",
      "1315 loss = 0.033812813460826874 test acc 0.8605\n",
      "1316 loss = 0.03381255641579628 test acc 0.8605\n",
      "1317 loss = 0.033812299370765686 test acc 0.8605\n",
      "1318 loss = 0.033812034875154495 test acc 0.8605\n",
      "1319 loss = 0.0338117815554142 test acc 0.8605\n",
      "1320 loss = 0.033811528235673904 test acc 0.8605\n",
      "1321 loss = 0.033811263740062714 test acc 0.8605\n",
      "1322 loss = 0.03381100669503212 test acc 0.8605\n",
      "1323 loss = 0.033810753375291824 test acc 0.8605\n",
      "1324 loss = 0.03381049260497093 test acc 0.8605\n",
      "1325 loss = 0.033810243010520935 test acc 0.8605\n",
      "1326 loss = 0.03380998596549034 test acc 0.8605\n",
      "1327 loss = 0.033809732645750046 test acc 0.8605\n",
      "1328 loss = 0.03380947932600975 test acc 0.8604\n",
      "1329 loss = 0.033809222280979156 test acc 0.8604\n",
      "1330 loss = 0.03380896896123886 test acc 0.8604\n",
      "1331 loss = 0.033808715641498566 test acc 0.8604\n",
      "1332 loss = 0.03380846604704857 test acc 0.8604\n",
      "1333 loss = 0.03380821272730827 test acc 0.8605\n",
      "1334 loss = 0.03380795940756798 test acc 0.8605\n",
      "1335 loss = 0.03380771353840828 test acc 0.8604\n",
      "1336 loss = 0.033807460218667984 test acc 0.8604\n",
      "1337 loss = 0.03380720689892769 test acc 0.8604\n",
      "1338 loss = 0.03380695730447769 test acc 0.8604\n",
      "1339 loss = 0.033806707710027695 test acc 0.8604\n",
      "1340 loss = 0.0338064581155777 test acc 0.8605\n",
      "1341 loss = 0.0338062085211277 test acc 0.8605\n",
      "1342 loss = 0.033805962651968 test acc 0.8605\n",
      "1343 loss = 0.033805716782808304 test acc 0.8605\n",
      "1344 loss = 0.03380546718835831 test acc 0.8605\n",
      "1345 loss = 0.03380521759390831 test acc 0.8605\n",
      "1346 loss = 0.03380497545003891 test acc 0.8603\n",
      "1347 loss = 0.03380472958087921 test acc 0.8603\n",
      "1348 loss = 0.03380448743700981 test acc 0.8603\n",
      "1349 loss = 0.033804237842559814 test acc 0.8603\n",
      "1350 loss = 0.03380399942398071 test acc 0.8603\n",
      "1351 loss = 0.033803749829530716 test acc 0.8603\n",
      "1352 loss = 0.033803507685661316 test acc 0.8603\n",
      "1353 loss = 0.033803269267082214 test acc 0.8603\n",
      "1354 loss = 0.03380301967263222 test acc 0.8603\n",
      "1355 loss = 0.03380277752876282 test acc 0.8603\n",
      "1356 loss = 0.03380253538489342 test acc 0.8603\n",
      "1357 loss = 0.03380229324102402 test acc 0.8603\n",
      "1358 loss = 0.033802054822444916 test acc 0.8603\n",
      "1359 loss = 0.033801812678575516 test acc 0.8603\n",
      "1360 loss = 0.033801570534706116 test acc 0.8603\n",
      "1361 loss = 0.033801332116127014 test acc 0.8603\n",
      "1362 loss = 0.033801089972257614 test acc 0.8603\n",
      "1363 loss = 0.03380085155367851 test acc 0.8603\n",
      "1364 loss = 0.03380061313509941 test acc 0.8603\n",
      "1365 loss = 0.03380037099123001 test acc 0.8603\n",
      "1366 loss = 0.03380013257265091 test acc 0.8602\n",
      "1367 loss = 0.033799897879362106 test acc 0.8602\n",
      "1368 loss = 0.033799659460783005 test acc 0.8602\n",
      "1369 loss = 0.0337994247674942 test acc 0.8601\n",
      "1370 loss = 0.0337991826236248 test acc 0.8601\n",
      "1371 loss = 0.0337989516556263 test acc 0.8601\n",
      "1372 loss = 0.033798716962337494 test acc 0.8601\n",
      "1373 loss = 0.03379847854375839 test acc 0.8601\n",
      "1374 loss = 0.03379824385046959 test acc 0.8602\n",
      "1375 loss = 0.033798009157180786 test acc 0.8602\n",
      "1376 loss = 0.033797770738601685 test acc 0.8602\n",
      "1377 loss = 0.03379753977060318 test acc 0.8601\n",
      "1378 loss = 0.03379730507731438 test acc 0.8601\n",
      "1379 loss = 0.03379707783460617 test acc 0.8601\n",
      "1380 loss = 0.03379684314131737 test acc 0.8601\n",
      "1381 loss = 0.03379661217331886 test acc 0.8601\n",
      "1382 loss = 0.03379638120532036 test acc 0.86\n",
      "1383 loss = 0.033796150237321854 test acc 0.86\n",
      "1384 loss = 0.03379591926932335 test acc 0.86\n",
      "1385 loss = 0.033795688301324844 test acc 0.86\n",
      "1386 loss = 0.03379545733332634 test acc 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387 loss = 0.033795230090618134 test acc 0.86\n",
      "1388 loss = 0.03379499539732933 test acc 0.8601\n",
      "1389 loss = 0.033794768154621124 test acc 0.8601\n",
      "1390 loss = 0.03379453718662262 test acc 0.8601\n",
      "1391 loss = 0.03379430994391441 test acc 0.8601\n",
      "1392 loss = 0.03379408270120621 test acc 0.8601\n",
      "1393 loss = 0.033793855458498 test acc 0.8601\n",
      "1394 loss = 0.033793628215789795 test acc 0.8601\n",
      "1395 loss = 0.03379340097308159 test acc 0.8601\n",
      "1396 loss = 0.03379317745566368 test acc 0.8601\n",
      "1397 loss = 0.03379295393824577 test acc 0.8601\n",
      "1398 loss = 0.03379272297024727 test acc 0.8601\n",
      "1399 loss = 0.03379249945282936 test acc 0.8601\n",
      "1400 loss = 0.03379227593541145 test acc 0.8601\n",
      "1401 loss = 0.03379204869270325 test acc 0.8601\n",
      "1402 loss = 0.03379182890057564 test acc 0.8601\n",
      "1403 loss = 0.03379160165786743 test acc 0.8601\n",
      "1404 loss = 0.033791378140449524 test acc 0.8601\n",
      "1405 loss = 0.033791154623031616 test acc 0.8601\n",
      "1406 loss = 0.03379093483090401 test acc 0.8601\n",
      "1407 loss = 0.0337907113134861 test acc 0.8601\n",
      "1408 loss = 0.03379049152135849 test acc 0.8601\n",
      "1409 loss = 0.03379026800394058 test acc 0.8601\n",
      "1410 loss = 0.03379004821181297 test acc 0.8601\n",
      "1411 loss = 0.033789824694395065 test acc 0.8601\n",
      "1412 loss = 0.033789604902267456 test acc 0.8601\n",
      "1413 loss = 0.033789388835430145 test acc 0.8601\n",
      "1414 loss = 0.033789169043302536 test acc 0.8601\n",
      "1415 loss = 0.03378894552588463 test acc 0.8601\n",
      "1416 loss = 0.03378872573375702 test acc 0.8601\n",
      "1417 loss = 0.03378851339221001 test acc 0.8601\n",
      "1418 loss = 0.033788297325372696 test acc 0.8601\n",
      "1419 loss = 0.03378807380795479 test acc 0.8601\n",
      "1420 loss = 0.033787861466407776 test acc 0.8601\n",
      "1421 loss = 0.03378764167428017 test acc 0.8601\n",
      "1422 loss = 0.03378742188215256 test acc 0.8601\n",
      "1423 loss = 0.03378720581531525 test acc 0.8601\n",
      "1424 loss = 0.033786993473768234 test acc 0.8601\n",
      "1425 loss = 0.03378678113222122 test acc 0.8601\n",
      "1426 loss = 0.03378656506538391 test acc 0.8601\n",
      "1427 loss = 0.0337863452732563 test acc 0.8601\n",
      "1428 loss = 0.03378613665699959 test acc 0.8601\n",
      "1429 loss = 0.03378592059016228 test acc 0.8602\n",
      "1430 loss = 0.033785704523324966 test acc 0.8602\n",
      "1431 loss = 0.033785492181777954 test acc 0.8602\n",
      "1432 loss = 0.03378527984023094 test acc 0.8602\n",
      "1433 loss = 0.03378506749868393 test acc 0.8602\n",
      "1434 loss = 0.03378485515713692 test acc 0.8602\n",
      "1435 loss = 0.033784642815589905 test acc 0.8602\n",
      "1436 loss = 0.03378443047404289 test acc 0.8602\n",
      "1437 loss = 0.03378422185778618 test acc 0.8602\n",
      "1438 loss = 0.033784013241529465 test acc 0.8602\n",
      "1439 loss = 0.033783793449401855 test acc 0.8602\n",
      "1440 loss = 0.03378358855843544 test acc 0.8602\n",
      "1441 loss = 0.03378337621688843 test acc 0.8602\n",
      "1442 loss = 0.033783167600631714 test acc 0.8602\n",
      "1443 loss = 0.033782958984375 test acc 0.8602\n",
      "1444 loss = 0.03378274664282799 test acc 0.8602\n",
      "1445 loss = 0.033782538026571274 test acc 0.8602\n",
      "1446 loss = 0.03378232941031456 test acc 0.8602\n",
      "1447 loss = 0.033782124519348145 test acc 0.8602\n",
      "1448 loss = 0.03378191590309143 test acc 0.8602\n",
      "1449 loss = 0.03378170728683472 test acc 0.8602\n",
      "1450 loss = 0.033781498670578 test acc 0.8602\n",
      "1451 loss = 0.033781297504901886 test acc 0.8602\n",
      "1452 loss = 0.03378109261393547 test acc 0.8602\n",
      "1453 loss = 0.033780887722969055 test acc 0.8602\n",
      "1454 loss = 0.03378067910671234 test acc 0.8602\n",
      "1455 loss = 0.033780474215745926 test acc 0.8602\n",
      "1456 loss = 0.03378026559948921 test acc 0.8602\n",
      "1457 loss = 0.033780064433813095 test acc 0.8602\n",
      "1458 loss = 0.03377985954284668 test acc 0.8602\n",
      "1459 loss = 0.03377965837717056 test acc 0.8602\n",
      "1460 loss = 0.033779457211494446 test acc 0.8602\n",
      "1461 loss = 0.03377925232052803 test acc 0.8602\n",
      "1462 loss = 0.03377905115485191 test acc 0.8602\n",
      "1463 loss = 0.0337788462638855 test acc 0.8602\n",
      "1464 loss = 0.03377864509820938 test acc 0.8602\n",
      "1465 loss = 0.033778440207242966 test acc 0.8602\n",
      "1466 loss = 0.03377823904156685 test acc 0.8602\n",
      "1467 loss = 0.03377803787589073 test acc 0.8602\n",
      "1468 loss = 0.033777832984924316 test acc 0.8602\n",
      "1469 loss = 0.0337776355445385 test acc 0.8602\n",
      "1470 loss = 0.03377743437886238 test acc 0.8602\n",
      "1471 loss = 0.033777233213186264 test acc 0.8602\n",
      "1472 loss = 0.033777035772800446 test acc 0.8602\n",
      "1473 loss = 0.03377683460712433 test acc 0.8602\n",
      "1474 loss = 0.03377663344144821 test acc 0.8602\n",
      "1475 loss = 0.03377643600106239 test acc 0.8603\n",
      "1476 loss = 0.033776238560676575 test acc 0.8603\n",
      "1477 loss = 0.033776041120290756 test acc 0.8603\n",
      "1478 loss = 0.03377584367990494 test acc 0.8603\n",
      "1479 loss = 0.03377564623951912 test acc 0.8603\n",
      "1480 loss = 0.033775445073843 test acc 0.8603\n",
      "1481 loss = 0.03377525135874748 test acc 0.8603\n",
      "1482 loss = 0.033775053918361664 test acc 0.8603\n",
      "1483 loss = 0.03377486392855644 test acc 0.8603\n",
      "1484 loss = 0.033774662762880325 test acc 0.8603\n",
      "1485 loss = 0.033774469047784805 test acc 0.8603\n",
      "1486 loss = 0.033774275332689285 test acc 0.8603\n",
      "1487 loss = 0.033774081617593765 test acc 0.8604\n",
      "1488 loss = 0.033773887902498245 test acc 0.8604\n",
      "1489 loss = 0.033773694187402725 test acc 0.8604\n",
      "1490 loss = 0.03377349674701691 test acc 0.8604\n",
      "1491 loss = 0.03377330303192139 test acc 0.8604\n",
      "1492 loss = 0.03377310931682587 test acc 0.8604\n",
      "1493 loss = 0.033772919327020645 test acc 0.8604\n",
      "1494 loss = 0.03377272188663483 test acc 0.8604\n",
      "1495 loss = 0.033772535622119904 test acc 0.8604\n",
      "1496 loss = 0.03377234563231468 test acc 0.8604\n",
      "1497 loss = 0.033772148191928864 test acc 0.8604\n",
      "1498 loss = 0.03377195820212364 test acc 0.8604\n",
      "1499 loss = 0.03377176821231842 test acc 0.8604\n",
      "1500 loss = 0.0337715782225132 test acc 0.8604\n",
      "1501 loss = 0.03377138823270798 test acc 0.8604\n",
      "1502 loss = 0.033771198242902756 test acc 0.8604\n",
      "1503 loss = 0.033771008253097534 test acc 0.8604\n",
      "1504 loss = 0.03377081826329231 test acc 0.8604\n",
      "1505 loss = 0.03377062827348709 test acc 0.8604\n",
      "1506 loss = 0.03377044200897217 test acc 0.8604\n",
      "1507 loss = 0.033770255744457245 test acc 0.8605\n",
      "1508 loss = 0.03377006575465202 test acc 0.8605\n",
      "1509 loss = 0.0337698757648468 test acc 0.8605\n",
      "1510 loss = 0.03376968577504158 test acc 0.8605\n",
      "1511 loss = 0.03376949951052666 test acc 0.8605\n",
      "1512 loss = 0.033769313246011734 test acc 0.8605\n",
      "1513 loss = 0.03376912698149681 test acc 0.8605\n",
      "1514 loss = 0.03376893699169159 test acc 0.8605\n",
      "1515 loss = 0.033768754452466965 test acc 0.8605\n",
      "1516 loss = 0.033768560737371445 test acc 0.8605\n",
      "1517 loss = 0.03376837819814682 test acc 0.8605\n",
      "1518 loss = 0.033768195658922195 test acc 0.8605\n",
      "1519 loss = 0.03376800939440727 test acc 0.8605\n",
      "1520 loss = 0.03376782685518265 test acc 0.8605\n",
      "1521 loss = 0.033767640590667725 test acc 0.8605\n",
      "1522 loss = 0.0337674543261528 test acc 0.8605\n",
      "1523 loss = 0.03376726806163788 test acc 0.8605\n",
      "1524 loss = 0.033767085522413254 test acc 0.8605\n",
      "1525 loss = 0.03376690298318863 test acc 0.8605\n",
      "1526 loss = 0.0337667241692543 test acc 0.8605\n",
      "1527 loss = 0.03376654163002968 test acc 0.8605\n",
      "1528 loss = 0.033766359090805054 test acc 0.8605\n",
      "1529 loss = 0.03376617282629013 test acc 0.8605\n",
      "1530 loss = 0.033765990287065506 test acc 0.8605\n",
      "1531 loss = 0.03376581147313118 test acc 0.8604\n",
      "1532 loss = 0.033765628933906555 test acc 0.8604\n",
      "1533 loss = 0.03376544639468193 test acc 0.8604\n",
      "1534 loss = 0.0337652713060379 test acc 0.8604\n",
      "1535 loss = 0.03376508504152298 test acc 0.8604\n",
      "1536 loss = 0.033764906227588654 test acc 0.8604\n",
      "1537 loss = 0.03376472741365433 test acc 0.8604\n",
      "1538 loss = 0.03376454859972 test acc 0.8604\n",
      "1539 loss = 0.03376436606049538 test acc 0.8604\n",
      "1540 loss = 0.03376419097185135 test acc 0.8605\n",
      "1541 loss = 0.03376401215791702 test acc 0.8605\n",
      "1542 loss = 0.0337638333439827 test acc 0.8605\n",
      "1543 loss = 0.03376365453004837 test acc 0.8605\n",
      "1544 loss = 0.03376347944140434 test acc 0.8605\n",
      "1545 loss = 0.03376329690217972 test acc 0.8605\n",
      "1546 loss = 0.03376311808824539 test acc 0.8605\n",
      "1547 loss = 0.03376294672489166 test acc 0.8605\n",
      "1548 loss = 0.03376276418566704 test acc 0.8605\n",
      "1549 loss = 0.03376258537173271 test acc 0.8605\n",
      "1550 loss = 0.03376241400837898 test acc 0.8605\n",
      "1551 loss = 0.033762235194444656 test acc 0.8605\n",
      "1552 loss = 0.03376206010580063 test acc 0.8605\n",
      "1553 loss = 0.0337618850171566 test acc 0.8605\n",
      "1554 loss = 0.033761706203222275 test acc 0.8605\n",
      "1555 loss = 0.03376153111457825 test acc 0.8605\n",
      "1556 loss = 0.03376135975122452 test acc 0.8605\n",
      "1557 loss = 0.03376118093729019 test acc 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558 loss = 0.03376100957393646 test acc 0.8606\n",
      "1559 loss = 0.033760834485292435 test acc 0.8606\n",
      "1560 loss = 0.033760663121938705 test acc 0.8606\n",
      "1561 loss = 0.033760491758584976 test acc 0.8606\n",
      "1562 loss = 0.03376031666994095 test acc 0.8606\n",
      "1563 loss = 0.03376014530658722 test acc 0.8606\n",
      "1564 loss = 0.03375997394323349 test acc 0.8606\n",
      "1565 loss = 0.033759795129299164 test acc 0.8606\n",
      "1566 loss = 0.033759623765945435 test acc 0.8606\n",
      "1567 loss = 0.033759456127882004 test acc 0.8606\n",
      "1568 loss = 0.033759284764528275 test acc 0.8606\n",
      "1569 loss = 0.033759113401174545 test acc 0.8606\n",
      "1570 loss = 0.033758942037820816 test acc 0.8606\n",
      "1571 loss = 0.033758774399757385 test acc 0.8606\n",
      "1572 loss = 0.033758603036403656 test acc 0.8607\n",
      "1573 loss = 0.03375843167304993 test acc 0.8607\n",
      "1574 loss = 0.033758264034986496 test acc 0.8607\n",
      "1575 loss = 0.03375808894634247 test acc 0.8607\n",
      "1576 loss = 0.03375791758298874 test acc 0.8607\n",
      "1577 loss = 0.03375774994492531 test acc 0.8607\n",
      "1578 loss = 0.033757586032152176 test acc 0.8607\n",
      "1579 loss = 0.03375741094350815 test acc 0.8607\n",
      "1580 loss = 0.03375724330544472 test acc 0.8607\n",
      "1581 loss = 0.03375707566738129 test acc 0.8607\n",
      "1582 loss = 0.033756908029317856 test acc 0.8607\n",
      "1583 loss = 0.03375673666596413 test acc 0.8607\n",
      "1584 loss = 0.033756569027900696 test acc 0.8607\n",
      "1585 loss = 0.033756401389837265 test acc 0.8607\n",
      "1586 loss = 0.03375624120235443 test acc 0.8607\n",
      "1587 loss = 0.033756073564291 test acc 0.8607\n",
      "1588 loss = 0.03375590965151787 test acc 0.8607\n",
      "1589 loss = 0.03375573828816414 test acc 0.8607\n",
      "1590 loss = 0.03375557065010071 test acc 0.8607\n",
      "1591 loss = 0.033755406737327576 test acc 0.8607\n",
      "1592 loss = 0.033755239099264145 test acc 0.8607\n",
      "1593 loss = 0.03375507518649101 test acc 0.8608\n",
      "1594 loss = 0.03375490754842758 test acc 0.8608\n",
      "1595 loss = 0.03375474363565445 test acc 0.8607\n",
      "1596 loss = 0.03375457599759102 test acc 0.8607\n",
      "1597 loss = 0.033754412084817886 test acc 0.8607\n",
      "1598 loss = 0.03375425562262535 test acc 0.8607\n",
      "1599 loss = 0.03375408798456192 test acc 0.8607\n",
      "1600 loss = 0.033753927797079086 test acc 0.8607\n",
      "1601 loss = 0.033753760159015656 test acc 0.8607\n",
      "1602 loss = 0.03375359997153282 test acc 0.8607\n",
      "1603 loss = 0.033753443509340286 test acc 0.8607\n",
      "1604 loss = 0.033753275871276855 test acc 0.8607\n",
      "1605 loss = 0.033753108233213425 test acc 0.8607\n",
      "1606 loss = 0.03375294804573059 test acc 0.8607\n",
      "1607 loss = 0.03375278785824776 test acc 0.8607\n",
      "1608 loss = 0.03375262767076492 test acc 0.8607\n",
      "1609 loss = 0.03375246748328209 test acc 0.8607\n",
      "1610 loss = 0.03375230357050896 test acc 0.8607\n",
      "1611 loss = 0.03375214710831642 test acc 0.8607\n",
      "1612 loss = 0.03375197947025299 test acc 0.8607\n",
      "1613 loss = 0.03375181928277016 test acc 0.8607\n",
      "1614 loss = 0.03375166282057762 test acc 0.8607\n",
      "1615 loss = 0.03375149890780449 test acc 0.8607\n",
      "1616 loss = 0.033751342445611954 test acc 0.8607\n",
      "1617 loss = 0.03375118225812912 test acc 0.8607\n",
      "1618 loss = 0.033751025795936584 test acc 0.8607\n",
      "1619 loss = 0.03375086560845375 test acc 0.8607\n",
      "1620 loss = 0.03375070542097092 test acc 0.8607\n",
      "1621 loss = 0.03375054895877838 test acc 0.8607\n",
      "1622 loss = 0.03375038877129555 test acc 0.8607\n",
      "1623 loss = 0.03375023230910301 test acc 0.8607\n",
      "1624 loss = 0.03375007212162018 test acc 0.8607\n",
      "1625 loss = 0.03374991565942764 test acc 0.8608\n",
      "1626 loss = 0.033749762922525406 test acc 0.8608\n",
      "1627 loss = 0.03374960273504257 test acc 0.8608\n",
      "1628 loss = 0.03374944627285004 test acc 0.8608\n",
      "1629 loss = 0.0337492898106575 test acc 0.8608\n",
      "1630 loss = 0.033749133348464966 test acc 0.8608\n",
      "1631 loss = 0.03374897316098213 test acc 0.8608\n",
      "1632 loss = 0.033748820424079895 test acc 0.8608\n",
      "1633 loss = 0.03374866768717766 test acc 0.8608\n",
      "1634 loss = 0.03374851122498512 test acc 0.8608\n",
      "1635 loss = 0.033748358488082886 test acc 0.8608\n",
      "1636 loss = 0.03374820202589035 test acc 0.8608\n",
      "1637 loss = 0.03374804928898811 test acc 0.8608\n",
      "1638 loss = 0.03374789282679558 test acc 0.8608\n",
      "1639 loss = 0.03374774008989334 test acc 0.8608\n",
      "1640 loss = 0.033747583627700806 test acc 0.8608\n",
      "1641 loss = 0.03374743089079857 test acc 0.8608\n",
      "1642 loss = 0.03374727815389633 test acc 0.8608\n",
      "1643 loss = 0.033747125416994095 test acc 0.8608\n",
      "1644 loss = 0.03374697268009186 test acc 0.8608\n",
      "1645 loss = 0.03374681994318962 test acc 0.8608\n",
      "1646 loss = 0.033746667206287384 test acc 0.8608\n",
      "1647 loss = 0.033746518194675446 test acc 0.8608\n",
      "1648 loss = 0.03374636545777321 test acc 0.8608\n",
      "1649 loss = 0.03374620899558067 test acc 0.8608\n",
      "1650 loss = 0.033746059983968735 test acc 0.8608\n",
      "1651 loss = 0.033745910972356796 test acc 0.8607\n",
      "1652 loss = 0.03374576196074486 test acc 0.8607\n",
      "1653 loss = 0.03374560922384262 test acc 0.8607\n",
      "1654 loss = 0.03374546021223068 test acc 0.8607\n",
      "1655 loss = 0.033745307475328445 test acc 0.8607\n",
      "1656 loss = 0.03374515473842621 test acc 0.8607\n",
      "1657 loss = 0.03374500572681427 test acc 0.8607\n",
      "1658 loss = 0.03374485671520233 test acc 0.8607\n",
      "1659 loss = 0.03374470770359039 test acc 0.8607\n",
      "1660 loss = 0.033744554966688156 test acc 0.8607\n",
      "1661 loss = 0.03374440595507622 test acc 0.8607\n",
      "1662 loss = 0.03374425694346428 test acc 0.8607\n",
      "1663 loss = 0.03374411165714264 test acc 0.8607\n",
      "1664 loss = 0.0337439589202404 test acc 0.8607\n",
      "1665 loss = 0.033743809908628464 test acc 0.8607\n",
      "1666 loss = 0.033743664622306824 test acc 0.8607\n",
      "1667 loss = 0.03374351188540459 test acc 0.8607\n",
      "1668 loss = 0.033743370324373245 test acc 0.8607\n",
      "1669 loss = 0.03374321758747101 test acc 0.8607\n",
      "1670 loss = 0.03374306857585907 test acc 0.8607\n",
      "1671 loss = 0.03374292328953743 test acc 0.8607\n",
      "1672 loss = 0.03374277800321579 test acc 0.8607\n",
      "1673 loss = 0.03374262526631355 test acc 0.8607\n",
      "1674 loss = 0.03374247997999191 test acc 0.8607\n",
      "1675 loss = 0.03374233469367027 test acc 0.8607\n",
      "1676 loss = 0.03374218940734863 test acc 0.8607\n",
      "1677 loss = 0.033742040395736694 test acc 0.8607\n",
      "1678 loss = 0.03374189883470535 test acc 0.8607\n",
      "1679 loss = 0.03374175354838371 test acc 0.8607\n",
      "1680 loss = 0.03374160826206207 test acc 0.8607\n",
      "1681 loss = 0.03374146297574043 test acc 0.8607\n",
      "1682 loss = 0.03374131768941879 test acc 0.8607\n",
      "1683 loss = 0.03374117612838745 test acc 0.8607\n",
      "1684 loss = 0.03374102711677551 test acc 0.8607\n",
      "1685 loss = 0.03374088555574417 test acc 0.8606\n",
      "1686 loss = 0.03374073654413223 test acc 0.8606\n",
      "1687 loss = 0.03374059125781059 test acc 0.8606\n",
      "1688 loss = 0.03374044969677925 test acc 0.8606\n",
      "1689 loss = 0.03374030441045761 test acc 0.8606\n",
      "1690 loss = 0.03374016284942627 test acc 0.8606\n",
      "1691 loss = 0.033740025013685226 test acc 0.8606\n",
      "1692 loss = 0.033739879727363586 test acc 0.8606\n",
      "1693 loss = 0.033739734441041946 test acc 0.8606\n",
      "1694 loss = 0.033739589154720306 test acc 0.8606\n",
      "1695 loss = 0.03373945131897926 test acc 0.8606\n",
      "1696 loss = 0.03373930603265762 test acc 0.8606\n",
      "1697 loss = 0.03373916447162628 test acc 0.8606\n",
      "1698 loss = 0.03373902663588524 test acc 0.8606\n",
      "1699 loss = 0.0337388813495636 test acc 0.8606\n",
      "1700 loss = 0.033738743513822556 test acc 0.8606\n",
      "1701 loss = 0.033738601952791214 test acc 0.8606\n",
      "1702 loss = 0.03373846039175987 test acc 0.8606\n",
      "1703 loss = 0.03373831883072853 test acc 0.8606\n",
      "1704 loss = 0.03373818099498749 test acc 0.8606\n",
      "1705 loss = 0.03373803570866585 test acc 0.8606\n",
      "1706 loss = 0.033737897872924805 test acc 0.8606\n",
      "1707 loss = 0.03373776003718376 test acc 0.8606\n",
      "1708 loss = 0.03373761847615242 test acc 0.8606\n",
      "1709 loss = 0.03373748064041138 test acc 0.8606\n",
      "1710 loss = 0.033737342804670334 test acc 0.8606\n",
      "1711 loss = 0.03373720124363899 test acc 0.8606\n",
      "1712 loss = 0.03373706713318825 test acc 0.8606\n",
      "1713 loss = 0.033736925572156906 test acc 0.8606\n",
      "1714 loss = 0.03373678773641586 test acc 0.8606\n",
      "1715 loss = 0.03373664990067482 test acc 0.8606\n",
      "1716 loss = 0.033736515790224075 test acc 0.8606\n",
      "1717 loss = 0.033736374229192734 test acc 0.8606\n",
      "1718 loss = 0.03373623639345169 test acc 0.8606\n",
      "1719 loss = 0.033736102283000946 test acc 0.8606\n",
      "1720 loss = 0.033735960721969604 test acc 0.8606\n",
      "1721 loss = 0.03373582288622856 test acc 0.8607\n",
      "1722 loss = 0.03373568877577782 test acc 0.8607\n",
      "1723 loss = 0.033735547214746475 test acc 0.8607\n",
      "1724 loss = 0.03373541310429573 test acc 0.8607\n",
      "1725 loss = 0.03373527526855469 test acc 0.8607\n",
      "1726 loss = 0.033735137432813644 test acc 0.8607\n",
      "1727 loss = 0.0337350033223629 test acc 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728 loss = 0.033734869211912155 test acc 0.8607\n",
      "1729 loss = 0.03373473137617111 test acc 0.8607\n",
      "1730 loss = 0.033734600991010666 test acc 0.8607\n",
      "1731 loss = 0.033734459429979324 test acc 0.8607\n",
      "1732 loss = 0.03373432904481888 test acc 0.8607\n",
      "1733 loss = 0.033734194934368134 test acc 0.8607\n",
      "1734 loss = 0.03373406082391739 test acc 0.8607\n",
      "1735 loss = 0.03373393043875694 test acc 0.8607\n",
      "1736 loss = 0.0337337888777256 test acc 0.8607\n",
      "1737 loss = 0.033733658492565155 test acc 0.8607\n",
      "1738 loss = 0.03373352810740471 test acc 0.8607\n",
      "1739 loss = 0.033733393996953964 test acc 0.8607\n",
      "1740 loss = 0.03373325988650322 test acc 0.8607\n",
      "1741 loss = 0.033733122050762177 test acc 0.8607\n",
      "1742 loss = 0.03373299166560173 test acc 0.8607\n",
      "1743 loss = 0.03373285382986069 test acc 0.8607\n",
      "1744 loss = 0.03373272716999054 test acc 0.8607\n",
      "1745 loss = 0.03373259678483009 test acc 0.8607\n",
      "1746 loss = 0.03373246267437935 test acc 0.8607\n",
      "1747 loss = 0.0337323322892189 test acc 0.8607\n",
      "1748 loss = 0.03373219817876816 test acc 0.8607\n",
      "1749 loss = 0.03373206406831741 test acc 0.8607\n",
      "1750 loss = 0.03373193368315697 test acc 0.8607\n",
      "1751 loss = 0.03373180329799652 test acc 0.8607\n",
      "1752 loss = 0.033731669187545776 test acc 0.8607\n",
      "1753 loss = 0.03373153880238533 test acc 0.8607\n",
      "1754 loss = 0.033731408417224884 test acc 0.8607\n",
      "1755 loss = 0.03373127430677414 test acc 0.8607\n",
      "1756 loss = 0.03373114764690399 test acc 0.8607\n",
      "1757 loss = 0.033731017261743546 test acc 0.8607\n",
      "1758 loss = 0.0337308868765831 test acc 0.8607\n",
      "1759 loss = 0.03373075649142265 test acc 0.8607\n",
      "1760 loss = 0.03373062610626221 test acc 0.8607\n",
      "1761 loss = 0.03373049572110176 test acc 0.8607\n",
      "1762 loss = 0.033730365335941315 test acc 0.8607\n",
      "1763 loss = 0.03373023867607117 test acc 0.8607\n",
      "1764 loss = 0.03373011201620102 test acc 0.8607\n",
      "1765 loss = 0.033729977905750275 test acc 0.8607\n",
      "1766 loss = 0.03372984752058983 test acc 0.8607\n",
      "1767 loss = 0.03372972458600998 test acc 0.8607\n",
      "1768 loss = 0.03372959420084953 test acc 0.8606\n",
      "1769 loss = 0.03372946381568909 test acc 0.8606\n",
      "1770 loss = 0.03372933715581894 test acc 0.8606\n",
      "1771 loss = 0.03372920677065849 test acc 0.8606\n",
      "1772 loss = 0.033729083836078644 test acc 0.8606\n",
      "1773 loss = 0.0337289534509182 test acc 0.8606\n",
      "1774 loss = 0.03372882679104805 test acc 0.8606\n",
      "1775 loss = 0.0337287001311779 test acc 0.8606\n",
      "1776 loss = 0.033728573471307755 test acc 0.8606\n",
      "1777 loss = 0.03372844681143761 test acc 0.8606\n",
      "1778 loss = 0.03372831642627716 test acc 0.8606\n",
      "1779 loss = 0.03372819349169731 test acc 0.8606\n",
      "1780 loss = 0.033728063106536865 test acc 0.8606\n",
      "1781 loss = 0.033727940171957016 test acc 0.8606\n",
      "1782 loss = 0.03372781351208687 test acc 0.8606\n",
      "1783 loss = 0.03372768685221672 test acc 0.8606\n",
      "1784 loss = 0.03372756391763687 test acc 0.8606\n",
      "1785 loss = 0.033727433532476425 test acc 0.8606\n",
      "1786 loss = 0.033727314323186874 test acc 0.8606\n",
      "1787 loss = 0.03372718766331673 test acc 0.8606\n",
      "1788 loss = 0.03372706472873688 test acc 0.8606\n",
      "1789 loss = 0.03372693806886673 test acc 0.8606\n",
      "1790 loss = 0.03372681140899658 test acc 0.8606\n",
      "1791 loss = 0.03372668847441673 test acc 0.8606\n",
      "1792 loss = 0.033726561814546585 test acc 0.8606\n",
      "1793 loss = 0.033726438879966736 test acc 0.8606\n",
      "1794 loss = 0.033726319670677185 test acc 0.8606\n",
      "1795 loss = 0.03372619301080704 test acc 0.8605\n",
      "1796 loss = 0.03372607007622719 test acc 0.8605\n",
      "1797 loss = 0.03372595086693764 test acc 0.8605\n",
      "1798 loss = 0.03372582420706749 test acc 0.8605\n",
      "1799 loss = 0.03372569754719734 test acc 0.8605\n",
      "1800 loss = 0.03372557833790779 test acc 0.8605\n",
      "1801 loss = 0.03372545912861824 test acc 0.8605\n",
      "1802 loss = 0.033725328743457794 test acc 0.8605\n",
      "1803 loss = 0.03372521325945854 test acc 0.8605\n",
      "1804 loss = 0.033725086599588394 test acc 0.8605\n",
      "1805 loss = 0.03372496739029884 test acc 0.8605\n",
      "1806 loss = 0.033724844455718994 test acc 0.8605\n",
      "1807 loss = 0.033724717795848846 test acc 0.8605\n",
      "1808 loss = 0.033724598586559296 test acc 0.8605\n",
      "1809 loss = 0.033724479377269745 test acc 0.8605\n",
      "1810 loss = 0.033724356442689896 test acc 0.8605\n",
      "1811 loss = 0.033724233508110046 test acc 0.8605\n",
      "1812 loss = 0.033724114298820496 test acc 0.8605\n",
      "1813 loss = 0.033723995089530945 test acc 0.8605\n",
      "1814 loss = 0.0337238684296608 test acc 0.8605\n",
      "1815 loss = 0.03372375667095184 test acc 0.8605\n",
      "1816 loss = 0.033723633736371994 test acc 0.8605\n",
      "1817 loss = 0.03372351452708244 test acc 0.8605\n",
      "1818 loss = 0.03372339531779289 test acc 0.8605\n",
      "1819 loss = 0.03372327238321304 test acc 0.8605\n",
      "1820 loss = 0.033723149448633194 test acc 0.8605\n",
      "1821 loss = 0.03372303396463394 test acc 0.8604\n",
      "1822 loss = 0.03372291475534439 test acc 0.8604\n",
      "1823 loss = 0.03372279554605484 test acc 0.8604\n",
      "1824 loss = 0.03372267633676529 test acc 0.8604\n",
      "1825 loss = 0.03372256085276604 test acc 0.8603\n",
      "1826 loss = 0.033722441643476486 test acc 0.8603\n",
      "1827 loss = 0.033722322434186935 test acc 0.8603\n",
      "1828 loss = 0.033722203224897385 test acc 0.8603\n",
      "1829 loss = 0.03372208774089813 test acc 0.8602\n",
      "1830 loss = 0.03372196853160858 test acc 0.8602\n",
      "1831 loss = 0.03372185304760933 test acc 0.8602\n",
      "1832 loss = 0.03372173383831978 test acc 0.8602\n",
      "1833 loss = 0.033721618354320526 test acc 0.8602\n",
      "1834 loss = 0.033721502870321274 test acc 0.8602\n",
      "1835 loss = 0.03372138738632202 test acc 0.8602\n",
      "1836 loss = 0.03372126817703247 test acc 0.8602\n",
      "1837 loss = 0.03372115641832352 test acc 0.8602\n",
      "1838 loss = 0.033721037209033966 test acc 0.8602\n",
      "1839 loss = 0.033720921725034714 test acc 0.8602\n",
      "1840 loss = 0.03372080251574516 test acc 0.8602\n",
      "1841 loss = 0.03372069075703621 test acc 0.8602\n",
      "1842 loss = 0.03372057154774666 test acc 0.8602\n",
      "1843 loss = 0.033720459789037704 test acc 0.8602\n",
      "1844 loss = 0.03372034430503845 test acc 0.8602\n",
      "1845 loss = 0.0337202250957489 test acc 0.8602\n",
      "1846 loss = 0.03372010961174965 test acc 0.8602\n",
      "1847 loss = 0.0337199941277504 test acc 0.8602\n",
      "1848 loss = 0.033719878643751144 test acc 0.8602\n",
      "1849 loss = 0.03371976315975189 test acc 0.8602\n",
      "1850 loss = 0.03371964767575264 test acc 0.8602\n",
      "1851 loss = 0.033719535917043686 test acc 0.8602\n",
      "1852 loss = 0.033719420433044434 test acc 0.8602\n",
      "1853 loss = 0.03371930494904518 test acc 0.8602\n",
      "1854 loss = 0.03371919319033623 test acc 0.8602\n",
      "1855 loss = 0.033719077706336975 test acc 0.8602\n",
      "1856 loss = 0.03371896222233772 test acc 0.8602\n",
      "1857 loss = 0.03371885418891907 test acc 0.8602\n",
      "1858 loss = 0.033718738704919815 test acc 0.8602\n",
      "1859 loss = 0.03371862322092056 test acc 0.8602\n",
      "1860 loss = 0.03371851146221161 test acc 0.8602\n",
      "1861 loss = 0.033718399703502655 test acc 0.8602\n",
      "1862 loss = 0.0337182879447937 test acc 0.8602\n",
      "1863 loss = 0.03371816873550415 test acc 0.8602\n",
      "1864 loss = 0.0337180569767952 test acc 0.8603\n",
      "1865 loss = 0.03371794894337654 test acc 0.8603\n",
      "1866 loss = 0.03371783345937729 test acc 0.8603\n",
      "1867 loss = 0.033717721700668335 test acc 0.8603\n",
      "1868 loss = 0.03371761366724968 test acc 0.8603\n",
      "1869 loss = 0.03371749818325043 test acc 0.8603\n",
      "1870 loss = 0.03371739014983177 test acc 0.8603\n",
      "1871 loss = 0.03371727839112282 test acc 0.8603\n",
      "1872 loss = 0.033717166632413864 test acc 0.8603\n",
      "1873 loss = 0.03371705487370491 test acc 0.8603\n",
      "1874 loss = 0.033716943114995956 test acc 0.8603\n",
      "1875 loss = 0.0337168350815773 test acc 0.8603\n",
      "1876 loss = 0.03371671959757805 test acc 0.8603\n",
      "1877 loss = 0.03371661528944969 test acc 0.8603\n",
      "1878 loss = 0.03371649980545044 test acc 0.8603\n",
      "1879 loss = 0.033716388046741486 test acc 0.8603\n",
      "1880 loss = 0.03371627628803253 test acc 0.8603\n",
      "1881 loss = 0.033716171979904175 test acc 0.8603\n",
      "1882 loss = 0.03371605649590492 test acc 0.8603\n",
      "1883 loss = 0.03371594846248627 test acc 0.8603\n",
      "1884 loss = 0.03371584042906761 test acc 0.8602\n",
      "1885 loss = 0.033715732395648956 test acc 0.8602\n",
      "1886 loss = 0.03371562063694 test acc 0.8602\n",
      "1887 loss = 0.03371551260352135 test acc 0.8602\n",
      "1888 loss = 0.03371540084481239 test acc 0.8602\n",
      "1889 loss = 0.03371529281139374 test acc 0.8602\n",
      "1890 loss = 0.03371518477797508 test acc 0.8602\n",
      "1891 loss = 0.03371507301926613 test acc 0.8602\n",
      "1892 loss = 0.03371496498584747 test acc 0.8602\n",
      "1893 loss = 0.03371485695242882 test acc 0.8602\n",
      "1894 loss = 0.03371474891901016 test acc 0.8602\n",
      "1895 loss = 0.03371464088559151 test acc 0.8602\n",
      "1896 loss = 0.03371453285217285 test acc 0.8602\n",
      "1897 loss = 0.033714424818754196 test acc 0.8602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898 loss = 0.03371432051062584 test acc 0.8602\n",
      "1899 loss = 0.033714212477207184 test acc 0.8602\n",
      "1900 loss = 0.03371410071849823 test acc 0.8602\n",
      "1901 loss = 0.03371399641036987 test acc 0.8602\n",
      "1902 loss = 0.03371388837695122 test acc 0.8601\n",
      "1903 loss = 0.03371378406882286 test acc 0.8601\n",
      "1904 loss = 0.03371367231011391 test acc 0.86\n",
      "1905 loss = 0.03371356800198555 test acc 0.86\n",
      "1906 loss = 0.033713459968566895 test acc 0.86\n",
      "1907 loss = 0.03371335566043854 test acc 0.86\n",
      "1908 loss = 0.03371324762701988 test acc 0.86\n",
      "1909 loss = 0.03371313959360123 test acc 0.86\n",
      "1910 loss = 0.03371303528547287 test acc 0.8601\n",
      "1911 loss = 0.03371293097734451 test acc 0.86\n",
      "1912 loss = 0.03371282294392586 test acc 0.86\n",
      "1913 loss = 0.0337127186357975 test acc 0.86\n",
      "1914 loss = 0.033712614327669144 test acc 0.86\n",
      "1915 loss = 0.033712513744831085 test acc 0.86\n",
      "1916 loss = 0.03371240198612213 test acc 0.86\n",
      "1917 loss = 0.033712297677993774 test acc 0.86\n",
      "1918 loss = 0.03371219336986542 test acc 0.86\n",
      "1919 loss = 0.03371209278702736 test acc 0.86\n",
      "1920 loss = 0.033711988478899 test acc 0.86\n",
      "1921 loss = 0.03371188044548035 test acc 0.86\n",
      "1922 loss = 0.03371177241206169 test acc 0.86\n",
      "1923 loss = 0.03371167182922363 test acc 0.86\n",
      "1924 loss = 0.033711567521095276 test acc 0.86\n",
      "1925 loss = 0.03371146321296692 test acc 0.86\n",
      "1926 loss = 0.03371135890483856 test acc 0.86\n",
      "1927 loss = 0.03371125087141991 test acc 0.86\n",
      "1928 loss = 0.03371115028858185 test acc 0.86\n",
      "1929 loss = 0.03371104598045349 test acc 0.86\n",
      "1930 loss = 0.03371094539761543 test acc 0.86\n",
      "1931 loss = 0.033710841089487076 test acc 0.86\n",
      "1932 loss = 0.03371073678135872 test acc 0.86\n",
      "1933 loss = 0.03371063247323036 test acc 0.86\n",
      "1934 loss = 0.0337105356156826 test acc 0.8599\n",
      "1935 loss = 0.033710431307554245 test acc 0.8599\n",
      "1936 loss = 0.03371032699942589 test acc 0.8599\n",
      "1937 loss = 0.03371022641658783 test acc 0.8599\n",
      "1938 loss = 0.03371012210845947 test acc 0.8599\n",
      "1939 loss = 0.03371002525091171 test acc 0.8599\n",
      "1940 loss = 0.03370991721749306 test acc 0.8599\n",
      "1941 loss = 0.033709824085235596 test acc 0.8599\n",
      "1942 loss = 0.03370971605181694 test acc 0.8599\n",
      "1943 loss = 0.03370961174368858 test acc 0.8599\n",
      "1944 loss = 0.033709511160850525 test acc 0.8599\n",
      "1945 loss = 0.03370941802859306 test acc 0.8599\n",
      "1946 loss = 0.03370930999517441 test acc 0.8599\n",
      "1947 loss = 0.03370920941233635 test acc 0.8599\n",
      "1948 loss = 0.03370910510420799 test acc 0.8599\n",
      "1949 loss = 0.03370900824666023 test acc 0.8599\n",
      "1950 loss = 0.033708903938531876 test acc 0.8599\n",
      "1951 loss = 0.033708807080984116 test acc 0.8599\n",
      "1952 loss = 0.03370870277285576 test acc 0.8599\n",
      "1953 loss = 0.0337086021900177 test acc 0.8599\n",
      "1954 loss = 0.03370850533246994 test acc 0.8599\n",
      "1955 loss = 0.03370840102434158 test acc 0.8599\n",
      "1956 loss = 0.03370830789208412 test acc 0.8599\n",
      "1957 loss = 0.03370820730924606 test acc 0.8599\n",
      "1958 loss = 0.033708106726408005 test acc 0.8599\n",
      "1959 loss = 0.033708006143569946 test acc 0.8599\n",
      "1960 loss = 0.033707909286022186 test acc 0.8599\n",
      "1961 loss = 0.03370780497789383 test acc 0.8599\n",
      "1962 loss = 0.03370770812034607 test acc 0.8599\n",
      "1963 loss = 0.03370761126279831 test acc 0.86\n",
      "1964 loss = 0.03370751067996025 test acc 0.86\n",
      "1965 loss = 0.03370741382241249 test acc 0.86\n",
      "1966 loss = 0.03370731323957443 test acc 0.86\n",
      "1967 loss = 0.033707212656736374 test acc 0.8601\n",
      "1968 loss = 0.033707115799188614 test acc 0.8601\n",
      "1969 loss = 0.033707015216350555 test acc 0.8601\n",
      "1970 loss = 0.033706922084093094 test acc 0.8601\n",
      "1971 loss = 0.033706825226545334 test acc 0.8601\n",
      "1972 loss = 0.033706724643707275 test acc 0.8601\n",
      "1973 loss = 0.03370662406086922 test acc 0.8601\n",
      "1974 loss = 0.03370652720332146 test acc 0.8601\n",
      "1975 loss = 0.0337064303457737 test acc 0.8601\n",
      "1976 loss = 0.03370632976293564 test acc 0.8601\n",
      "1977 loss = 0.03370623290538788 test acc 0.8601\n",
      "1978 loss = 0.03370613604784012 test acc 0.8601\n",
      "1979 loss = 0.03370604291558266 test acc 0.8601\n",
      "1980 loss = 0.0337059460580349 test acc 0.8601\n",
      "1981 loss = 0.03370584547519684 test acc 0.8601\n",
      "1982 loss = 0.03370574861764908 test acc 0.8601\n",
      "1983 loss = 0.03370565176010132 test acc 0.8601\n",
      "1984 loss = 0.03370555490255356 test acc 0.8601\n",
      "1985 loss = 0.0337054580450058 test acc 0.8601\n",
      "1986 loss = 0.03370536118745804 test acc 0.8601\n",
      "1987 loss = 0.03370526805520058 test acc 0.8601\n",
      "1988 loss = 0.03370517119765282 test acc 0.8602\n",
      "1989 loss = 0.03370507434010506 test acc 0.8602\n",
      "1990 loss = 0.033704981207847595 test acc 0.8602\n",
      "1991 loss = 0.033704884350299835 test acc 0.8602\n",
      "1992 loss = 0.033704787492752075 test acc 0.8602\n",
      "1993 loss = 0.033704690635204315 test acc 0.8602\n",
      "1994 loss = 0.033704597502946854 test acc 0.8602\n",
      "1995 loss = 0.033704500645399094 test acc 0.8602\n",
      "1996 loss = 0.03370440751314163 test acc 0.8602\n",
      "1997 loss = 0.03370431065559387 test acc 0.8602\n",
      "1998 loss = 0.03370421379804611 test acc 0.8602\n",
      "1999 loss = 0.03370412439107895 test acc 0.8602\n",
      "2000 loss = 0.03370402753353119 test acc 0.8602\n",
      "2001 loss = 0.03370393067598343 test acc 0.8602\n",
      "2002 loss = 0.03370383754372597 test acc 0.8602\n",
      "2003 loss = 0.033703744411468506 test acc 0.8602\n",
      "2004 loss = 0.033703651279211044 test acc 0.8602\n",
      "2005 loss = 0.033703554421663284 test acc 0.8602\n",
      "2006 loss = 0.03370346128940582 test acc 0.8602\n",
      "2007 loss = 0.03370336443185806 test acc 0.8602\n",
      "2008 loss = 0.0337032750248909 test acc 0.8601\n",
      "2009 loss = 0.03370317816734314 test acc 0.8601\n",
      "2010 loss = 0.03370308876037598 test acc 0.8601\n",
      "2011 loss = 0.033702995628118515 test acc 0.8601\n",
      "2012 loss = 0.033702898770570755 test acc 0.8601\n",
      "2013 loss = 0.03370280936360359 test acc 0.8601\n",
      "2014 loss = 0.03370271623134613 test acc 0.8601\n",
      "2015 loss = 0.03370262309908867 test acc 0.8601\n",
      "2016 loss = 0.03370252996683121 test acc 0.8601\n",
      "2017 loss = 0.033702436834573746 test acc 0.8601\n",
      "2018 loss = 0.033702343702316284 test acc 0.8601\n",
      "2019 loss = 0.03370225057005882 test acc 0.8601\n",
      "2020 loss = 0.03370215371251106 test acc 0.8601\n",
      "2021 loss = 0.0337020643055439 test acc 0.8601\n",
      "2022 loss = 0.03370197117328644 test acc 0.8601\n",
      "2023 loss = 0.033701878041028976 test acc 0.8601\n",
      "2024 loss = 0.03370178863406181 test acc 0.8601\n",
      "2025 loss = 0.03370169550180435 test acc 0.8601\n",
      "2026 loss = 0.03370160609483719 test acc 0.8601\n",
      "2027 loss = 0.03370150923728943 test acc 0.8601\n",
      "2028 loss = 0.033701423555612564 test acc 0.8601\n",
      "2029 loss = 0.0337013304233551 test acc 0.8601\n",
      "2030 loss = 0.03370123729109764 test acc 0.8601\n",
      "2031 loss = 0.03370114788413048 test acc 0.8601\n",
      "2032 loss = 0.033701054751873016 test acc 0.8601\n",
      "2033 loss = 0.03370096907019615 test acc 0.8601\n",
      "2034 loss = 0.03370087593793869 test acc 0.8601\n",
      "2035 loss = 0.03370078653097153 test acc 0.8601\n",
      "2036 loss = 0.033700693398714066 test acc 0.8601\n",
      "2037 loss = 0.0337006039917469 test acc 0.8601\n",
      "2038 loss = 0.03370051831007004 test acc 0.8601\n",
      "2039 loss = 0.033700428903102875 test acc 0.8601\n",
      "2040 loss = 0.033700332045555115 test acc 0.8601\n",
      "2041 loss = 0.03370024636387825 test acc 0.8601\n",
      "2042 loss = 0.03370015695691109 test acc 0.8601\n",
      "2043 loss = 0.033700063824653625 test acc 0.8601\n",
      "2044 loss = 0.03369997441768646 test acc 0.8601\n",
      "2045 loss = 0.0336998887360096 test acc 0.8601\n",
      "2046 loss = 0.033699799329042435 test acc 0.8601\n",
      "2047 loss = 0.033699702471494675 test acc 0.8601\n",
      "2048 loss = 0.03369962051510811 test acc 0.8602\n",
      "2049 loss = 0.033699534833431244 test acc 0.8602\n",
      "2050 loss = 0.03369944170117378 test acc 0.8602\n",
      "2051 loss = 0.03369935601949692 test acc 0.8602\n",
      "2052 loss = 0.033699266612529755 test acc 0.8602\n",
      "2053 loss = 0.03369917720556259 test acc 0.8602\n",
      "2054 loss = 0.03369909152388573 test acc 0.8602\n",
      "2055 loss = 0.033698998391628265 test acc 0.8602\n",
      "2056 loss = 0.0336989127099514 test acc 0.8602\n",
      "2057 loss = 0.03369882330298424 test acc 0.8602\n",
      "2058 loss = 0.03369873762130737 test acc 0.8602\n",
      "2059 loss = 0.03369864821434021 test acc 0.8602\n",
      "2060 loss = 0.03369855880737305 test acc 0.8602\n",
      "2061 loss = 0.033698469400405884 test acc 0.8602\n",
      "2062 loss = 0.03369838744401932 test acc 0.8602\n",
      "2063 loss = 0.033698298037052155 test acc 0.8602\n",
      "2064 loss = 0.03369821235537529 test acc 0.8602\n",
      "2065 loss = 0.033698126673698425 test acc 0.8602\n",
      "2066 loss = 0.03369803726673126 test acc 0.8602\n",
      "2067 loss = 0.0336979478597641 test acc 0.8602\n",
      "2068 loss = 0.033697862178087234 test acc 0.8602\n",
      "2069 loss = 0.03369777649641037 test acc 0.8602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070 loss = 0.03369768708944321 test acc 0.8602\n",
      "2071 loss = 0.03369760513305664 test acc 0.8602\n",
      "2072 loss = 0.03369751572608948 test acc 0.8602\n",
      "2073 loss = 0.033697426319122314 test acc 0.8602\n",
      "2074 loss = 0.03369734436273575 test acc 0.8602\n",
      "2075 loss = 0.033697254955768585 test acc 0.8602\n",
      "2076 loss = 0.03369716927409172 test acc 0.8602\n",
      "2077 loss = 0.033697087317705154 test acc 0.8602\n",
      "2078 loss = 0.03369699791073799 test acc 0.8602\n",
      "2079 loss = 0.033696915954351425 test acc 0.8602\n",
      "2080 loss = 0.03369682654738426 test acc 0.8602\n",
      "2081 loss = 0.0336967408657074 test acc 0.8602\n",
      "2082 loss = 0.03369665518403053 test acc 0.8602\n",
      "2083 loss = 0.03369657322764397 test acc 0.8602\n",
      "2084 loss = 0.033696483820676804 test acc 0.8602\n",
      "2085 loss = 0.03369639813899994 test acc 0.8602\n",
      "2086 loss = 0.033696308732032776 test acc 0.8602\n",
      "2087 loss = 0.03369622677564621 test acc 0.8602\n",
      "2088 loss = 0.033696144819259644 test acc 0.8602\n",
      "2089 loss = 0.03369605541229248 test acc 0.8602\n",
      "2090 loss = 0.033695973455905914 test acc 0.8602\n",
      "2091 loss = 0.03369588777422905 test acc 0.8602\n",
      "2092 loss = 0.033695802092552185 test acc 0.8602\n",
      "2093 loss = 0.03369571641087532 test acc 0.8602\n",
      "2094 loss = 0.033695634454488754 test acc 0.8602\n",
      "2095 loss = 0.03369554877281189 test acc 0.8602\n",
      "2096 loss = 0.033695466816425323 test acc 0.8602\n",
      "2097 loss = 0.03369538113474846 test acc 0.8602\n",
      "2098 loss = 0.03369529917836189 test acc 0.8602\n",
      "2099 loss = 0.03369521349668503 test acc 0.8602\n",
      "2100 loss = 0.03369512781500816 test acc 0.8602\n",
      "2101 loss = 0.0336950421333313 test acc 0.8602\n",
      "2102 loss = 0.03369496017694473 test acc 0.8602\n",
      "2103 loss = 0.033694878220558167 test acc 0.8602\n",
      "2104 loss = 0.0336947925388813 test acc 0.8602\n",
      "2105 loss = 0.03369470685720444 test acc 0.8602\n",
      "2106 loss = 0.03369463235139847 test acc 0.8602\n",
      "2107 loss = 0.033694542944431305 test acc 0.8602\n",
      "2108 loss = 0.03369446098804474 test acc 0.8602\n",
      "2109 loss = 0.03369437903165817 test acc 0.8602\n",
      "2110 loss = 0.033694297075271606 test acc 0.8602\n",
      "2111 loss = 0.03369421511888504 test acc 0.8602\n",
      "2112 loss = 0.033694129437208176 test acc 0.8601\n",
      "2113 loss = 0.03369404748082161 test acc 0.8601\n",
      "2114 loss = 0.033693961799144745 test acc 0.8601\n",
      "2115 loss = 0.033693887293338776 test acc 0.8601\n",
      "2116 loss = 0.03369380161166191 test acc 0.8601\n",
      "2117 loss = 0.033693719655275345 test acc 0.8601\n",
      "2118 loss = 0.03369364142417908 test acc 0.8601\n",
      "2119 loss = 0.03369355946779251 test acc 0.8601\n",
      "2120 loss = 0.033693477511405945 test acc 0.8601\n",
      "2121 loss = 0.03369339182972908 test acc 0.8601\n",
      "2122 loss = 0.03369331359863281 test acc 0.8601\n",
      "2123 loss = 0.033693231642246246 test acc 0.8601\n",
      "2124 loss = 0.03369314968585968 test acc 0.8601\n",
      "2125 loss = 0.03369307145476341 test acc 0.8601\n",
      "2126 loss = 0.033692989498376846 test acc 0.8601\n",
      "2127 loss = 0.03369290754199028 test acc 0.8601\n",
      "2128 loss = 0.033692825585603714 test acc 0.8601\n",
      "2129 loss = 0.033692747354507446 test acc 0.8601\n",
      "2130 loss = 0.03369266539812088 test acc 0.8601\n",
      "2131 loss = 0.033692579716444016 test acc 0.8601\n",
      "2132 loss = 0.033692505210638046 test acc 0.8601\n",
      "2133 loss = 0.03369242325425148 test acc 0.8601\n",
      "2134 loss = 0.033692341297864914 test acc 0.8601\n",
      "2135 loss = 0.033692263066768646 test acc 0.8601\n",
      "2136 loss = 0.03369218111038208 test acc 0.8601\n",
      "2137 loss = 0.033692095428705215 test acc 0.8601\n",
      "2138 loss = 0.033692020922899246 test acc 0.8601\n",
      "2139 loss = 0.03369193896651268 test acc 0.8601\n",
      "2140 loss = 0.03369186073541641 test acc 0.8601\n",
      "2141 loss = 0.03369178622961044 test acc 0.8601\n",
      "2142 loss = 0.03369170054793358 test acc 0.8601\n",
      "2143 loss = 0.03369161859154701 test acc 0.8601\n",
      "2144 loss = 0.033691540360450745 test acc 0.8601\n",
      "2145 loss = 0.03369146212935448 test acc 0.8601\n",
      "2146 loss = 0.03369138389825821 test acc 0.8601\n",
      "2147 loss = 0.03369130566716194 test acc 0.8601\n",
      "2148 loss = 0.033691227436065674 test acc 0.8601\n",
      "2149 loss = 0.03369114547967911 test acc 0.8601\n",
      "2150 loss = 0.03369106352329254 test acc 0.8601\n",
      "2151 loss = 0.03369098901748657 test acc 0.8601\n",
      "2152 loss = 0.033690907061100006 test acc 0.8601\n",
      "2153 loss = 0.03369082883000374 test acc 0.8601\n",
      "2154 loss = 0.03369075804948807 test acc 0.8601\n",
      "2155 loss = 0.0336906723678112 test acc 0.8602\n",
      "2156 loss = 0.033690594136714935 test acc 0.8602\n",
      "2157 loss = 0.03369051590561867 test acc 0.8602\n",
      "2158 loss = 0.0336904376745224 test acc 0.8602\n",
      "2159 loss = 0.03369036316871643 test acc 0.8602\n",
      "2160 loss = 0.03369028493762016 test acc 0.8602\n",
      "2161 loss = 0.033690206706523895 test acc 0.8602\n",
      "2162 loss = 0.033690132200717926 test acc 0.8602\n",
      "2163 loss = 0.03369005024433136 test acc 0.8602\n",
      "2164 loss = 0.03368997573852539 test acc 0.8602\n",
      "2165 loss = 0.03368989750742912 test acc 0.8602\n",
      "2166 loss = 0.033689819276332855 test acc 0.8602\n",
      "2167 loss = 0.033689744770526886 test acc 0.8602\n",
      "2168 loss = 0.03368966653943062 test acc 0.8602\n",
      "2169 loss = 0.03368958830833435 test acc 0.8602\n",
      "2170 loss = 0.033689506351947784 test acc 0.8602\n",
      "2171 loss = 0.033689435571432114 test acc 0.8602\n",
      "2172 loss = 0.03368935361504555 test acc 0.8602\n",
      "2173 loss = 0.03368928283452988 test acc 0.8602\n",
      "2174 loss = 0.03368920460343361 test acc 0.8602\n",
      "2175 loss = 0.03368912637233734 test acc 0.8602\n",
      "2176 loss = 0.03368905186653137 test acc 0.8602\n",
      "2177 loss = 0.033688969910144806 test acc 0.8602\n",
      "2178 loss = 0.03368889540433884 test acc 0.8602\n",
      "2179 loss = 0.03368881717324257 test acc 0.8602\n",
      "2180 loss = 0.0336887389421463 test acc 0.8602\n",
      "2181 loss = 0.03368866443634033 test acc 0.8602\n",
      "2182 loss = 0.03368858993053436 test acc 0.8602\n",
      "2183 loss = 0.033688511699438095 test acc 0.8602\n",
      "2184 loss = 0.03368843346834183 test acc 0.8602\n",
      "2185 loss = 0.03368835896253586 test acc 0.8602\n",
      "2186 loss = 0.03368828818202019 test acc 0.8602\n",
      "2187 loss = 0.03368820622563362 test acc 0.8602\n",
      "2188 loss = 0.03368813171982765 test acc 0.8602\n",
      "2189 loss = 0.03368805721402168 test acc 0.8602\n",
      "2190 loss = 0.03368797525763512 test acc 0.8602\n",
      "2191 loss = 0.033687904477119446 test acc 0.8602\n",
      "2192 loss = 0.03368782997131348 test acc 0.8602\n",
      "2193 loss = 0.03368775546550751 test acc 0.8602\n",
      "2194 loss = 0.03368768095970154 test acc 0.8602\n",
      "2195 loss = 0.03368760645389557 test acc 0.8602\n",
      "2196 loss = 0.0336875319480896 test acc 0.8602\n",
      "2197 loss = 0.03368745744228363 test acc 0.8602\n",
      "2198 loss = 0.03368737921118736 test acc 0.8602\n",
      "2199 loss = 0.03368730843067169 test acc 0.8602\n",
      "2200 loss = 0.033687230199575424 test acc 0.8602\n",
      "2201 loss = 0.03368715941905975 test acc 0.8602\n",
      "2202 loss = 0.033687084913253784 test acc 0.8602\n",
      "2203 loss = 0.033687010407447815 test acc 0.8602\n",
      "2204 loss = 0.033686935901641846 test acc 0.8602\n",
      "2205 loss = 0.033686861395835876 test acc 0.8602\n",
      "2206 loss = 0.033686790615320206 test acc 0.8602\n",
      "2207 loss = 0.03368671238422394 test acc 0.8602\n",
      "2208 loss = 0.03368663787841797 test acc 0.8602\n",
      "2209 loss = 0.0336865670979023 test acc 0.8602\n",
      "2210 loss = 0.03368648886680603 test acc 0.8602\n",
      "2211 loss = 0.03368641808629036 test acc 0.8602\n",
      "2212 loss = 0.03368634730577469 test acc 0.8601\n",
      "2213 loss = 0.03368627279996872 test acc 0.8601\n",
      "2214 loss = 0.03368619829416275 test acc 0.8601\n",
      "2215 loss = 0.03368612378835678 test acc 0.8601\n",
      "2216 loss = 0.03368605300784111 test acc 0.8601\n",
      "2217 loss = 0.03368597477674484 test acc 0.8601\n",
      "2218 loss = 0.03368590027093887 test acc 0.8601\n",
      "2219 loss = 0.0336858294904232 test acc 0.8601\n",
      "2220 loss = 0.03368575870990753 test acc 0.8601\n",
      "2221 loss = 0.03368568792939186 test acc 0.8601\n",
      "2222 loss = 0.03368561342358589 test acc 0.8601\n",
      "2223 loss = 0.03368553891777992 test acc 0.8601\n",
      "2224 loss = 0.03368546813726425 test acc 0.8601\n",
      "2225 loss = 0.03368539363145828 test acc 0.8601\n",
      "2226 loss = 0.03368532285094261 test acc 0.8601\n",
      "2227 loss = 0.03368524834513664 test acc 0.8601\n",
      "2228 loss = 0.03368517383933067 test acc 0.8601\n",
      "2229 loss = 0.033685103058815 test acc 0.8601\n",
      "2230 loss = 0.03368503227829933 test acc 0.8601\n",
      "2231 loss = 0.03368496149778366 test acc 0.8601\n",
      "2232 loss = 0.03368488699197769 test acc 0.8601\n",
      "2233 loss = 0.03368481621146202 test acc 0.8601\n",
      "2234 loss = 0.03368474543094635 test acc 0.8601\n",
      "2235 loss = 0.03368467092514038 test acc 0.8601\n",
      "2236 loss = 0.03368460014462471 test acc 0.8601\n",
      "2237 loss = 0.03368452936410904 test acc 0.8601\n",
      "2238 loss = 0.03368445485830307 test acc 0.8601\n",
      "2239 loss = 0.0336843878030777 test acc 0.8601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2240 loss = 0.03368431702256203 test acc 0.8601\n",
      "2241 loss = 0.03368424251675606 test acc 0.8601\n",
      "2242 loss = 0.03368417173624039 test acc 0.8601\n",
      "2243 loss = 0.033684104681015015 test acc 0.8601\n",
      "2244 loss = 0.033684033900499344 test acc 0.8601\n",
      "2245 loss = 0.033683959394693375 test acc 0.8601\n",
      "2246 loss = 0.0336838960647583 test acc 0.8601\n",
      "2247 loss = 0.03368382155895233 test acc 0.8601\n",
      "2248 loss = 0.03368375077843666 test acc 0.8601\n",
      "2249 loss = 0.03368368372321129 test acc 0.8601\n",
      "2250 loss = 0.03368361294269562 test acc 0.8601\n",
      "2251 loss = 0.03368353843688965 test acc 0.8601\n",
      "2252 loss = 0.033683471381664276 test acc 0.8601\n",
      "2253 loss = 0.033683400601148605 test acc 0.8601\n",
      "2254 loss = 0.033683329820632935 test acc 0.8601\n",
      "2255 loss = 0.03368326276540756 test acc 0.8601\n",
      "2256 loss = 0.03368319198489189 test acc 0.8601\n",
      "2257 loss = 0.03368312492966652 test acc 0.8601\n",
      "2258 loss = 0.03368305042386055 test acc 0.8601\n",
      "2259 loss = 0.03368297591805458 test acc 0.8601\n",
      "2260 loss = 0.03368290886282921 test acc 0.8601\n",
      "2261 loss = 0.033682841807603836 test acc 0.8601\n",
      "2262 loss = 0.033682771027088165 test acc 0.8601\n",
      "2263 loss = 0.033682700246572495 test acc 0.8601\n",
      "2264 loss = 0.03368263691663742 test acc 0.8601\n",
      "2265 loss = 0.03368256241083145 test acc 0.8601\n",
      "2266 loss = 0.03368249535560608 test acc 0.8601\n",
      "2267 loss = 0.03368242830038071 test acc 0.8601\n",
      "2268 loss = 0.033682357519865036 test acc 0.8601\n",
      "2269 loss = 0.033682286739349365 test acc 0.8601\n",
      "2270 loss = 0.033682215958833694 test acc 0.8601\n",
      "2271 loss = 0.03368214890360832 test acc 0.8601\n",
      "2272 loss = 0.03368208184838295 test acc 0.8601\n",
      "2273 loss = 0.03368201479315758 test acc 0.8601\n",
      "2274 loss = 0.03368194401264191 test acc 0.8601\n",
      "2275 loss = 0.033681876957416534 test acc 0.8601\n",
      "2276 loss = 0.033681806176900864 test acc 0.8601\n",
      "2277 loss = 0.03368173539638519 test acc 0.8601\n",
      "2278 loss = 0.03368166834115982 test acc 0.8601\n",
      "2279 loss = 0.03368160501122475 test acc 0.8601\n",
      "2280 loss = 0.033681534230709076 test acc 0.8601\n",
      "2281 loss = 0.033681463450193405 test acc 0.8601\n",
      "2282 loss = 0.03368139639496803 test acc 0.8601\n",
      "2283 loss = 0.03368132561445236 test acc 0.8601\n",
      "2284 loss = 0.03368125483393669 test acc 0.8601\n",
      "2285 loss = 0.03368119150400162 test acc 0.8601\n",
      "2286 loss = 0.033681124448776245 test acc 0.8601\n",
      "2287 loss = 0.033681053668260574 test acc 0.8601\n",
      "2288 loss = 0.0336809903383255 test acc 0.8601\n",
      "2289 loss = 0.03368092328310013 test acc 0.8601\n",
      "2290 loss = 0.03368085250258446 test acc 0.8601\n",
      "2291 loss = 0.033680789172649384 test acc 0.8602\n",
      "2292 loss = 0.03368072211742401 test acc 0.8602\n",
      "2293 loss = 0.03368065133690834 test acc 0.8602\n",
      "2294 loss = 0.03368058800697327 test acc 0.8602\n",
      "2295 loss = 0.033680517226457596 test acc 0.8602\n",
      "2296 loss = 0.033680450171232224 test acc 0.8602\n",
      "2297 loss = 0.03368038684129715 test acc 0.8602\n",
      "2298 loss = 0.03368031606078148 test acc 0.8602\n",
      "2299 loss = 0.033680252730846405 test acc 0.8602\n",
      "2300 loss = 0.033680181950330734 test acc 0.8602\n",
      "2301 loss = 0.03368011862039566 test acc 0.8602\n",
      "2302 loss = 0.03368005156517029 test acc 0.8603\n",
      "2303 loss = 0.033679988235235214 test acc 0.8603\n",
      "2304 loss = 0.03367992118000984 test acc 0.8603\n",
      "2305 loss = 0.03367985412478447 test acc 0.8603\n",
      "2306 loss = 0.0336797833442688 test acc 0.8603\n",
      "2307 loss = 0.033679720014333725 test acc 0.8603\n",
      "2308 loss = 0.03367965295910835 test acc 0.8603\n",
      "2309 loss = 0.03367958962917328 test acc 0.8603\n",
      "2310 loss = 0.033679522573947906 test acc 0.8603\n",
      "2311 loss = 0.03367946296930313 test acc 0.8603\n",
      "2312 loss = 0.03367939218878746 test acc 0.8603\n",
      "2313 loss = 0.03367932513356209 test acc 0.8604\n",
      "2314 loss = 0.033679261803627014 test acc 0.8604\n",
      "2315 loss = 0.03367919474840164 test acc 0.8604\n",
      "2316 loss = 0.03367912769317627 test acc 0.8605\n",
      "2317 loss = 0.033679064363241196 test acc 0.8605\n",
      "2318 loss = 0.03367899730801582 test acc 0.8605\n",
      "2319 loss = 0.03367893397808075 test acc 0.8605\n",
      "2320 loss = 0.033678870648145676 test acc 0.8605\n",
      "2321 loss = 0.033678799867630005 test acc 0.8605\n",
      "2322 loss = 0.03367873653769493 test acc 0.8605\n",
      "2323 loss = 0.03367866948246956 test acc 0.8605\n",
      "2324 loss = 0.033678606152534485 test acc 0.8605\n",
      "2325 loss = 0.03367854282259941 test acc 0.8605\n",
      "2326 loss = 0.03367847949266434 test acc 0.8605\n",
      "2327 loss = 0.03367841616272926 test acc 0.8605\n",
      "2328 loss = 0.03367834910750389 test acc 0.8605\n",
      "2329 loss = 0.03367828205227852 test acc 0.8605\n",
      "2330 loss = 0.033678214997053146 test acc 0.8605\n",
      "2331 loss = 0.03367815539240837 test acc 0.8605\n",
      "2332 loss = 0.033678088337183 test acc 0.8605\n",
      "2333 loss = 0.033678025007247925 test acc 0.8605\n",
      "2334 loss = 0.03367796167731285 test acc 0.8605\n",
      "2335 loss = 0.03367789462208748 test acc 0.8605\n",
      "2336 loss = 0.0336778350174427 test acc 0.8605\n",
      "2337 loss = 0.03367776796221733 test acc 0.8605\n",
      "2338 loss = 0.03367770463228226 test acc 0.8605\n",
      "2339 loss = 0.03367764130234718 test acc 0.8605\n",
      "2340 loss = 0.03367757797241211 test acc 0.8605\n",
      "2341 loss = 0.03367751091718674 test acc 0.8605\n",
      "2342 loss = 0.03367745131254196 test acc 0.8605\n",
      "2343 loss = 0.03367738425731659 test acc 0.8605\n",
      "2344 loss = 0.033677320927381516 test acc 0.8605\n",
      "2345 loss = 0.03367725759744644 test acc 0.8605\n",
      "2346 loss = 0.03367719426751137 test acc 0.8605\n",
      "2347 loss = 0.03367713466286659 test acc 0.8605\n",
      "2348 loss = 0.03367706760764122 test acc 0.8605\n",
      "2349 loss = 0.033677008002996445 test acc 0.8605\n",
      "2350 loss = 0.03367694094777107 test acc 0.8605\n",
      "2351 loss = 0.0336768813431263 test acc 0.8605\n",
      "2352 loss = 0.03367681801319122 test acc 0.8605\n",
      "2353 loss = 0.03367675095796585 test acc 0.8605\n",
      "2354 loss = 0.033676695078611374 test acc 0.8605\n",
      "2355 loss = 0.033676628023386 test acc 0.8605\n",
      "2356 loss = 0.03367656469345093 test acc 0.8606\n",
      "2357 loss = 0.033676501363515854 test acc 0.8606\n",
      "2358 loss = 0.03367644175887108 test acc 0.8606\n",
      "2359 loss = 0.033676378428936005 test acc 0.8606\n",
      "2360 loss = 0.03367631882429123 test acc 0.8606\n",
      "2361 loss = 0.033676255494356155 test acc 0.8606\n",
      "2362 loss = 0.03367619216442108 test acc 0.8606\n",
      "2363 loss = 0.033676132559776306 test acc 0.8606\n",
      "2364 loss = 0.03367606922984123 test acc 0.8606\n",
      "2365 loss = 0.03367600589990616 test acc 0.8606\n",
      "2366 loss = 0.033675942569971085 test acc 0.8606\n",
      "2367 loss = 0.03367588669061661 test acc 0.8606\n",
      "2368 loss = 0.033675819635391235 test acc 0.8606\n",
      "2369 loss = 0.03367575630545616 test acc 0.8606\n",
      "2370 loss = 0.033675696700811386 test acc 0.8606\n",
      "2371 loss = 0.03367563337087631 test acc 0.8606\n",
      "2372 loss = 0.03367557004094124 test acc 0.8605\n",
      "2373 loss = 0.03367551416158676 test acc 0.8605\n",
      "2374 loss = 0.03367545083165169 test acc 0.8605\n",
      "2375 loss = 0.033675387501716614 test acc 0.8605\n",
      "2376 loss = 0.03367532789707184 test acc 0.8605\n",
      "2377 loss = 0.033675264567136765 test acc 0.8605\n",
      "2378 loss = 0.03367520496249199 test acc 0.8605\n",
      "2379 loss = 0.033675141632556915 test acc 0.8605\n",
      "2380 loss = 0.03367508202791214 test acc 0.8605\n",
      "2381 loss = 0.03367502614855766 test acc 0.8605\n",
      "2382 loss = 0.03367495909333229 test acc 0.8605\n",
      "2383 loss = 0.033674903213977814 test acc 0.8605\n",
      "2384 loss = 0.03367483988404274 test acc 0.8605\n",
      "2385 loss = 0.033674776554107666 test acc 0.8605\n",
      "2386 loss = 0.03367472067475319 test acc 0.8605\n",
      "2387 loss = 0.033674661070108414 test acc 0.8605\n",
      "2388 loss = 0.03367459774017334 test acc 0.8605\n",
      "2389 loss = 0.033674534410238266 test acc 0.8605\n",
      "2390 loss = 0.03367447853088379 test acc 0.8605\n",
      "2391 loss = 0.033674418926239014 test acc 0.8605\n",
      "2392 loss = 0.03367435932159424 test acc 0.8605\n",
      "2393 loss = 0.033674295991659164 test acc 0.8605\n",
      "2394 loss = 0.03367423266172409 test acc 0.8605\n",
      "2395 loss = 0.033674176782369614 test acc 0.8605\n",
      "2396 loss = 0.03367411717772484 test acc 0.8605\n",
      "2397 loss = 0.03367406129837036 test acc 0.8605\n",
      "2398 loss = 0.03367399424314499 test acc 0.8605\n",
      "2399 loss = 0.03367393836379051 test acc 0.8605\n",
      "2400 loss = 0.03367387875914574 test acc 0.8605\n",
      "2401 loss = 0.03367381915450096 test acc 0.8605\n",
      "2402 loss = 0.033673759549856186 test acc 0.8605\n",
      "2403 loss = 0.03367369994521141 test acc 0.8605\n",
      "2404 loss = 0.033673640340566635 test acc 0.8605\n",
      "2405 loss = 0.03367357701063156 test acc 0.8605\n",
      "2406 loss = 0.033673521131277084 test acc 0.8605\n",
      "2407 loss = 0.03367345780134201 test acc 0.8605\n",
      "2408 loss = 0.033673401921987534 test acc 0.8605\n",
      "2409 loss = 0.03367333859205246 test acc 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410 loss = 0.033673278987407684 test acc 0.8605\n",
      "2411 loss = 0.03367321938276291 test acc 0.8605\n",
      "2412 loss = 0.033673156052827835 test acc 0.8605\n",
      "2413 loss = 0.03367310017347336 test acc 0.8605\n",
      "2414 loss = 0.03367304056882858 test acc 0.8605\n",
      "2415 loss = 0.03367298096418381 test acc 0.8605\n",
      "2416 loss = 0.03367292135953903 test acc 0.8605\n",
      "2417 loss = 0.033672865480184555 test acc 0.8605\n",
      "2418 loss = 0.03367280960083008 test acc 0.8605\n",
      "2419 loss = 0.033672746270895004 test acc 0.8605\n",
      "2420 loss = 0.03367269039154053 test acc 0.8605\n",
      "2421 loss = 0.03367263078689575 test acc 0.8605\n",
      "2422 loss = 0.033672574907541275 test acc 0.8605\n",
      "2423 loss = 0.0336725153028965 test acc 0.8605\n",
      "2424 loss = 0.03367245942354202 test acc 0.8605\n",
      "2425 loss = 0.03367239981889725 test acc 0.8605\n",
      "2426 loss = 0.03367234393954277 test acc 0.8605\n",
      "2427 loss = 0.0336722806096077 test acc 0.8605\n",
      "2428 loss = 0.03367222473025322 test acc 0.8605\n",
      "2429 loss = 0.033672161400318146 test acc 0.8605\n",
      "2430 loss = 0.03367210552096367 test acc 0.8605\n",
      "2431 loss = 0.03367204964160919 test acc 0.8605\n",
      "2432 loss = 0.033671990036964417 test acc 0.8605\n",
      "2433 loss = 0.03367193415760994 test acc 0.8605\n",
      "2434 loss = 0.033671874552965164 test acc 0.8605\n",
      "2435 loss = 0.03367181867361069 test acc 0.8605\n",
      "2436 loss = 0.03367176279425621 test acc 0.8605\n",
      "2437 loss = 0.033671699464321136 test acc 0.8605\n",
      "2438 loss = 0.03367164358496666 test acc 0.8605\n",
      "2439 loss = 0.033671583980321884 test acc 0.8605\n",
      "2440 loss = 0.033671531826257706 test acc 0.8605\n",
      "2441 loss = 0.03367147222161293 test acc 0.8605\n",
      "2442 loss = 0.033671412616968155 test acc 0.8605\n",
      "2443 loss = 0.033671360462903976 test acc 0.8605\n",
      "2444 loss = 0.0336713008582592 test acc 0.8605\n",
      "2445 loss = 0.033671244978904724 test acc 0.8605\n",
      "2446 loss = 0.03367118537425995 test acc 0.8605\n",
      "2447 loss = 0.03367113322019577 test acc 0.8605\n",
      "2448 loss = 0.033671069890260696 test acc 0.8605\n",
      "2449 loss = 0.03367101401090622 test acc 0.8605\n",
      "2450 loss = 0.03367095813155174 test acc 0.8605\n",
      "2451 loss = 0.033670902252197266 test acc 0.8605\n",
      "2452 loss = 0.03367084264755249 test acc 0.8605\n",
      "2453 loss = 0.03367078676819801 test acc 0.8605\n",
      "2454 loss = 0.033670734614133835 test acc 0.8605\n",
      "2455 loss = 0.03367067873477936 test acc 0.8605\n",
      "2456 loss = 0.03367061913013458 test acc 0.8605\n",
      "2457 loss = 0.0336705707013607 test acc 0.8605\n",
      "2458 loss = 0.03367050737142563 test acc 0.8605\n",
      "2459 loss = 0.03367045149207115 test acc 0.8605\n",
      "2460 loss = 0.033670395612716675 test acc 0.8605\n",
      "2461 loss = 0.0336703397333622 test acc 0.8605\n",
      "2462 loss = 0.03367028757929802 test acc 0.8605\n",
      "2463 loss = 0.03367023169994354 test acc 0.8605\n",
      "2464 loss = 0.03367017209529877 test acc 0.8605\n",
      "2465 loss = 0.03367011994123459 test acc 0.8605\n",
      "2466 loss = 0.03367006406188011 test acc 0.8605\n",
      "2467 loss = 0.033670004457235336 test acc 0.8605\n",
      "2468 loss = 0.03366995230317116 test acc 0.8605\n",
      "2469 loss = 0.03366989269852638 test acc 0.8605\n",
      "2470 loss = 0.033669836819171906 test acc 0.8605\n",
      "2471 loss = 0.03366978466510773 test acc 0.8605\n",
      "2472 loss = 0.03366972878575325 test acc 0.8605\n",
      "2473 loss = 0.03366967290639877 test acc 0.8605\n",
      "2474 loss = 0.033669613301754 test acc 0.8605\n",
      "2475 loss = 0.03366956114768982 test acc 0.8605\n",
      "2476 loss = 0.03366950526833534 test acc 0.8605\n",
      "2477 loss = 0.033669453114271164 test acc 0.8605\n",
      "2478 loss = 0.03366939723491669 test acc 0.8605\n",
      "2479 loss = 0.03366934135556221 test acc 0.8605\n",
      "2480 loss = 0.03366928547620773 test acc 0.8605\n",
      "2481 loss = 0.033669233322143555 test acc 0.8605\n",
      "2482 loss = 0.03366917744278908 test acc 0.8605\n",
      "2483 loss = 0.0336691215634346 test acc 0.8605\n",
      "2484 loss = 0.033669065684080124 test acc 0.8605\n",
      "2485 loss = 0.03366900980472565 test acc 0.8605\n",
      "2486 loss = 0.03366895392537117 test acc 0.8605\n",
      "2487 loss = 0.03366890177130699 test acc 0.8605\n",
      "2488 loss = 0.033668845891952515 test acc 0.8605\n",
      "2489 loss = 0.03366878628730774 test acc 0.8605\n",
      "2490 loss = 0.03366873785853386 test acc 0.8605\n",
      "2491 loss = 0.03366868197917938 test acc 0.8605\n",
      "2492 loss = 0.033668626099824905 test acc 0.8605\n",
      "2493 loss = 0.03366857394576073 test acc 0.8605\n",
      "2494 loss = 0.03366851806640625 test acc 0.8605\n",
      "2495 loss = 0.03366846218705177 test acc 0.8605\n",
      "2496 loss = 0.033668410032987595 test acc 0.8605\n",
      "2497 loss = 0.033668357878923416 test acc 0.8605\n",
      "2498 loss = 0.03366830199956894 test acc 0.8605\n",
      "2499 loss = 0.03366824984550476 test acc 0.8605\n",
      "2500 loss = 0.033668193966150284 test acc 0.8605\n",
      "2501 loss = 0.033668141812086105 test acc 0.8605\n",
      "2502 loss = 0.03366808593273163 test acc 0.8605\n",
      "2503 loss = 0.03366803377866745 test acc 0.8605\n",
      "2504 loss = 0.03366798162460327 test acc 0.8605\n",
      "2505 loss = 0.033667925745248795 test acc 0.8605\n",
      "2506 loss = 0.033667877316474915 test acc 0.8605\n",
      "2507 loss = 0.03366782143712044 test acc 0.8605\n",
      "2508 loss = 0.03366776555776596 test acc 0.8605\n",
      "2509 loss = 0.03366771340370178 test acc 0.8605\n",
      "2510 loss = 0.033667661249637604 test acc 0.8605\n",
      "2511 loss = 0.03366760164499283 test acc 0.8605\n",
      "2512 loss = 0.03366755321621895 test acc 0.8605\n",
      "2513 loss = 0.03366750106215477 test acc 0.8605\n",
      "2514 loss = 0.03366744518280029 test acc 0.8605\n",
      "2515 loss = 0.03366739675402641 test acc 0.8605\n",
      "2516 loss = 0.033667340874671936 test acc 0.8605\n",
      "2517 loss = 0.03366728872060776 test acc 0.8605\n",
      "2518 loss = 0.03366723284125328 test acc 0.8605\n",
      "2519 loss = 0.0336671844124794 test acc 0.8605\n",
      "2520 loss = 0.03366713225841522 test acc 0.8605\n",
      "2521 loss = 0.033667076379060745 test acc 0.8605\n",
      "2522 loss = 0.03366702422499657 test acc 0.8605\n",
      "2523 loss = 0.03366697207093239 test acc 0.8605\n",
      "2524 loss = 0.03366691991686821 test acc 0.8605\n",
      "2525 loss = 0.03366686403751373 test acc 0.8605\n",
      "2526 loss = 0.033666811883449554 test acc 0.8605\n",
      "2527 loss = 0.033666759729385376 test acc 0.8605\n",
      "2528 loss = 0.033666711300611496 test acc 0.8605\n",
      "2529 loss = 0.03366665914654732 test acc 0.8605\n",
      "2530 loss = 0.03366660326719284 test acc 0.8605\n",
      "2531 loss = 0.03366655111312866 test acc 0.8605\n",
      "2532 loss = 0.03366650268435478 test acc 0.8605\n",
      "2533 loss = 0.033666446805000305 test acc 0.8605\n",
      "2534 loss = 0.03366639465093613 test acc 0.8605\n",
      "2535 loss = 0.03366633877158165 test acc 0.8605\n",
      "2536 loss = 0.03366628661751747 test acc 0.8605\n",
      "2537 loss = 0.03366623446345329 test acc 0.8605\n",
      "2538 loss = 0.03366618603467941 test acc 0.8605\n",
      "2539 loss = 0.033666130155324936 test acc 0.8605\n",
      "2540 loss = 0.03366607800126076 test acc 0.8605\n",
      "2541 loss = 0.03366602957248688 test acc 0.8605\n",
      "2542 loss = 0.0336659774184227 test acc 0.8605\n",
      "2543 loss = 0.03366592526435852 test acc 0.8605\n",
      "2544 loss = 0.03366587311029434 test acc 0.8605\n",
      "2545 loss = 0.033665820956230164 test acc 0.8605\n",
      "2546 loss = 0.033665772527456284 test acc 0.8605\n",
      "2547 loss = 0.033665720373392105 test acc 0.8605\n",
      "2548 loss = 0.03366566449403763 test acc 0.8605\n",
      "2549 loss = 0.03366561606526375 test acc 0.8605\n",
      "2550 loss = 0.03366556391119957 test acc 0.8605\n",
      "2551 loss = 0.03366551548242569 test acc 0.8605\n",
      "2552 loss = 0.03366546332836151 test acc 0.8605\n",
      "2553 loss = 0.03366541117429733 test acc 0.8605\n",
      "2554 loss = 0.033665359020233154 test acc 0.8605\n",
      "2555 loss = 0.033665306866168976 test acc 0.8605\n",
      "2556 loss = 0.0336652509868145 test acc 0.8605\n",
      "2557 loss = 0.03366520628333092 test acc 0.8605\n",
      "2558 loss = 0.03366515412926674 test acc 0.8605\n",
      "2559 loss = 0.03366510197520256 test acc 0.8605\n",
      "2560 loss = 0.03366504982113838 test acc 0.8605\n",
      "2561 loss = 0.0336650013923645 test acc 0.8605\n",
      "2562 loss = 0.033664949238300323 test acc 0.8605\n",
      "2563 loss = 0.033664897084236145 test acc 0.8605\n",
      "2564 loss = 0.033664848655462265 test acc 0.8605\n",
      "2565 loss = 0.03366479650139809 test acc 0.8605\n",
      "2566 loss = 0.03366474807262421 test acc 0.8605\n",
      "2567 loss = 0.03366469591856003 test acc 0.8605\n",
      "2568 loss = 0.03366464376449585 test acc 0.8605\n",
      "2569 loss = 0.03366459906101227 test acc 0.8605\n",
      "2570 loss = 0.03366454690694809 test acc 0.8605\n",
      "2571 loss = 0.03366449475288391 test acc 0.8605\n",
      "2572 loss = 0.03366444259881973 test acc 0.8605\n",
      "2573 loss = 0.03366439417004585 test acc 0.8605\n",
      "2574 loss = 0.03366434574127197 test acc 0.8605\n",
      "2575 loss = 0.033664293587207794 test acc 0.8605\n",
      "2576 loss = 0.033664241433143616 test acc 0.8605\n",
      "2577 loss = 0.033664193004369736 test acc 0.8605\n",
      "2578 loss = 0.03366414085030556 test acc 0.8605\n",
      "2579 loss = 0.03366409242153168 test acc 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2580 loss = 0.033664047718048096 test acc 0.8605\n",
      "2581 loss = 0.03366399556398392 test acc 0.8605\n",
      "2582 loss = 0.03366394713521004 test acc 0.8605\n",
      "2583 loss = 0.03366389498114586 test acc 0.8605\n",
      "2584 loss = 0.03366384655237198 test acc 0.8605\n",
      "2585 loss = 0.0336637943983078 test acc 0.8605\n",
      "2586 loss = 0.03366374969482422 test acc 0.8605\n",
      "2587 loss = 0.03366369754076004 test acc 0.8605\n",
      "2588 loss = 0.03366364911198616 test acc 0.8605\n",
      "2589 loss = 0.03366359695792198 test acc 0.8605\n",
      "2590 loss = 0.0336635485291481 test acc 0.8605\n",
      "2591 loss = 0.03366349637508392 test acc 0.8605\n",
      "2592 loss = 0.03366344794631004 test acc 0.8605\n",
      "2593 loss = 0.03366340324282646 test acc 0.8605\n",
      "2594 loss = 0.03366335108876228 test acc 0.8605\n",
      "2595 loss = 0.0336633026599884 test acc 0.8605\n",
      "2596 loss = 0.03366325423121452 test acc 0.8605\n",
      "2597 loss = 0.033663202077150345 test acc 0.8605\n",
      "2598 loss = 0.03366315737366676 test acc 0.8605\n",
      "2599 loss = 0.033663105219602585 test acc 0.8605\n",
      "2600 loss = 0.033663060516119 test acc 0.8605\n",
      "2601 loss = 0.033663008362054825 test acc 0.8605\n",
      "2602 loss = 0.03366296365857124 test acc 0.8605\n",
      "2603 loss = 0.033662911504507065 test acc 0.8605\n",
      "2604 loss = 0.033662859350442886 test acc 0.8605\n",
      "2605 loss = 0.0336628183722496 test acc 0.8605\n",
      "2606 loss = 0.033662766218185425 test acc 0.8605\n",
      "2607 loss = 0.033662717789411545 test acc 0.8605\n",
      "2608 loss = 0.033662669360637665 test acc 0.8605\n",
      "2609 loss = 0.033662617206573486 test acc 0.8605\n",
      "2610 loss = 0.033662572503089905 test acc 0.8605\n",
      "2611 loss = 0.033662520349025726 test acc 0.8605\n",
      "2612 loss = 0.033662475645542145 test acc 0.8605\n",
      "2613 loss = 0.033662427216768265 test acc 0.8605\n",
      "2614 loss = 0.033662378787994385 test acc 0.8604\n",
      "2615 loss = 0.033662330359220505 test acc 0.8604\n",
      "2616 loss = 0.033662281930446625 test acc 0.8604\n",
      "2617 loss = 0.033662233501672745 test acc 0.8604\n",
      "2618 loss = 0.033662185072898865 test acc 0.8604\n",
      "2619 loss = 0.033662136644124985 test acc 0.8604\n",
      "2620 loss = 0.0336620919406414 test acc 0.8604\n",
      "2621 loss = 0.03366204351186752 test acc 0.8604\n",
      "2622 loss = 0.03366199508309364 test acc 0.8604\n",
      "2623 loss = 0.033661942929029465 test acc 0.8604\n",
      "2624 loss = 0.03366190195083618 test acc 0.8604\n",
      "2625 loss = 0.033661849796772 test acc 0.8604\n",
      "2626 loss = 0.03366180509328842 test acc 0.8604\n",
      "2627 loss = 0.03366175293922424 test acc 0.8604\n",
      "2628 loss = 0.03366170823574066 test acc 0.8604\n",
      "2629 loss = 0.03366165980696678 test acc 0.8604\n",
      "2630 loss = 0.0336616151034832 test acc 0.8603\n",
      "2631 loss = 0.03366157039999962 test acc 0.8603\n",
      "2632 loss = 0.03366152197122574 test acc 0.8603\n",
      "2633 loss = 0.03366147726774216 test acc 0.8603\n",
      "2634 loss = 0.03366142883896828 test acc 0.8603\n",
      "2635 loss = 0.0336613804101944 test acc 0.8603\n",
      "2636 loss = 0.033661335706710815 test acc 0.8603\n",
      "2637 loss = 0.033661287277936935 test acc 0.8603\n",
      "2638 loss = 0.033661242574453354 test acc 0.8603\n",
      "2639 loss = 0.033661194145679474 test acc 0.8603\n",
      "2640 loss = 0.033661145716905594 test acc 0.8603\n",
      "2641 loss = 0.03366110101342201 test acc 0.8603\n",
      "2642 loss = 0.033661048859357834 test acc 0.8603\n",
      "2643 loss = 0.03366100415587425 test acc 0.8603\n",
      "2644 loss = 0.03366095572710037 test acc 0.8603\n",
      "2645 loss = 0.03366091474890709 test acc 0.8603\n",
      "2646 loss = 0.03366086259484291 test acc 0.8603\n",
      "2647 loss = 0.03366081789135933 test acc 0.8603\n",
      "2648 loss = 0.03366077318787575 test acc 0.8603\n",
      "2649 loss = 0.033660728484392166 test acc 0.8603\n",
      "2650 loss = 0.03366067633032799 test acc 0.8603\n",
      "2651 loss = 0.033660631626844406 test acc 0.8603\n",
      "2652 loss = 0.033660586923360825 test acc 0.8603\n",
      "2653 loss = 0.03366054221987724 test acc 0.8603\n",
      "2654 loss = 0.03366049379110336 test acc 0.8603\n",
      "2655 loss = 0.03366044908761978 test acc 0.8603\n",
      "2656 loss = 0.0336604006588459 test acc 0.8603\n",
      "2657 loss = 0.03366035595536232 test acc 0.8603\n",
      "2658 loss = 0.03366031125187874 test acc 0.8603\n",
      "2659 loss = 0.033660270273685455 test acc 0.8603\n",
      "2660 loss = 0.03366021439433098 test acc 0.8603\n",
      "2661 loss = 0.0336601696908474 test acc 0.8603\n",
      "2662 loss = 0.033660124987363815 test acc 0.8603\n",
      "2663 loss = 0.03366008400917053 test acc 0.8603\n",
      "2664 loss = 0.03366003558039665 test acc 0.8603\n",
      "2665 loss = 0.03365998715162277 test acc 0.8603\n",
      "2666 loss = 0.03365994244813919 test acc 0.8603\n",
      "2667 loss = 0.03365989774465561 test acc 0.8603\n",
      "2668 loss = 0.03365984931588173 test acc 0.8603\n",
      "2669 loss = 0.033659808337688446 test acc 0.8603\n",
      "2670 loss = 0.033659759908914566 test acc 0.8603\n",
      "2671 loss = 0.033659711480140686 test acc 0.8603\n",
      "2672 loss = 0.033659666776657104 test acc 0.8603\n",
      "2673 loss = 0.03365962207317352 test acc 0.8603\n",
      "2674 loss = 0.03365957736968994 test acc 0.8603\n",
      "2675 loss = 0.03365952894091606 test acc 0.8603\n",
      "2676 loss = 0.03365948423743248 test acc 0.8603\n",
      "2677 loss = 0.0336594395339489 test acc 0.8603\n",
      "2678 loss = 0.03365939483046532 test acc 0.8603\n",
      "2679 loss = 0.03365934640169144 test acc 0.8603\n",
      "2680 loss = 0.033659305423498154 test acc 0.8603\n",
      "2681 loss = 0.03365926072001457 test acc 0.8603\n",
      "2682 loss = 0.03365921601653099 test acc 0.8603\n",
      "2683 loss = 0.03365916758775711 test acc 0.8603\n",
      "2684 loss = 0.03365912660956383 test acc 0.8603\n",
      "2685 loss = 0.03365907445549965 test acc 0.8603\n",
      "2686 loss = 0.033659037202596664 test acc 0.8603\n",
      "2687 loss = 0.033658988773822784 test acc 0.8603\n",
      "2688 loss = 0.0336589440703392 test acc 0.8603\n",
      "2689 loss = 0.03365889564156532 test acc 0.8603\n",
      "2690 loss = 0.03365885466337204 test acc 0.8604\n",
      "2691 loss = 0.03365881368517876 test acc 0.8604\n",
      "2692 loss = 0.03365876525640488 test acc 0.8604\n",
      "2693 loss = 0.033658720552921295 test acc 0.8604\n",
      "2694 loss = 0.033658672124147415 test acc 0.8604\n",
      "2695 loss = 0.03365863114595413 test acc 0.8604\n",
      "2696 loss = 0.03365858644247055 test acc 0.8604\n",
      "2697 loss = 0.03365854173898697 test acc 0.8604\n",
      "2698 loss = 0.03365849703550339 test acc 0.8604\n",
      "2699 loss = 0.033658452332019806 test acc 0.8604\n",
      "2700 loss = 0.033658403903245926 test acc 0.8604\n",
      "2701 loss = 0.03365836292505264 test acc 0.8604\n",
      "2702 loss = 0.03365831822156906 test acc 0.8604\n",
      "2703 loss = 0.03365827351808548 test acc 0.8604\n",
      "2704 loss = 0.0336582288146019 test acc 0.8604\n",
      "2705 loss = 0.03365818411111832 test acc 0.8604\n",
      "2706 loss = 0.033658143132925034 test acc 0.8604\n",
      "2707 loss = 0.03365809842944145 test acc 0.8604\n",
      "2708 loss = 0.03365805745124817 test acc 0.8604\n",
      "2709 loss = 0.03365800902247429 test acc 0.8604\n",
      "2710 loss = 0.03365796431899071 test acc 0.8604\n",
      "2711 loss = 0.033657923340797424 test acc 0.8604\n",
      "2712 loss = 0.033657874912023544 test acc 0.8604\n",
      "2713 loss = 0.03365783765912056 test acc 0.8604\n",
      "2714 loss = 0.03365779295563698 test acc 0.8604\n",
      "2715 loss = 0.0336577445268631 test acc 0.8604\n",
      "2716 loss = 0.033657703548669815 test acc 0.8604\n",
      "2717 loss = 0.03365766257047653 test acc 0.8604\n",
      "2718 loss = 0.03365761786699295 test acc 0.8604\n",
      "2719 loss = 0.03365756943821907 test acc 0.8604\n",
      "2720 loss = 0.03365752473473549 test acc 0.8604\n",
      "2721 loss = 0.03365748003125191 test acc 0.8604\n",
      "2722 loss = 0.033657439053058624 test acc 0.8604\n",
      "2723 loss = 0.03365739434957504 test acc 0.8604\n",
      "2724 loss = 0.03365735337138176 test acc 0.8604\n",
      "2725 loss = 0.03365730866789818 test acc 0.8604\n",
      "2726 loss = 0.033657267689704895 test acc 0.8604\n",
      "2727 loss = 0.03365722671151161 test acc 0.8604\n",
      "2728 loss = 0.03365718200802803 test acc 0.8604\n",
      "2729 loss = 0.03365713730454445 test acc 0.8604\n",
      "2730 loss = 0.03365709260106087 test acc 0.8604\n",
      "2731 loss = 0.033657051622867584 test acc 0.8604\n",
      "2732 loss = 0.0336570143699646 test acc 0.8604\n",
      "2733 loss = 0.03365696594119072 test acc 0.8604\n",
      "2734 loss = 0.033656924962997437 test acc 0.8604\n",
      "2735 loss = 0.03365688398480415 test acc 0.8604\n",
      "2736 loss = 0.03365683928132057 test acc 0.8604\n",
      "2737 loss = 0.03365679457783699 test acc 0.8604\n",
      "2738 loss = 0.03365675359964371 test acc 0.8604\n",
      "2739 loss = 0.033656712621450424 test acc 0.8604\n",
      "2740 loss = 0.03365667164325714 test acc 0.8604\n",
      "2741 loss = 0.03365662693977356 test acc 0.8604\n",
      "2742 loss = 0.03365658223628998 test acc 0.8604\n",
      "2743 loss = 0.033656541258096695 test acc 0.8604\n",
      "2744 loss = 0.03365649655461311 test acc 0.8604\n",
      "2745 loss = 0.03365645557641983 test acc 0.8604\n",
      "2746 loss = 0.03365641459822655 test acc 0.8605\n",
      "2747 loss = 0.03365636616945267 test acc 0.8605\n",
      "2748 loss = 0.033656325191259384 test acc 0.8605\n",
      "2749 loss = 0.0336562879383564 test acc 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750 loss = 0.03365624323487282 test acc 0.8605\n",
      "2751 loss = 0.033656202256679535 test acc 0.8605\n",
      "2752 loss = 0.03365615755319595 test acc 0.8605\n",
      "2753 loss = 0.03365612030029297 test acc 0.8605\n",
      "2754 loss = 0.03365606814622879 test acc 0.8605\n",
      "2755 loss = 0.033656030893325806 test acc 0.8605\n",
      "2756 loss = 0.03365598991513252 test acc 0.8605\n",
      "2757 loss = 0.03365594521164894 test acc 0.8605\n",
      "2758 loss = 0.03365590423345566 test acc 0.8605\n",
      "2759 loss = 0.033655863255262375 test acc 0.8605\n",
      "2760 loss = 0.03365582227706909 test acc 0.8605\n",
      "2761 loss = 0.03365577384829521 test acc 0.8605\n",
      "2762 loss = 0.03365573287010193 test acc 0.8605\n",
      "2763 loss = 0.033655691891908646 test acc 0.8605\n",
      "2764 loss = 0.03365565091371536 test acc 0.8605\n",
      "2765 loss = 0.03365561366081238 test acc 0.8605\n",
      "2766 loss = 0.033655568957328796 test acc 0.8605\n",
      "2767 loss = 0.03365552797913551 test acc 0.8605\n",
      "2768 loss = 0.03365548327565193 test acc 0.8605\n",
      "2769 loss = 0.03365544602274895 test acc 0.8605\n",
      "2770 loss = 0.033655401319265366 test acc 0.8605\n",
      "2771 loss = 0.03365536406636238 test acc 0.8605\n",
      "2772 loss = 0.0336553230881691 test acc 0.8605\n",
      "2773 loss = 0.033655278384685516 test acc 0.8605\n",
      "2774 loss = 0.03365524113178253 test acc 0.8605\n",
      "2775 loss = 0.03365519270300865 test acc 0.8605\n",
      "2776 loss = 0.03365515172481537 test acc 0.8605\n",
      "2777 loss = 0.03365510702133179 test acc 0.8605\n",
      "2778 loss = 0.033655066043138504 test acc 0.8605\n",
      "2779 loss = 0.03365503251552582 test acc 0.8605\n",
      "2780 loss = 0.033654987812042236 test acc 0.8605\n",
      "2781 loss = 0.03365494683384895 test acc 0.8605\n",
      "2782 loss = 0.03365490585565567 test acc 0.8605\n",
      "2783 loss = 0.03365486115217209 test acc 0.8605\n",
      "2784 loss = 0.033654820173978806 test acc 0.8605\n",
      "2785 loss = 0.03365478292107582 test acc 0.8605\n",
      "2786 loss = 0.03365473821759224 test acc 0.8605\n",
      "2787 loss = 0.033654700964689255 test acc 0.8605\n",
      "2788 loss = 0.03365465626120567 test acc 0.8604\n",
      "2789 loss = 0.03365461528301239 test acc 0.8604\n",
      "2790 loss = 0.033654578030109406 test acc 0.8603\n",
      "2791 loss = 0.033654533326625824 test acc 0.8603\n",
      "2792 loss = 0.03365449607372284 test acc 0.8603\n",
      "2793 loss = 0.03365445137023926 test acc 0.8603\n",
      "2794 loss = 0.03365441411733627 test acc 0.8603\n",
      "2795 loss = 0.03365437313914299 test acc 0.8603\n",
      "2796 loss = 0.033654335886240005 test acc 0.8603\n",
      "2797 loss = 0.03365429490804672 test acc 0.8603\n",
      "2798 loss = 0.03365425392985344 test acc 0.8603\n",
      "2799 loss = 0.033654212951660156 test acc 0.8603\n",
      "2800 loss = 0.03365417197346687 test acc 0.8603\n",
      "2801 loss = 0.03365412726998329 test acc 0.8603\n",
      "2802 loss = 0.03365409001708031 test acc 0.8603\n",
      "2803 loss = 0.033654049038887024 test acc 0.8603\n",
      "2804 loss = 0.03365401178598404 test acc 0.8603\n",
      "2805 loss = 0.033653970807790756 test acc 0.8603\n",
      "2806 loss = 0.033653926104307175 test acc 0.8603\n",
      "2807 loss = 0.03365388885140419 test acc 0.8603\n",
      "2808 loss = 0.033653851598501205 test acc 0.8603\n",
      "2809 loss = 0.03365381062030792 test acc 0.8603\n",
      "2810 loss = 0.03365376964211464 test acc 0.8603\n",
      "2811 loss = 0.033653732389211655 test acc 0.8602\n",
      "2812 loss = 0.03365369141101837 test acc 0.8602\n",
      "2813 loss = 0.03365365043282509 test acc 0.8602\n",
      "2814 loss = 0.033653613179922104 test acc 0.8602\n",
      "2815 loss = 0.03365357220172882 test acc 0.8602\n",
      "2816 loss = 0.03365353122353554 test acc 0.8602\n",
      "2817 loss = 0.033653490245342255 test acc 0.8602\n",
      "2818 loss = 0.03365345299243927 test acc 0.8602\n",
      "2819 loss = 0.03365341201424599 test acc 0.8602\n",
      "2820 loss = 0.033653371036052704 test acc 0.8602\n",
      "2821 loss = 0.03365333378314972 test acc 0.8602\n",
      "2822 loss = 0.033653296530246735 test acc 0.8602\n",
      "2823 loss = 0.03365325182676315 test acc 0.8602\n",
      "2824 loss = 0.03365321457386017 test acc 0.8602\n",
      "2825 loss = 0.033653177320957184 test acc 0.8602\n",
      "2826 loss = 0.0336531363427639 test acc 0.8602\n",
      "2827 loss = 0.033653099089860916 test acc 0.8602\n",
      "2828 loss = 0.03365305811166763 test acc 0.8602\n",
      "2829 loss = 0.03365302085876465 test acc 0.8602\n",
      "2830 loss = 0.033652979880571365 test acc 0.8602\n",
      "2831 loss = 0.03365294262766838 test acc 0.8602\n",
      "2832 loss = 0.0336528979241848 test acc 0.8602\n",
      "2833 loss = 0.03365286439657211 test acc 0.8602\n",
      "2834 loss = 0.03365282714366913 test acc 0.8602\n",
      "2835 loss = 0.03365278244018555 test acc 0.8602\n",
      "2836 loss = 0.03365274518728256 test acc 0.8602\n",
      "2837 loss = 0.033652711659669876 test acc 0.8602\n",
      "2838 loss = 0.03365267068147659 test acc 0.8602\n",
      "2839 loss = 0.03365262597799301 test acc 0.8602\n",
      "2840 loss = 0.03365258872509003 test acc 0.8602\n",
      "2841 loss = 0.03365255519747734 test acc 0.8602\n",
      "2842 loss = 0.03365251421928406 test acc 0.8602\n",
      "2843 loss = 0.03365247696638107 test acc 0.8602\n",
      "2844 loss = 0.03365243971347809 test acc 0.8602\n",
      "2845 loss = 0.033652398735284805 test acc 0.8602\n",
      "2846 loss = 0.03365235775709152 test acc 0.8602\n",
      "2847 loss = 0.03365232050418854 test acc 0.8602\n",
      "2848 loss = 0.03365228325128555 test acc 0.8602\n",
      "2849 loss = 0.03365224599838257 test acc 0.8602\n",
      "2850 loss = 0.033652205020189285 test acc 0.8602\n",
      "2851 loss = 0.033652164041996 test acc 0.8602\n",
      "2852 loss = 0.03365211933851242 test acc 0.8602\n",
      "2853 loss = 0.03365208953619003 test acc 0.8602\n",
      "2854 loss = 0.03365204855799675 test acc 0.8602\n",
      "2855 loss = 0.03365200757980347 test acc 0.8602\n",
      "2856 loss = 0.03365197032690048 test acc 0.8602\n",
      "2857 loss = 0.0336519330739975 test acc 0.8602\n",
      "2858 loss = 0.03365189954638481 test acc 0.8602\n",
      "2859 loss = 0.03365185856819153 test acc 0.8602\n",
      "2860 loss = 0.033651817589998245 test acc 0.8602\n",
      "2861 loss = 0.03365178406238556 test acc 0.8602\n",
      "2862 loss = 0.033651746809482574 test acc 0.8602\n",
      "2863 loss = 0.03365170583128929 test acc 0.8602\n",
      "2864 loss = 0.03365166485309601 test acc 0.8602\n",
      "2865 loss = 0.033651627600193024 test acc 0.8602\n",
      "2866 loss = 0.03365159407258034 test acc 0.8602\n",
      "2867 loss = 0.033651553094387054 test acc 0.8602\n",
      "2868 loss = 0.03365151211619377 test acc 0.8602\n",
      "2869 loss = 0.033651478588581085 test acc 0.8602\n",
      "2870 loss = 0.0336514413356781 test acc 0.8602\n",
      "2871 loss = 0.03365140035748482 test acc 0.8602\n",
      "2872 loss = 0.033651359379291534 test acc 0.8602\n",
      "2873 loss = 0.03365132585167885 test acc 0.8602\n",
      "2874 loss = 0.03365129232406616 test acc 0.8602\n",
      "2875 loss = 0.03365125134587288 test acc 0.8602\n",
      "2876 loss = 0.033651214092969894 test acc 0.8602\n",
      "2877 loss = 0.03365117684006691 test acc 0.8602\n",
      "2878 loss = 0.033651139587163925 test acc 0.8602\n",
      "2879 loss = 0.03365110233426094 test acc 0.8602\n",
      "2880 loss = 0.03365106135606766 test acc 0.8602\n",
      "2881 loss = 0.03365102410316467 test acc 0.8602\n",
      "2882 loss = 0.03365098685026169 test acc 0.8602\n",
      "2883 loss = 0.033650953322649 test acc 0.8602\n",
      "2884 loss = 0.03365091606974602 test acc 0.8602\n",
      "2885 loss = 0.03365087881684303 test acc 0.8602\n",
      "2886 loss = 0.03365083783864975 test acc 0.8602\n",
      "2887 loss = 0.033650804311037064 test acc 0.8602\n",
      "2888 loss = 0.03365076705813408 test acc 0.8602\n",
      "2889 loss = 0.033650729805231094 test acc 0.8602\n",
      "2890 loss = 0.03365069255232811 test acc 0.8602\n",
      "2891 loss = 0.033650655299425125 test acc 0.8602\n",
      "2892 loss = 0.03365061804652214 test acc 0.8603\n",
      "2893 loss = 0.033650580793619156 test acc 0.8603\n",
      "2894 loss = 0.03365054354071617 test acc 0.8603\n",
      "2895 loss = 0.033650510013103485 test acc 0.8603\n",
      "2896 loss = 0.0336504690349102 test acc 0.8603\n",
      "2897 loss = 0.03365043178200722 test acc 0.8603\n",
      "2898 loss = 0.03365039452910423 test acc 0.8603\n",
      "2899 loss = 0.03365036100149155 test acc 0.8603\n",
      "2900 loss = 0.033650320023298264 test acc 0.8603\n",
      "2901 loss = 0.03365028649568558 test acc 0.8603\n",
      "2902 loss = 0.033650245517492294 test acc 0.8603\n",
      "2903 loss = 0.03365021198987961 test acc 0.8603\n",
      "2904 loss = 0.03365017846226692 test acc 0.8603\n",
      "2905 loss = 0.03365013748407364 test acc 0.8603\n",
      "2906 loss = 0.03365010395646095 test acc 0.8603\n",
      "2907 loss = 0.03365006297826767 test acc 0.8603\n",
      "2908 loss = 0.033650025725364685 test acc 0.8603\n",
      "2909 loss = 0.033649992197752 test acc 0.8603\n",
      "2910 loss = 0.033649954944849014 test acc 0.8603\n",
      "2911 loss = 0.03364992141723633 test acc 0.8603\n",
      "2912 loss = 0.03364987671375275 test acc 0.8603\n",
      "2913 loss = 0.03364984691143036 test acc 0.8603\n",
      "2914 loss = 0.033649805933237076 test acc 0.8603\n",
      "2915 loss = 0.03364977240562439 test acc 0.8603\n",
      "2916 loss = 0.033649738878011703 test acc 0.8603\n",
      "2917 loss = 0.03364970162510872 test acc 0.8603\n",
      "2918 loss = 0.033649664372205734 test acc 0.8603\n",
      "2919 loss = 0.03364963084459305 test acc 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920 loss = 0.033649593591690063 test acc 0.8603\n",
      "2921 loss = 0.03364955261349678 test acc 0.8603\n",
      "2922 loss = 0.033649519085884094 test acc 0.8603\n",
      "2923 loss = 0.03364948555827141 test acc 0.8603\n",
      "2924 loss = 0.033649444580078125 test acc 0.8603\n",
      "2925 loss = 0.03364941105246544 test acc 0.8603\n",
      "2926 loss = 0.03364937752485275 test acc 0.8603\n",
      "2927 loss = 0.03364934027194977 test acc 0.8603\n",
      "2928 loss = 0.03364930301904678 test acc 0.8603\n",
      "2929 loss = 0.0336492657661438 test acc 0.8603\n",
      "2930 loss = 0.03364923223853111 test acc 0.8603\n",
      "2931 loss = 0.03364919498562813 test acc 0.8603\n",
      "2932 loss = 0.03364916145801544 test acc 0.8603\n",
      "2933 loss = 0.03364912420511246 test acc 0.8603\n",
      "2934 loss = 0.03364908695220947 test acc 0.8603\n",
      "2935 loss = 0.033649057149887085 test acc 0.8603\n",
      "2936 loss = 0.0336490161716938 test acc 0.8603\n",
      "2937 loss = 0.03364897891879082 test acc 0.8603\n",
      "2938 loss = 0.03364894911646843 test acc 0.8603\n",
      "2939 loss = 0.033648911863565445 test acc 0.8603\n",
      "2940 loss = 0.03364887833595276 test acc 0.8603\n",
      "2941 loss = 0.033648841083049774 test acc 0.8603\n",
      "2942 loss = 0.03364880755543709 test acc 0.8603\n",
      "2943 loss = 0.033648766577243805 test acc 0.8603\n",
      "2944 loss = 0.03364872932434082 test acc 0.8603\n",
      "2945 loss = 0.033648692071437836 test acc 0.8603\n",
      "2946 loss = 0.03364866226911545 test acc 0.8603\n",
      "2947 loss = 0.03364862874150276 test acc 0.8603\n",
      "2948 loss = 0.03364859148859978 test acc 0.8603\n",
      "2949 loss = 0.03364855796098709 test acc 0.8603\n",
      "2950 loss = 0.033648520708084106 test acc 0.8603\n",
      "2951 loss = 0.03364848718047142 test acc 0.8603\n",
      "2952 loss = 0.033648449927568436 test acc 0.8603\n",
      "2953 loss = 0.03364841639995575 test acc 0.8603\n",
      "2954 loss = 0.033648379147052765 test acc 0.8603\n",
      "2955 loss = 0.03364834189414978 test acc 0.8603\n",
      "2956 loss = 0.033648304641246796 test acc 0.8603\n",
      "2957 loss = 0.03364827111363411 test acc 0.8603\n",
      "2958 loss = 0.03364823758602142 test acc 0.8603\n",
      "2959 loss = 0.03364820405840874 test acc 0.8603\n",
      "2960 loss = 0.03364816680550575 test acc 0.8603\n",
      "2961 loss = 0.033648133277893066 test acc 0.8603\n",
      "2962 loss = 0.03364809602499008 test acc 0.8603\n",
      "2963 loss = 0.0336480587720871 test acc 0.8603\n",
      "2964 loss = 0.03364802524447441 test acc 0.8603\n",
      "2965 loss = 0.033647991716861725 test acc 0.8603\n",
      "2966 loss = 0.03364795446395874 test acc 0.8603\n",
      "2967 loss = 0.033647917211055756 test acc 0.8603\n",
      "2968 loss = 0.03364788368344307 test acc 0.8603\n",
      "2969 loss = 0.03364785015583038 test acc 0.8603\n",
      "2970 loss = 0.0336478166282177 test acc 0.8603\n",
      "2971 loss = 0.03364777937531471 test acc 0.8603\n",
      "2972 loss = 0.033647749572992325 test acc 0.8603\n",
      "2973 loss = 0.03364771232008934 test acc 0.8603\n",
      "2974 loss = 0.033647678792476654 test acc 0.8604\n",
      "2975 loss = 0.03364764526486397 test acc 0.8604\n",
      "2976 loss = 0.03364760801196098 test acc 0.8604\n",
      "2977 loss = 0.033647570759058 test acc 0.8604\n",
      "2978 loss = 0.03364753723144531 test acc 0.8604\n",
      "2979 loss = 0.03364749997854233 test acc 0.8604\n",
      "2980 loss = 0.03364747017621994 test acc 0.8604\n",
      "2981 loss = 0.033647436648607254 test acc 0.8604\n",
      "2982 loss = 0.03364739939570427 test acc 0.8604\n",
      "2983 loss = 0.033647362142801285 test acc 0.8604\n",
      "2984 loss = 0.0336473286151886 test acc 0.8604\n",
      "2985 loss = 0.03364729881286621 test acc 0.8604\n",
      "2986 loss = 0.033647265285253525 test acc 0.8604\n",
      "2987 loss = 0.03364722803235054 test acc 0.8604\n",
      "2988 loss = 0.033647190779447556 test acc 0.8604\n",
      "2989 loss = 0.03364715725183487 test acc 0.8604\n",
      "2990 loss = 0.03364712372422218 test acc 0.8604\n",
      "2991 loss = 0.0336470901966095 test acc 0.8604\n",
      "2992 loss = 0.03364705666899681 test acc 0.8604\n",
      "2993 loss = 0.03364702686667442 test acc 0.8604\n",
      "2994 loss = 0.03364698961377144 test acc 0.8604\n",
      "2995 loss = 0.03364695608615875 test acc 0.8604\n",
      "2996 loss = 0.033646922558546066 test acc 0.8604\n",
      "2997 loss = 0.03364688903093338 test acc 0.8604\n",
      "2998 loss = 0.033646855503320694 test acc 0.8604\n",
      "2999 loss = 0.03364681825041771 test acc 0.8604\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    for inner_counter, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output: torch.Tensor = model(x)  \n",
    "        y=F.one_hot(y, num_classes=10).float()\n",
    "        loss: torch.Tensor = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "    \n",
    "    #add model parameters to tab\n",
    "    loss_tab.append(loss.item())\n",
    "    params_tab = []\n",
    "    for param in model.parameters():\n",
    "        params_tab.append(param.detach().numpy().flatten()  )\n",
    "    w1_mean_tab.append(params_tab[0].mean())\n",
    "    w2_mean_tab.append(params_tab[1].mean())\n",
    "    w1_std_tab.append(params_tab[0].std())\n",
    "    w2_std_tab.append(params_tab[1].std())\n",
    "\n",
    "    # at the end of an epoch run evaluation on the test set\n",
    "    with torch.no_grad():\n",
    "        correct: int = 0 \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            output: torch.Tensor = model(x)\n",
    "            pred_labels = torch.argmax(output, 1)\n",
    "            correct += ( (pred_labels -y) ==0).sum()\n",
    "        train_accuracy_tab.append( float(correct) / len(train_data))\n",
    "        correct: int = 0 \n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            output: torch.Tensor = model(x)\n",
    "            pred_labels = torch.argmax(output, 1)\n",
    "            correct += ( (pred_labels -y) ==0).sum()\n",
    "        test_accuracy_tab.append( float(correct) / len(test_data))\n",
    "    \n",
    "    # save params\n",
    "    params=[]\n",
    "    for param in model.parameters():\n",
    "        params.append(param.detach().numpy())\n",
    "    w1=params[0] \n",
    "    w2=params[1]\n",
    "\n",
    "    R = U_matrix.T @ w2 @ w1 @ V_matrix\n",
    "\n",
    "    ######################### original terms ########################    \n",
    "    term_1 = 0\n",
    "    for alpha in range(10):\n",
    "        term_1 += (R[alpha][alpha] - S31_matrix[alpha]/S11_matrix[alpha][alpha])**2 * S11_matrix[alpha][alpha]\n",
    "    term_2 = 0\n",
    "    for beta in range(10):\n",
    "        for alpha in range(784):\n",
    "            if(alpha != beta):\n",
    "                term_2 += (R[beta][alpha])**2 *S11_matrix[alpha][alpha]\n",
    "    term_4 = 0\n",
    "    for alpha in range(10):\n",
    "        term_4+= (S31_matrix[alpha])**2/S11_matrix[alpha][alpha]\n",
    "\n",
    "    term_I_tab.append(round(float(term_1), 6))\n",
    "    term_II_tab.append(round(float(term_2), 6))\n",
    "    term_IV_tab.append(round(float(term_4), 6))\n",
    "    \n",
    "    \n",
    "    ########################## S11 diamond ##########################\n",
    "    term_1 = 0\n",
    "    for alpha in range(10):\n",
    "        term_1 += (R[alpha][alpha] - S31_matrix[alpha]/S11_improved[alpha])**2 * S11_improved[alpha]\n",
    "    term_2 = 0\n",
    "    for beta in range(10):\n",
    "        for alpha in range(784):\n",
    "            if(alpha != beta):\n",
    "                if alpha <10:\n",
    "                    term_2 += (R[beta][alpha])**2 * S11_improved[alpha]\n",
    "                else:\n",
    "                    term_2 += (R[beta][alpha])**2 *S11_matrix[alpha][alpha]\n",
    "\n",
    "    term_4 = 0\n",
    "    for alpha in range(10):\n",
    "        term_4+= (S31_matrix[alpha])**2/S11_improved[alpha]\n",
    "  \n",
    "    term_I_diamond_tab.append(round(float(term_1), 6))\n",
    "    term_II_diamond_tab.append(round(float(term_2), 6))\n",
    "    term_IV_diamond_tab.append(round(float(term_4), 6))\n",
    "    \n",
    "    \n",
    "    ########################## S31 star ##########################    \n",
    "    term_1 = 0\n",
    "    for alpha in range(10):\n",
    "        term_1 += (R[alpha][alpha] - S31_improved[alpha]/S11_matrix[alpha][alpha])**2 * S11_matrix[alpha][alpha]\n",
    "    term_2 = 0\n",
    "    for beta in range(10):\n",
    "        for alpha in range(784):\n",
    "            if(alpha != beta):\n",
    "                term_2 += (R[beta][alpha])**2 *S11_matrix[alpha][alpha]\n",
    "    term_4 = 0\n",
    "    for alpha in range(10):\n",
    "        term_4+= (S31_improved[alpha])**2/S11_matrix[alpha][alpha]\n",
    "       \n",
    "    term_I_star_tab.append(round(float(term_1), 6))\n",
    "    term_II_star_tab.append(round(float(term_2), 6))\n",
    "    term_IV_star_tab.append(round(float(term_4), 6))\n",
    "    \n",
    "    print(f'{e} loss = {loss} test acc {test_accuracy_tab[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "MSE_star =[]\n",
    "MSE_diamond =[]\n",
    "\n",
    "for i in range(3000):\n",
    "    MSE.append(term_I_tab[i] + term_II_tab[i] + 1.0 - term_IV_tab[i])\n",
    "    MSE_star.append(term_I_star_tab[i] + term_II_star_tab[i] + 1.0 - term_IV_star_tab[i])\n",
    "    MSE_diamond.append(term_I_diamond_tab[i] + term_II_diamond_tab[i] + 1.0 - term_IV_diamond_tab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE = []\n",
    "MSE_star =[]\n",
    "MSE_diamond =[]\n",
    "\n",
    "for i in range(3000):\n",
    "    MSE.append(term_I_tab[i] + term_II_tab[i] + 1.0 - term_IV_tab[i])\n",
    "    MSE_star.append(term_I_star_tab[i] + term_II_star_tab[i] + 1.0 - term_IV_star_tab[i])\n",
    "    MSE_diamond.append(term_I_diamond_tab[i] + term_II_diamond_tab[i] + 1.0 - term_IV_diamond_tab[i])\n",
    "    \n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "\n",
    "axs[0].plot(np.array(loss_tab)*10, color= 'pink', label = 'loss')\n",
    "\n",
    "axs[0].plot(MSE, color= 'indigo', label = '$MSE$')\n",
    "axs[1].plot(term_I_tab, color= 'indigo', label = '$T_1$')\n",
    "axs[2].plot(term_II_tab, color= 'indigo', label = '$T_2$')\n",
    "#axs[3].plot(term_IV_tab, color= 'indigo', label = 'original')\n",
    "\n",
    "axs[0].plot(MSE_star, color= 'plum', label = '$MSE^*$')\n",
    "axs[1].plot(term_I_star_tab, color= 'plum', label = '$T_1^*$')\n",
    "axs[2].plot(term_II_star_tab, color= 'plum', label = '$T_2^*$')\n",
    "#axs[3].plot(term_IV_star_tab, color= 'rebeccapurple', label = '$S^{31}$ improved')\n",
    "\n",
    "axs[0].plot(MSE_diamond, color= 'darkviolet', label = '$MSE^\\diamond$')\n",
    "axs[1].plot(term_I_diamond_tab, color= 'darkviolet', label = '$T_1^\\diamond$')\n",
    "axs[2].plot(term_II_diamond_tab, color= 'darkviolet', label = '$T_2^\\diamond$')\n",
    "#axs[3].plot(term_IV_diamond_tab, color= 'plum', label = '$S^{11}$ improved')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.grid(True, color='gray', alpha = 0.2)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "\n",
    "axs[0].set_ylabel('MSE', fontsize=12)\n",
    "axs[1].set_ylabel('$T_1$',fontsize=12)\n",
    "axs[2].set_ylabel('$T_2$',fontsize=12)\n",
    "axs[-1].set_xlabel('epoch',fontsize=12)\n",
    "axs[-1].set_xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['loss'] = loss_tab\n",
    "df['train_accuracy'] = train_accuracy_tab\n",
    "df['test_accuracy'] = test_accuracy_tab\n",
    "\n",
    "df['w1_mean'] = w1_mean_tab\n",
    "df['w1_std'] = w1_std_tab\n",
    "df['w2_mean'] = w2_mean_tab\n",
    "df['w2_std'] = w2_std_tab\n",
    "\n",
    "df['MSE'] = MSE\n",
    "df['term_I'] = term_I_tab\n",
    "df['term_II'] = term_II_tab\n",
    "df['term_IV'] = term_IV_tab\n",
    "\n",
    "df['MSE_star'] = MSE_star\n",
    "df['term_I_star'] = term_I_star_tab\n",
    "df['term_II_star'] = term_II_star_tab\n",
    "df['term_IV_star'] = term_IV_star_tab\n",
    "\n",
    "df['MSE_diamond']= MSE_diamond\n",
    "df['term_I_diamond'] = term_I_diamond_tab\n",
    "df['term_II_diamond'] = term_II_diamond_tab\n",
    "df['term_IV_diamond'] = term_IV_diamond_tab\n",
    "\n",
    "df.to_csv('terms_500.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
